{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6860a3f",
   "metadata": {},
   "source": [
    "#### TabNet - Feature Selection\n",
    "1. Masking처리 방법을 사용해서 매번 다른 input마다 어떤 feature을 선택할지 결정하는 것을 학습한다. 기존에는 ML algorithm을 사용하면 데이터 전처리, feature selection, modeling등의 과정을 모두 따로 진행 했지만 이 딥러닝 모델 하나만으로 end-to-end로 모든 것이 한번에 가능하게 된다.\n",
    "2. 이건 데이터 처리 단계에서 할텐데, feature 1을 선택한다면 feature 1에 대해서만 1로 masking 처리를 하고 나머지 feature은 0으로 둔다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ad33a",
   "metadata": {},
   "source": [
    "#### TabNet - Feature Transformer\n",
    "1. 앞선 feature selection에서 masking처리 되어 전달되는 feature에 embedding을 해준다.\n",
    "2. Feature Transformer = Fully Connected Layer + Ghost Batch Norm + GLU(Gated Linear Unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fcb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ghost Batch Normalization\n",
    "\"\"\"\n",
    "Batch를 다시 더 작은 batch로 분할해서 잡음을 momentum을 사용해 추가해주는 방법으로 generalization 성능을 향상시켜 준다.\n",
    "이때 내부적으로 nano batch를 사용하기 때문에 학습 시에는 large batch를 사용할 수 있어서 학습 속도가 빨라진다.\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "class GBN(nn.Module):\n",
    "    def __init__(self, input_dim, batch_size, momentum):\n",
    "        super(GBN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.momentum = momentum\n",
    "        self.bn = nn.BatchNorm1d(self.input_dim, momentum)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.batch_size)), 0)\n",
    "        results = [self.bn(c) for c in chuncks]\n",
    "        return torch.cat(results, dim = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a59885",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TabNet Encoder\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Encoder(nn.Module):\n",
    "    input_dim: int\n",
    "    output_dim: list[int]\n",
    "    n_d: int # prediction layer의 차원 수\n",
    "    n_a: int # attention layer의 차원 수\n",
    "    n_steps: int\n",
    "    gamma: float # 1.0과 2.0사이의 값으로, attention update를 위한 scaling factor이다.\n",
    "    n_glu_layer: int\n",
    "    epsilon: float\n",
    "    batch_size: int\n",
    "    momentum: float\n",
    "    \n",
    "    if (self.n_glu_layer > 0):\n",
    "        shared_feat_transform = nn.ModuleList()\n",
    "        for i in range(self.n_glu_layer):\n",
    "            if i == 0:\n",
    "                shared_feat_transform.append(nn.Linear(self.input_dim, 2 * (self.n_d + self.n_a), bias = False))\n",
    "            else:\n",
    "                shared_feat_transform.append(nn.Linear(self.n_d + self.n_a , 2 * (self.n_d + self.n_a), bias = False))\n",
    "    else:\n",
    "        shared_feat_transform = None\n",
    "    \n",
    "    self.feature_transformers = nn.ModuleList()\n",
    "    self.attention_transformers = nn.ModuleList()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05a473",
   "metadata": {},
   "source": [
    "#### TabNet - Attentive Transformer\n",
    "1. feature들을 선택하는 기능을 하는 것으로, Prior Scale + SparseMax로 구성이 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da1e99",
   "metadata": {},
   "source": [
    "#### TabNet - Decoder\n",
    "1. Encoder-Decoder 형태의 Auto Encoder처럼 unsupervised learning이 가능하다.\n",
    "2. 특정한 영역이 masking된 encoded data를 원본 처럼 복원할 수 있는 과정을 학습한다. 이때 결국에 자연어 처리에서 BERT같은 모델을 학습시킬때 사용하는 Masked Language Modeling과 유사하다고 할 수 있다.\n",
    "3. 이렇게 사전학습을 하여 예측의 정확도및 속도를 증가 시킬 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SiDConfig:\n",
    "    num_categories_list: list[int]\n",
    "    num_numerical_features: int\n",
    "    num_text_features: int\n",
    "    text_input_size: int\n",
    "    embedding_size: int = 64\n",
    "    hidden_size: int = 256\n",
    "    intermediate_size: int = 1024\n",
    "    num_hidden_layers: int = 18\n",
    "    num_transform_blocks: int = 1\n",
    "    num_attention_blocks: int = 1\n",
    "    hidden_dropout_prob: float = 0.5\n",
    "    attention_dropout_prob: float = 0.5\n",
    "    drop_path_prob: float = 0.5\n",
    "    embed_init_std: float = 0.02\n",
    "    num_labels: Optional[int] = None\n",
    "\n",
    "    @property\n",
    "    def num_total_categories(self) -> int:\n",
    "        return sum(self.num_categories_list)\n",
    "\n",
    "    @property\n",
    "    def num_categorical_features(self) -> int:\n",
    "        return len(self.num_categories_list)\n",
    "\n",
    "    @property\n",
    "    def num_total_features(self) -> int:\n",
    "        return (\n",
    "            self.num_categorical_features\n",
    "            + self.num_numerical_features\n",
    "            + self.num_text_features\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def total_embedding_size(self) -> int:\n",
    "        return self.num_total_features * self.embedding_size\n",
    "\n",
    "\n",
    "class StochasticDepth(nn.Module):\n",
    "    def __init__(self, drop_path_prob: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        if self.drop_path_prob == 0 or not self.training:\n",
    "            return hidden_states\n",
    "\n",
    "        mask = torch.rand((hidden_states.size(0), 1), device=hidden_states.device)\n",
    "        mask = (mask > self.drop_path_prob).type_as(hidden_states) / self.drop_path_prob\n",
    "        return mask * hidden_states\n",
    "\n",
    "\n",
    "class SiDEmbeddings(nn.Module):\n",
    "    def __init__(self, config: SiDConfig):\n",
    "        super().__init__()\n",
    "        self.categorical_embeddings = nn.Embedding(\n",
    "            config.num_total_categories, config.embedding_size\n",
    "        )\n",
    "        self.numerical_direction = nn.Parameter(\n",
    "            torch.rand(config.num_numerical_features, config.embedding_size)\n",
    "        )\n",
    "        self.numerical_anchor = nn.Parameter(\n",
    "            torch.rand(config.num_numerical_features, config.embedding_size)\n",
    "        )\n",
    "\n",
    "        # Although we define the multiple dense layers to project each text embedding to\n",
    "        # the input embedding space, we will use batched (stacked) matmul by gathering\n",
    "        # the weight matrices.\n",
    "        self.text_projections = nn.ModuleList(\n",
    "            nn.Linear(config.text_input_size, config.embedding_size, bias=False)\n",
    "            for _ in range(config.num_text_features)\n",
    "        )\n",
    "\n",
    "        # Create embedding offsets which indicate the start embedding index of each\n",
    "        # categorical feature. Because this class uses only one embedding layer which\n",
    "        # contains the embedding vectors for all categorical features, it is necessary\n",
    "        # to separate each embedding group from other features.\n",
    "        self.register_buffer(\n",
    "            \"categorical_embedding_offsets\",\n",
    "            torch.tensor([[0] + config.num_categories_list[:-1]]).cumsum(1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        categorical_inputs: torch.Tensor,\n",
    "        numerical_inputs: torch.Tensor,\n",
    "        text_inputs: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # Add embedding offsets to the categorical features to map to the corresponding\n",
    "        # embedding groups.\n",
    "        categorical_inputs = categorical_inputs + self.categorical_embedding_offsets\n",
    "        categorical_embeddings = self.categorical_embeddings(categorical_inputs)\n",
    "\n",
    "        numerical_embeddings = numerical_inputs[:, :, None] * self.numerical_direction\n",
    "        numerical_embeddings = numerical_embeddings + self.numerical_anchor\n",
    "\n",
    "        stacked_weight = torch.stack(\n",
    "            [layer.weight.transpose(0, 1) for layer in self.text_projections],\n",
    "        )\n",
    "        text_embeddings = torch.einsum(\"btm,tmn->btn\", text_inputs, stacked_weight)\n",
    "\n",
    "        # After creating embedding vectors for categorical, numerical and text features,\n",
    "        # they will be concatenated to a single tensor.\n",
    "        return torch.cat(\n",
    "            (categorical_embeddings, numerical_embeddings, text_embeddings), dim=1\n",
    "        )\n",
    "\n",
    "\n",
    "class SiDResidualBlock(nn.Module):\n",
    "    def __init__(self, config: SiDConfig):\n",
    "        super().__init__()\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.intermediate_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.intermediate_size, config.hidden_size * 2),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        output = self.feedforward(hidden_states)\n",
    "\n",
    "        output, gating = output.chunk(2, dim=1)\n",
    "        output = output * gating.sigmoid()\n",
    "\n",
    "        return hidden_states + self.dropout(output)\n",
    "\n",
    "\n",
    "class SiDLayer(nn.Module):\n",
    "    def __init__(self, config: SiDConfig, use_attention: bool = True):\n",
    "        super().__init__()\n",
    "        if use_attention:\n",
    "            self.attention = nn.Sequential(\n",
    "                *[SiDResidualBlock(config) for _ in range(config.num_attention_blocks)],\n",
    "                nn.Linear(config.hidden_size, config.num_total_features),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "            self.dropout = nn.Dropout(config.attention_dropout_prob)\n",
    "\n",
    "        self.projection = nn.Linear(config.total_embedding_size, config.hidden_size)\n",
    "        self.transform = nn.Sequential(\n",
    "            *[SiDResidualBlock(config) for _ in range(config.num_transform_blocks)]\n",
    "        )\n",
    "        self.droppath = StochasticDepth(config.drop_path_prob)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_embeddings: torch.Tensor,\n",
    "        hidden_states: Optional[torch.Tensor] = None,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Calculate the attention probabilities and multiply to the embeddings.\n",
    "        if hasattr(self, \"attention\") and hidden_states is not None:\n",
    "            attention_probs = self.attention(hidden_states)\n",
    "            attention_probs = self.dropout(attention_probs)\n",
    "            input_embeddings = input_embeddings * attention_probs[:, :, None]\n",
    "\n",
    "        output = self.projection(input_embeddings.flatten(1))\n",
    "        output = self.transform(output)\n",
    "\n",
    "        # If `hidden_states` is not None then use residual connection.\n",
    "        if hidden_states is not None:\n",
    "            return hidden_states + self.droppath(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SiDModel(nn.Module):\n",
    "    def __init__(self, config: SiDConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embeddings = SiDEmbeddings(config)\n",
    "        self.layers = nn.ModuleList(\n",
    "            SiDLayer(config, use_attention=i > 0)\n",
    "            for i in range(config.num_hidden_layers)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(config.hidden_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self, module: Optional[nn.Module] = None):\n",
    "        if module is None:\n",
    "            self.apply(self.init_weights)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, std=self.config.embed_init_std)\n",
    "        elif isinstance(module, SiDEmbeddings):\n",
    "            nn.init.normal_(module.numerical_direction, std=self.config.embed_init_std)\n",
    "            nn.init.normal_(module.numerical_anchor, std=self.config.embed_init_std)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_uniform_(module.weight, 5 ** 0.5)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        categorical_inputs: torch.Tensor,\n",
    "        numerical_inputs: torch.Tensor,\n",
    "        text_inputs: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        input_embeddings = self.embeddings(\n",
    "            categorical_inputs,\n",
    "            numerical_inputs,\n",
    "            text_inputs,\n",
    "        )\n",
    "\n",
    "        hidden_states = None\n",
    "        for layer in self.layers:\n",
    "            hidden_states = layer(input_embeddings, hidden_states)\n",
    "\n",
    "        hidden_states = self.normalization(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class SiDClassifier(nn.Module):\n",
    "    def __init__(self, config: SiDConfig):\n",
    "        super().__init__()\n",
    "        self.model = SiDModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        categorical_inputs: torch.Tensor,\n",
    "        numerical_inputs: torch.Tensor,\n",
    "        text_inputs: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        hidden_states = self.model(categorical_inputs, numerical_inputs, text_inputs)\n",
    "        logits = self.classifier(hidden_states)\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
