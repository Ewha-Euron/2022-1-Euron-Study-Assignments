Linear Classifier에서 어떤 가중치(w) 값을 사용하느냐에 따라 정확도가 달라진 다는 것을 배웠다.
그렇다면 어떻게 최적의 가중치 값을 찾아야 하는지 알아야 하는데 이를 위해서 사용하는 정량화 방법이 loss function이다.
loss fuction은 어느 가중치 값이 얼마나 "안 좋은지"를 알려주는 지표이다.
그리고 이 안 좋은 가중치를 좋은 가중치로 바꿔나가는 과정을 optimization이라고 한다.
f(x, W) = Wx + b
이 식에서 x는 이미지, W는 가중치, b는 편향값이다.
이 식에서 loss를 구하는 방법은 각 카테고리 (고양이 자동차 개구리 등)별로 loss를 각각 구해서 그걸 모두 더한 후 평균을 내는 것이다.
강의 자료에서 제시된 고양이 자동차 개구리 이미지를 통해 loss를 구한 값들은 다음과 같다.

- SVM loss (= hinge loss)
sj는 정답이 아닌 클래스의 score이고 syi는 정답 클래스의 score 값이다.
만약, syi > sj + safety margin(강의자료에서는 1)이면 loss = 0이고,
syi < sj + safety margin 이면 loss = sj - syi + safety margin이다.
SVM loss = SUM(j != y_i) { max (0, sj-syi+1) }
강의 자료의 고양이 자동차 개구리의 케이스로 계산한 SVM loss = 5.27이다.
고양이 자동차의 경우는 loss 값이 작지만 개구리에서 12.9의 loss 값이 나온다.

Q1. 그런데 이 때 자동차의 score 값을 조금 변경해서 loss 값을 계산해도 loss 값이 크게 변동하지 않는 것을 볼 수 있다.
따라서, SVM hinge loss는 데이터에 민감하지 않다는 특성이 있음을 알 수 있다.
Q2. 그럼 최소 최댓값은 어떻게 될까?
loss의 최소값은 0이다. 그리고 최대값은 무한대이다.
Q3. 만약 W가 매우 작아져서 score가 0에 근사해지면 어떻게 되나?
계산해보면, 클래스 3개니까 (2+2+2)/3 = 2가 나오고 만일 클래스가 9개라면 (9+9+9+~+9)/10 = 9가 나올 것이다.
따라서 그럴 경우 loss = 클래스 갯수 -1이 된다. 이 계산은 디버그 용으로 사용한다.
0으로 해주었을 때 loss가 클래수 갯수 -1의 값으로 나오는지 검사하는 것이다.
이걸 sanity check라고 부른다.
Q4. 지금까지 계산하면서 정답 클래스 값을 제외하고 계산했는데 그 이유는?
정답 클래스 값을 포함해서 계산하게 되면 모든 경우에서 loss 값이 +1 증가하게 된다.
그러나 우리는 loss 값이 0에 근사하게 되길 바라기 때문에 정답 클래스 값을 제외하는 것이다.
Q5. 만약 sum 대신 평균을 이용하면 어떻게 되나?
계산해보면 딱히 상관은 없다. 단지 평균을 사용했기 때문에 scale만 작아질 뿐이다.
다만, loss가 0에 가까워지도록 하길 바라기 때문에 scale을 크게 해서 변화를 관찰하는 것이 좋은 방법일 수 있다!
Q6. 그럼 max 값에 제곱승을 해서 계산하면?
제곱승을 해서 계산하게 되면 nonlinear한 결과가 나오고, 답이 달라지게 된다.
이렇게 계산하는 방식을 squared hinge loss라고 하는데 때에 따라서는 이 방식이 잘 먹힐 때도 있다.
그래서 "아주 좋다"와 "아주 나쁘다"를 따질 때 유용한 방식이다. (그러나 잘 사용하지는 않음)

그런데 이렇게 구하는 W 값은 과연 유일한 걸까? -> 아님
각각의 score 값을 2배 혹은 3배 증가시켜도 똑같은 loss 값이 나올 수 있다. 따라서 W는 여러 개가 나올 수 있다.
유일하지 않는 W값이 문제가 되는 이유는 
-> 우리는 새로운 값에 대해서 예측을 하기 위해 model을 만들기 때문에 test set에 더 관심이 많고 따라서 정확도도 test set을 통해서 추출한다.
그런데 지금까지 구한 W값은 train set에 맞춰서 나온 것들이기 때문에 최적값도 train set에 맞춰져서 나오게 된다.
그래서 그 최적값은 test set에는 맞지 않을 수도 있다는 문제가 있다.
-> overfitting의 문제가 생길 수도 있다는 것이다.

따라서 test set에도 맞을 수 있는 W값을 찾아야 하는데 이를 위해 사용하는 방식이 regularization이다.
L(W) = 1/N * SUM^N_(i=1) { Li(f(xi, W), yi) } + lamda R(W) 
이 식에서 왼쪽의 항은 data loss이고 오른쪽의 항은 regularization이다.
data loss는 train set의 입장에서, regularazation은 test set의 입장에 있기 때문에 
이 식에 따르면, 매 loss 값을 계산할 때 마다 train에만 맞는 것을 학습하려고 하면 regularization에서 패널티를 부여하게 된다.
이 과정을 통해서 test set에도 맞는 W 값을 찾아나갈 수 있다.

* 여기서 lamda R(W)가 무엇이길래 패널티를 부여하는 것일까?
일단 다항식이 너무 깊어지게 되면 복잡한 계산을 하게 되기 때문에 이를 방지하는 효과가 있다.
그리고 L1 regularization, L2 regularization이 있는데
전자는 실제로 차수 값이 0이 되도록하고, 후자는 전체 차수의 값이 0에 가깝도록 유도한다.
따라서 L1은 원하는 특성이 제거될 수 있기 때문에 L2가 모든 것을 고려한다는 점에서 비교우위를 가지게 된다.
그리고 lamda 값은 규제의 강도 값이고, 높으면 모델이 단순해지며 underfitting / 낮으면 모델이 복잡해지며 overfitting이 된다는 문제가 있다.

위와 같은 특성들 때문에 L1은 가중치 값 중 0이 있는 경우를, L2는 전체적으로 0에 가깝게 퍼진 가중치 값을 선호한다.

어쨋든 우리의 목적에 더 부합하는 것은 L2 regularization이기 때문에 이를 더 많이 사용하고 이는 dropout, batch normalization에서도 많이 사용한다.

- softmax classifier (=cross entropy)
모든 스코어에 exp를 취하고 그걸 모두 더한 뒤 원하는 클래스의 점수에 exp를 취해서 나눈다.
이렇게 계산한 것은 확률 값으로 도출되며, 이 때 원하는 정답 클래스에 -log를 취해 loss를 구하게 된다.
softmax는 multinomial logistic regression이다. (logistic regression = sigmoid function)
위와 같은 정의에 따라 위의 계산 방식에서 exp를 취해주는 것이다.
그리고 우리는 얼마나 "안" 좋은지를 판단하고자 하는데
x축을 확률, y축을 loss라고 했을 때, -log의 함수가 확률이 1에 가까워질 수록 0에 가까워지기 때문에 -log를 취해 최종 loss를 구하게 되는 것이다.

Q1. 이런 방식을 취했을 때 min, max는?
이론적으로 최소는 0, 최대는 무한대이다. (feat. -log graph)
Q2. 만약 score가 0에 가까워지면?
-log(1/클래스 갯수)가 되고 이 또한 디버깅 용으로 사용하며, sanity check라고 불린다.

강의자료에서는 예시 자료를 통해 svm과 softmax를 비교하고 있다.
1. max값을 취해서 loss를 구하는 것과 exp를 취해서 확률 값으로 loss를 구하는 것의 차이가 있다.
2. 만약 data point를 흔들어 주게 되면?
SVM의 경우에는 딱히 영향이 없었고 둔감하다는 결론이 나왔으나,
cross-entropy loss의 경우에는 조금만 데이터가 바뀌어도 확률에 영향이 있었고 매우 민감하다는 결론이 나온다.

+) Full loss라는 것은 언제가 regularization을 추가한다. 

위와 같은 방식들을 통해서 얻은 결론은 "어떤 W값이 얼마나 안좋은지"이다.
그렇다면 좋은 W값은? -> Optimization을 통해 구할 수 있다.
optimization은 쉽게 말하면 산 골짜기의 가장 깊은 곳으로 내려가는 것과 같으며 이 과정이 곧 loss가 0에 가까워지도록 하는 것이다.
몇 가지 방법이 소개되고 있는데 그 중에서 Random search는 사용하지 말아야 한다. (연산 오래 걸릴 수 있음.)
보통은 Follow the slope (gradient descent)경사 하강법을 사용한다.

1-dimension, the derivative of a function
d f(x) / d x = lim_(h->0) { ( f(x+h) - f(x) ) / h } (* 만약 다차원이면 편미분 형태의 식)
이렇게 수식으로 하나하나 계산해서 사용하는 방법 -> numerical 방법 (수치적 방법)
이 방식은 모든 가중치 W 값에 조금씩 변화를 줘가면서 loss 값의 변화를 관찰하는 것인데 이렇게 하면 너무 연산이 오래 걸린다.
단지 W가 변화할 때의 loss 값을 알고 싶을 뿐이라면?
미분을 이용한 analytic gradient(해석적 방법)을 사용한다. 이 방식을 사용하면 일일이 계산할 필요없이 딱! 원하는 값이 나오게 된다.
요약하자면,
numerical gradient: 정확하지 않고 느리지만 간편한 연산 방식 (오류가 덜 나는 편)
analytic gradient: 정확하고 빠르지만 복잡한 연산 방식 (오류가 날 가능성이 있음)
이다. 보통은 해석적 방법을 더 많이 사용하지만 디버깅을 할 때는 수치적 방법을 사용하기도 한다. 이를 gradient check라고 한다.

위와 같이 gradient 계산한 것들은 앞에 -가 붙으면 음의 기울기이기 때문에 +방향으로 이동하고
앞에 +가 붙으면 - 방향으로 이동하면서 그래프에서 가장 낮은 지점으로 이동한다.
여기서 한 번 이동할 때 이동하는 거리를 step size (=learning rate)라고 부른다. 이 값도 적절한 값을 찾아서 적용시키는 것이 중요하다.
그래서 임의의 w 위치에서 가운데 빨간색 지점으로 가는 것, 즉 기울기가 0에 가까운 지점으로 가는 것이 목표이다.

+) 지금까지 계산한 방식들은 N을 한 번에 올려서 계산했는데, 만약 N이 굉장히 큰 값이라면 매우 비효율적인 결과가 나올 것이다.
그래서 이 N을 나눠서 계산하는 stochastic gradient descent (SGD)를 많이 사용한다.
mini batch를 두어서 데이터 갯수를 잘라 사용하는 것인데 보통 2의 제곱수 만큼 잘라서 사용한다.
(256개를 가지고 W를 업데이트하고 그 다음 256개를 가지고 W를 업데이트하는 것을 반복하는 식이다.)

그냥 이미지를 그대로 넣어버리는 식으로 사용하는 것은 성능이 그닥 좋지 않았다. (이전 강의록의 말 머리가 2개 있는 식이라던가..)
그래서 CNN이 연구 되기 전까지는 이미지의 특징을 뽑아내고 이 특징을 합쳐서 linear regression에 넣는 방식을 사용해왔다.
이전에 linear classification으로 해결할 수 없는 것들의 예시를 보여주었었는데 이 때 극좌표계로 변환함으로써 직선으로 구분 가능한 형태로 바뀌는 경우가 있었다.
이미지를 활용할 때는 이렇게 하지 않지만 여기서 동기 부여를 받아 특징을 추출하는 방식으로 이어지게 된 것이다.
특징 추출의 한 가지 방법이 바로 color histogram이다. 컬러 hue 값이 있는데 여기에 어떤 컬러가 많이 나오는지 count 해서 특징을 추출하는 것이다.
2번 째 방법은 HoG(Historam of Oriented Gradients)이다. 방향 값을 히스토 그램으로 표현하는 것이다.
전체 이미지 내에서 어느 방향으로의 각도가 많은지 히스토그램으로 나타내 특징을 추출하는 것이다.
3번 째 방법은 bag of words이다. 자연어 처리에서 많이 사용하는 방법인데
먼저 이미지를 여러 개로 잘라낸 뒤, 비지도 학습과 같이 클러스터링을 돌려 각도, 색 등의 특징을 추출한다.
이 후 새로운 이미지가 들어오면 이 이미지를 잘라내서 클러스터와 비교해 어떤 특징이 있는지 비교한다.

그러나 CNN 연구 방식이 도입된 후 특징을 미리 뽑아내는 것이 아니라 입력된 이미지에서 스스로 특징을 추출하도록 하여 사용하고 있다.

(-> 다음 강의: neural network & backpropagation)
