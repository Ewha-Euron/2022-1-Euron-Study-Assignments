{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"week5_nlp_hw.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["📌 week5 내용 주차에 해당되는 과제는 3주차의 Glove 모델 실습, 4주차의 NER task 실습, 5주차의 Dependency Parsing task 실습으로 구성되어 있습니다. (**참고** : 제출은 week6 branch 복습과제로!) \n","\n","📌 위키독스의 딥러닝을 이용한 자연어 처리 입문 교재 실습, 캐글 노트북 등의 자료로 구성되어있는 과제입니다. \n","\n","📌 안내된 링크에 맞추어 **직접 코드를 따라 치면서 (필사)** 해당 nlp task 의 기본적인 라이브러리와 메서드를 숙지해보시면 좋을 것 같습니다😊 필수라고 체크한 부분은 과제에 반드시 포함시켜주시고, 선택으로 체크한 부분은 자율적으로 스터디 하시면 됩니다.\n","\n","📌 궁금한 사항은 깃허브 이슈나, 카톡방, 세션 발표 시작 이전 시간 등을 활용하여 자유롭게 공유해주세요!"],"metadata":{"id":"QhUHfXkPAORh"}},{"cell_type":"code","source":["import nltk\n","# nltk colab 환경에서 실행시 필요한 코드입니다. \n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","nltk.download('brown')"],"metadata":{"id":"3XjTSbcxBB6o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649602097186,"user_tz":-540,"elapsed":1425,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"65c1734d-55cd-4866-d709-7d4f848187b5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["### 1️⃣ **Glove**\n","\n"],"metadata":{"id":"-vPZn15zBHIv"}},{"cell_type":"markdown","source":["👀 **내용 복습** \n","* 스탠포드 대학에서 개발한 카운트 기반과 예측 기반을 모두 사용하는 단어 임베딩 방법론 \n","* word2vec 의 단점을 보완해서 나온 모델 \n","* glove model 의 **input 은 반드시 동시등장행렬 형태**여야 한다 ⭐\n","\n","![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n","\n","\n","\n","\n","🤔 한국어 예제는 없는 것 같습니다. 논문에서는 k-Glove 로 소개되는 연구가 있긴 한데, 좀 더 알아봐야 할 것 같아요!\n","\n","➕ [논문1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n","\n","\n","➕[논문2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"],"metadata":{"id":"P11biHcUuBaH"}},{"cell_type":"markdown","source":["🔹 **1-(1)** glove python\n","\n","* [실습 : basic code](https://wikidocs.net/22885) 👉 필수"],"metadata":{"id":"asGcGy6fBM1E"}},{"cell_type":"code","source":["import re\n","import urllib.request\n","import zipfile\n","from lxml import etree\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize, sent_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybnJoHLUDkTd","executionInfo":{"status":"ok","timestamp":1649587302208,"user_tz":-540,"elapsed":759,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"ba72737d-856a-49fc-a249-627dabd80ee0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OckC-JojDpok","executionInfo":{"status":"ok","timestamp":1649587305703,"user_tz":-540,"elapsed":805,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"13a7e9ea-b345-4c5d-dd4b-d07748209567"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7fb81046fe50>)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","target_text = etree.parse(targetXML)\n","\n","# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n","# 해당 코드는 괄호로 구성된 내용을 제거.\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","\n","# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","sent_text = sent_tokenize(content_text)\n","\n","# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","target_text = etree.parse(targetXML)\n","\n","# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n","# 해당 코드는 괄호로 구성된 내용을 제거.\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","\n","# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","sent_text = sent_tokenize(content_text)\n","\n","# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","\n","# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n","result = [word_tokenize(sentence) for sentence in normalized_text]\n","print('총 샘플의 개수 : {}'.format(len(result)))\n","# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n","result = [word_tokenize(sentence) for sentence in normalized_text]\n","print('총 샘플의 개수 : {}'.format(len(result)))\n","\n","for line in result[:3]:\n","    print(line)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6LvfOHhDthW","executionInfo":{"status":"ok","timestamp":1649587402294,"user_tz":-540,"elapsed":95503,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"8c91feb1-e0f1-45fa-aeca-cb5f78e072a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["총 샘플의 개수 : 273424\n","총 샘플의 개수 : 273424\n","['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n","['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n","['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"]}]},{"cell_type":"code","source":["pip install glove_python_binary"],"metadata":{"id":"hBJb4Vf2BFnP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649586994097,"user_tz":-540,"elapsed":4306,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"e0045b3d-d1c2-4e5f-b54f-201b414da060"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting glove_python_binary\n","  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 948 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.4.1)\n","Installing collected packages: glove-python-binary\n","Successfully installed glove-python-binary-0.2.0\n"]}]},{"cell_type":"code","source":["from glove import Corpus, Glove\n","\n","corpus = Corpus() \n","\n","# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n","corpus.fit(result, window=5)\n","glove = Glove(no_components=100, learning_rate=0.05)\n","\n","# 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20.\n","glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n","glove.add_dictionary(corpus.dictionary)"],"metadata":{"id":"i4tfK0zEgoxe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649587536624,"user_tz":-540,"elapsed":129698,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"198dad58-67a7-4451-9fa9-198542e83b66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing 20 training epochs with 4 threads\n","Epoch 0\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Epoch 9\n","Epoch 10\n","Epoch 11\n","Epoch 12\n","Epoch 13\n","Epoch 14\n","Epoch 15\n","Epoch 16\n","Epoch 17\n","Epoch 18\n","Epoch 19\n"]}]},{"cell_type":"code","source":["print(glove.most_similar(\"man\"))"],"metadata":{"id":"4AZWdutNFJKp","executionInfo":{"status":"ok","timestamp":1649587561464,"user_tz":-540,"elapsed":394,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"7df52744-c3fa-429f-fd1b-650164e90760","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('woman', 0.9587923848401108), ('guy', 0.8862452469428628), ('girl', 0.8776861947016005), ('young', 0.8510707305606063)]\n"]}]},{"cell_type":"code","source":["print(glove.most_similar(\"boy\"))"],"metadata":{"id":"Ea7sUu2vFKhX","executionInfo":{"status":"ok","timestamp":1649587569630,"user_tz":-540,"elapsed":379,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"97600d74-7802-4bea-e20b-39297975c464","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('girl', 0.9419106589610142), ('kid', 0.8426432386793163), ('woman', 0.8336767388220712), ('man', 0.8279362410773474)]\n"]}]},{"cell_type":"code","source":["print(glove.most_similar(\"university\"))"],"metadata":{"id":"BUYs_sUCFNiu","executionInfo":{"status":"ok","timestamp":1649587583335,"user_tz":-540,"elapsed":333,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"cef19697-c6cc-452b-95de-f6a8f0de3340","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('harvard', 0.8821548970564737), ('mit', 0.8430463953216943), ('cambridge', 0.8388854120957965), ('stanford', 0.8333815995816576)]\n"]}]},{"cell_type":"markdown","source":["🔹 **1-(2)** pre-trained glove \n","\n","* **사전학습모델** : 임의의 값으로 초기화하던 모델의 가중치들을 다른 문제에 학습시킨 가중치들로 초기화하는 방법이다.사전 학습한 가중치를 활용해 학습하고자 하는 본래 문제를 하위문제라고 한다. \n","\n","* [실습 : 문장의 긍부정을 판단하는 감성 분류 모델 만들기](https://wikidocs.net/33793) 👉 필수\n","  * [설명참고](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n","* pre-trained data 를 가져오는데 시간이 오래걸림\n","* kaggle 대회에서 주로 이 방식을 많이 사용함\n","  * [참고](https://lsjsj92.tistory.com/455)"],"metadata":{"id":"3ADfVM9lO9NE"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n","y_train = [1, 0, 0, 1, 1, 0, 1]"],"metadata":{"id":"b1ktg4xggolx","executionInfo":{"status":"ok","timestamp":1649601220966,"user_tz":-540,"elapsed":2518,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n","print('단어 집합 :',vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nM08mI8o5Qvs","executionInfo":{"status":"ok","timestamp":1649601232720,"user_tz":-540,"elapsed":661,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"26e67a16-4c38-4b85-b4ab-9bc7d9009364"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합 : 16\n"]}]},{"cell_type":"code","source":["X_encoded = tokenizer.texts_to_sequences(sentences)\n","print('정수 인코딩 결과 :',X_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLxa923E5T7J","executionInfo":{"status":"ok","timestamp":1649601240204,"user_tz":-540,"elapsed":3,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"8a07e6ba-3565-4d68-b72a-9e6b26bee25d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["정수 인코딩 결과 : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"]}]},{"cell_type":"code","source":["max_len = max(len(l) for l in X_encoded)\n","print('최대 길이 :',max_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19_C57r95Wnb","executionInfo":{"status":"ok","timestamp":1649601254836,"user_tz":-540,"elapsed":300,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"2fe26dd4-b693-4c7e-d0f4-811b50734c19"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["최대 길이 : 4\n"]}]},{"cell_type":"code","source":["X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n","y_train = np.array(y_train)\n","print('패딩 결과 :')\n","print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ku1lIuCa5Y2j","executionInfo":{"status":"ok","timestamp":1649601262528,"user_tz":-540,"elapsed":485,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"1845e7fd-3987-4f00-a564-a49dd3ca6276"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["패딩 결과 :\n","[[ 1  2  3  4]\n"," [ 5  6  0  0]\n"," [ 7  8  0  0]\n"," [ 9 10  0  0]\n"," [11 12  0  0]\n"," [13  0  0  0]\n"," [14 15  0  0]]\n"]}]},{"cell_type":"code","source":["from urllib.request import urlretrieve, urlopen\n","import gzip\n","import zipfile\n","\n","urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n","zf = zipfile.ZipFile('glove.6B.zip')\n","zf.extractall() \n","zf.close()"],"metadata":{"id":"KVyEXCtA5h_i","executionInfo":{"status":"ok","timestamp":1649601589440,"user_tz":-540,"elapsed":182840,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["embedding_dict = dict()\n","\n","f = open('glove.6B.100d.txt', encoding=\"utf8\")\n","\n","for line in f:\n","    word_vector = line.split()\n","    word = word_vector[0]\n","\n","    # 100개의 값을 가지는 array로 변환\n","    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n","    embedding_dict[word] = word_vector_arr\n","f.close()\n","\n","print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWv87Vv55-zS","executionInfo":{"status":"ok","timestamp":1649601746670,"user_tz":-540,"elapsed":9630,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"65fc8c20-8599-4b49-e26f-a620ded445c7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["400000개의 Embedding vector가 있습니다.\n"]}]},{"cell_type":"markdown","source":["🔹 **1-(3)** fine tuning glove\n","* 미세조정 : 사전 학습한 모든 가중치와 더불어 하위 문제를 위한 최소한의 가중치를 추가해 모델을 추가로 학습하는 방법이다. \n","\n","* fine tuning 이 필요한 경우 \n","  * pretrained model 에 데이터셋에 있는 단어가 포함되지 않은 경우 \n","  * 데이터 집합이 너무 작아서 전체 모델을 훈련시키기 어려운 경우 \n","\n","* [Mittens 라이브러리로 fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) 👉 필수\n","  *  GloVe 임베딩을 fine-tuning 하기 위한 파이썬 라이브러리\n","  * [github](https://github.com/roamanalytics/mittens)\n","\n","* [한국어 소설 텍스트 데이터 미세조정 모델 학습 - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) 👉 선택 (glove 모델 예제는 아닙니다. fine-tuning 에 초점을 두어서 참고해주시면 좋을 것 같습니다.)"],"metadata":{"id":"f_wcrE5PtLMI"}},{"cell_type":"code","source":["pip install -U mittens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DuSSaFgl79oC","executionInfo":{"status":"ok","timestamp":1649601934268,"user_tz":-540,"elapsed":3895,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"96ce415f-7eda-4bb5-8bf7-5c3fe0258cad"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mittens\n","  Downloading mittens-0.2-py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mittens) (1.21.5)\n","Installing collected packages: mittens\n","Successfully installed mittens-0.2\n"]}]},{"cell_type":"code","source":["import csv\n","import numpy as np\n","from collections import Counter\n","from nltk.corpus import brown\n","from mittens import GloVe, Mittens\n","from sklearn.feature_extraction import _stop_words\n","from sklearn.feature_extraction.text import CountVectorizer\n","import pickle\n","\n","\n","def glove2dict(glove_filename):\n","    with open(glove_filename, encoding='utf-8') as f:\n","        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n","        embed = {line[0]: np.array(list(map(float, line[1:])))\n","                for line in reader}\n","    return embed\n","\n","glove_path = \"glove.6B.50d.txt\" # get it from https://nlp.stanford.edu/projects/glove\n","pre_glove = glove2dict(glove_path)\n","\n","sw = list(_stop_words.ENGLISH_STOP_WORDS)\n","brown_data = brown.words()[:200000]\n","brown_nonstop = [token.lower() for token in brown_data if (token.lower() not in sw)]\n","oov = [token for token in brown_nonstop if token not in pre_glove.keys()]\n","\n","def get_rareoov(xdict, val):\n","    return [k for (k,v) in Counter(xdict).items() if v<=val]\n","\n","#oov_rare = get_rareoov(oov, 1)\n","#corp_vocab = list(set(oov) - set(oov_rare))\n","#brown_tokens = [token for token in brown_nonstop if token not in oov_rare]\n","#brown_doc = [' '.join(brown_tokens)]\n","\n","corp_vocab = list(set(oov))\n","brown_doc = [' '.join(brown_nonstop)]\n","\n","cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n","X = cv.fit_transform(brown_doc)\n","Xc = (X.T * X)\n","Xc.setdiag(0)\n","coocc_ar = Xc.toarray()\n","\n","mittens_model = Mittens(n=50, max_iter=1000)\n","\n","new_embeddings = mittens_model.fit(\n","    coocc_ar,\n","    vocab=corp_vocab,\n","    initial_embedding_dict= pre_glove)\n","\n","newglove = dict(zip(corp_vocab, new_embeddings))\n","f = open(\"repo_glove.pkl\",\"wb\")\n","pickle.dump(newglove, f)\n","f.close()"],"metadata":{"id":"tW_Z7VULX_i2","executionInfo":{"status":"ok","timestamp":1649602586763,"user_tz":-540,"elapsed":166512,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75fb49c2-340a-4a8c-94ea-a410649a46ad"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n","  self._set_arrayXarray(i, j, x)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n","Iteration 1000: loss: 0.02815323695540428"]}]},{"cell_type":"markdown","source":["* (참고) word2vec pretrained example\n","\n","➕ [word2vec 사전학습 모델 -한국어1](http://doc.mindscale.kr/km/unstructured/11.html)\n","\n","➕ [word2vec 사전학습 - 한국어2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"],"metadata":{"id":"I_-OB9Siga3G"}},{"cell_type":"markdown","source":["### **2️⃣ NER**"],"metadata":{"id":"xUWWDwdiPLS9"}},{"cell_type":"markdown","source":["👀 **내용 복습** \n","* 개체명 인식을 사용하면 코퍼스로부터 어떤 단어가 사람, 장소, 조직 등을 의미하는 단어인지를 찾을 수 있다. "],"metadata":{"id":"9N0B4VknPkTk"}},{"cell_type":"markdown","source":["\n","\n","\n","🔹 **2-(1)** NER task by nltk library\n","\n","\n","* nltk 에서는 개체명 인식기 (NER chunker) 를 지원하고 있다. \n","* ne_chunk 는 개체명을 태깅하기 위해서 앞서 품사 태깅 pos_tag 가 수행되어야 한다. \n","\n","\n","📌 [basic code](https://wikidocs.net/30682) 👉 필수 \n","\n","📌 [BIO 표현, LSTM을 활용한 NER 실습](https://wikidocs.net/24682) 👉 선택\n","\n","\n"],"metadata":{"id":"QWgla1BuPRqJ"}},{"cell_type":"code","source":["from nltk import word_tokenize, pos_tag, ne_chunk\n","\n","sentence = \"James is working at Disney in London\"\n","# 토큰화 후 품사 태깅\n","tokenized_sentence = pos_tag(word_tokenize(sentence))\n","print(tokenized_sentence)"],"metadata":{"id":"diaZweMyAxJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649602586765,"user_tz":-540,"elapsed":17,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"4d45f13b-2d66-42db-ddb1-2acd5031d2ba"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"]}]},{"cell_type":"code","source":["ner_sentence = ne_chunk(tokenized_sentence)\n","print(ner_sentence)"],"metadata":{"id":"1k09tKha3Lgi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649602606552,"user_tz":-540,"elapsed":412,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"aecf678c-e1a0-42ca-87a9-205af03fd849"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (PERSON James/NNP)\n","  is/VBZ\n","  working/VBG\n","  at/IN\n","  (ORGANIZATION Disney/NNP)\n","  in/IN\n","  (GPE London/NNP))\n"]}]},{"cell_type":"markdown","source":["🔹 **2-(2)** NER task by spacy library\n","\n","\n","* spaCy 는 자연어처리를 위한 파이썬 기반의 오픈 소스 라이브러리로 다음과 같은 기능을 제공한다. \n","  * Tokenization \n","  * POS tagging \n","  * Lemmatization \n","  * Sentence Boundary Detection (SBD)\n","  * Named Entity Recognition (NER)\n","  * Similarity\n","  * Text Classification\n","  * Rule-based Matching\n","  * Training\n","  * Serialization\n","\n","* spaCy 와 NER\n","  * .ents → .label_\n","\n","\n","📌 [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) 👉 필수 (NER 부분만)\n","\n","📌 [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) 👉 선택\n","\n","  * 훈련되지 않은 데이터 세트에 명명된 엔티티를 학습하는 방법 : 이력서 pdf 데이터 활용 \n","  * manually labelled \n","\n","📌 [한국어 NER](https://github.com/monologg/KoBERT-NER) 👉 참고하면 좋을 자료\n","\n","➕ [참고](http://aispiration.com/nlp2/nlp-ner-python.html)"],"metadata":{"id":"TPX-WtSvPmm6"}},{"cell_type":"code","source":["!pip install spacy"],"metadata":{"id":"WXjRfz-qP0Xx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649603707215,"user_tz":-540,"elapsed":6970,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"2f165624-61b3-453d-d215-7ad601977c67"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.4)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.1.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.15)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.63.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"]}]},{"cell_type":"code","source":["import spacy \n","!python -m spacy download en\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","doc = nlp('Apple is looking at buyin at U.K startup for $1 billion.')\n","print(type(doc)) \n","print(doc)\n","print(list(doc))\n","print(type(doc[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3K6iuTxo-xTf","executionInfo":{"status":"ok","timestamp":1649603787318,"user_tz":-540,"elapsed":13962,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"bcd82c47-d0bd-48f2-d008-57ee7d48c987"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Collecting en-core-web-sm==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n","\u001b[K     |████████████████████████████████| 13.9 MB 23.9 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.63.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n","Installing collected packages: en-core-web-sm\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en-core-web-sm 2.2.5\n","    Uninstalling en-core-web-sm-2.2.5:\n","      Successfully uninstalled en-core-web-sm-2.2.5\n","Successfully installed en-core-web-sm-3.2.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","<class 'spacy.tokens.doc.Doc'>\n","Apple is looking at buyin at U.K startup for $1 billion.\n","[Apple, is, looking, at, buyin, at, U.K, startup, for, $, 1, billion, .]\n","<class 'spacy.tokens.token.Token'>\n"]}]},{"cell_type":"code","source":["doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n","\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JjmcUSNx_CHB","executionInfo":{"status":"ok","timestamp":1649603793227,"user_tz":-540,"elapsed":313,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"d05636c4-fa9e-4bf4-efc2-ec514c74aac2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Apple ORG\n","U.K. GPE\n","$1 billion MONEY\n"]}]},{"cell_type":"code","source":["doc = nlp(\"\"\"But Google is starting from behind. The company made a late push\n","into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n","software, which runs on its Echo and Dot devices, have clear leads in\n","consumer adoption.\"\"\".replace(\"\\n\", \" \").strip())\n","\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Xp-k0Tc_Lsv","executionInfo":{"status":"ok","timestamp":1649603795065,"user_tz":-540,"elapsed":306,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"c38fea72-445c-4e6e-a443-b73f5a91414d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Google ORG\n","Apple’s Siri ORG\n","iPhones ORG\n","Amazon’s Alexa ORG\n","Echo GPE\n"]}]},{"cell_type":"markdown","source":["###**3️⃣ Dependency Parsing**"],"metadata":{"id":"008-V5QsQG25"}},{"cell_type":"markdown","source":["👀 **내용 복습** \n","* 문장의 전체적인 구성/구조 보다는 각 개별단어 간의 '의존관계' 또는 '수식관계' 와 같은 단어간 관계를 파악하는 것이 목적인 NLP Task\n","* 문장 해석의 모호성을 없애기 위해 Parsing 을 한다."],"metadata":{"id":"oQfcodHQQPlt"}},{"cell_type":"markdown","source":["\n","\n","\n","🔹 **3-(1)** Dependency Parsing by spacy library\n","\n","\n","* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) 👉 dependecy parsing 부분만 필수\n","* .dep_ 메서드\n","\n"],"metadata":{"id":"mJLAzZnbRNlL"}},{"cell_type":"code","source":["doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n","\n","noun_chunks = doc.noun_chunks\n","print(type(noun_chunks))\n","noun_chunk = list(noun_chunks)[0]\n","print(type(noun_chunk))\n","token = noun_chunk[0]\n","print(type(token))\n","\n","print(\"==\"*30)\n","print(\"\"\"\n","Text: The original noun chunk text.\n","Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n","Root dep: Dependency relation connecting the root to its head.\n","Root head text: The text of the root token's head.\n","\"\"\".strip())\n","print(\"==\"*30)\n","str_format = \"{:>25}\"*4\n","for chunk in doc.noun_chunks:\n","    print(str_format.format(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text))"],"metadata":{"id":"HbQEYt76bJXz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649603797526,"user_tz":-540,"elapsed":324,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"2ccbf9b9-b8a7-451d-81a1-5f1594247fb7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'generator'>\n","<class 'spacy.tokens.span.Span'>\n","<class 'spacy.tokens.token.Token'>\n","============================================================\n","Text: The original noun chunk text.\n","Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n","Root dep: Dependency relation connecting the root to its head.\n","Root head text: The text of the root token's head.\n","============================================================\n","          Autonomous cars                     cars                    nsubj                    shift\n","      insurance liability                liability                     dobj                    shift\n","            manufacturers            manufacturers                     pobj                   toward\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","import matplotlib.pyplot as plt \n","\n","nG = nx.Graph()\n","doc[2] ## root node\n","\n","def add_n_to_g(inputG, tok):\n","    inputG.add_node(tok)\n","    children = list(tok.children)\n","    if children != []:\n","        inputG.add_nodes_from(children)\n","        for c in children:\n","            inputG.add_edges_from([(tok, c, {'dependency':c.dep_})])\n","            add_n_to_g(inputG, c)\n","add_n_to_g(nG, doc[2])\n","print(nG.nodes(data=True))\n","print(\"==\"*20)\n","for e in nG.edges(data=True):\n","    print(f\"{e[0]}, {e[1]}, ### dependency: {e[2]['dependency']}\")"],"metadata":{"id":"W9QAEsrLAxHP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649603800478,"user_tz":-540,"elapsed":702,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"b4531ec3-ef33-40dc-e085-70b6f9a4aadc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[(shift, {}), (cars, {}), (liability, {}), (toward, {}), (Autonomous, {}), (insurance, {}), (manufacturers, {})]\n","========================================\n","shift, cars, ### dependency: nsubj\n","shift, liability, ### dependency: dobj\n","shift, toward, ### dependency: prep\n","cars, Autonomous, ### dependency: amod\n","liability, insurance, ### dependency: compound\n","toward, manufacturers, ### dependency: pobj\n"]}]},{"cell_type":"markdown","source":["🔹 **3-(2)** Spacy (kaggle) \n","\n","* 캐글 노트북 환경에서 실습해보는 것을 권장드립니다!\n","\n","* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) 👉 필수\n","  * 도날드 트럼프 트위터 트윗 내용 데이터 분석\n","\n","\n","👀 **노트북 키포인트** \n","  1. spacy.display 메서드를 사용한 NER 시각화 \n","  2. Tagging 을 통한 트럼프 트윗 분석 : noun_chunks 는 dependency graph를 고려하여, noun phrase를 뽑아준다. \n","  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : 직접 문장/단어 패턴을 등록하여 parsing\n","  4. Question and answering task using Dependency Parsing\n","    * spacy display :  ``style = 'dep'``\n","    * .dep_\n"],"metadata":{"id":"XQD5oiGgRfHe"}},{"cell_type":"code","source":["!python -m spacy download en_core_web_lg"],"metadata":{"id":"LuHGKITRbKYq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649603879746,"user_tz":-540,"elapsed":69262,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"a2f3b475-9a08-457d-f213-11d081245b35"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-lg==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n","\u001b[K     |████████████████████████████████| 777.4 MB 6.1 kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.2.0) (3.2.4)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (57.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.11.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.21.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (7.1.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.9)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.23.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.15)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.63.0)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.10)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.1)\n","Installing collected packages: en-core-web-lg\n","  Attempting uninstall: en-core-web-lg\n","    Found existing installation: en-core-web-lg 2.2.5\n","    Uninstalling en-core-web-lg-2.2.5:\n","      Successfully uninstalled en-core-web-lg-2.2.5\n","Successfully installed en-core-web-lg-3.2.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n"]}]},{"cell_type":"code","source":["!pip install textacy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ia2kE53OCEPV","executionInfo":{"status":"ok","timestamp":1649603883417,"user_tz":-540,"elapsed":3676,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"f2da7bb2-c57f-43a0-edb1-b10c23f43aad"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: textacy in /usr/local/lib/python3.7/dist-packages (0.11.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n","Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n","Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n","Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.9.0)\n","Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.11.2)\n","Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.63.0)\n","Requirement already satisfied: pyphen>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.12.0)\n","Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n","Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (3.2.4)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.5)\n","Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.6.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.10.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.3.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.9)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (7.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.4.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (8.0.15)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n"]}]},{"cell_type":"code","source":["nlp = spacy.load('en_core_web_lg')"],"metadata":{"id":"9WcS6gHtBrqg","executionInfo":{"status":"ok","timestamp":1649603894895,"user_tz":-540,"elapsed":4777,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"uMArOUrxAJ8K","colab":{"base_uri":"https://localhost:8080/","height":342},"executionInfo":{"status":"error","timestamp":1649604119768,"user_tz":-540,"elapsed":268,"user":{"displayName":"­조서영(엘텍공과대학 소프트웨어학부)","userId":"17786557581373572835"}},"outputId":"d47abbbd-aed8-4924-dd90-f888e8212fab"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-cde8bf652215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\stell\\\\Downloads\\\\all_djt_tweets.csv\\\\all_djt_tweets.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stell\\\\Downloads\\\\all_djt_tweets.csv\\\\all_djt_tweets.csv'"]}],"source":["import pandas as pd\n","tweets = pd.read_csv(\"C:\\\\Users\\\\stell\\\\Downloads\\\\all_djt_tweets.csv\\\\all_djt_tweets.csv\")"]}]}