## ğŸ“• ì „ì´í•™ìŠµ ì •ë¦¬ (Pytorch)

### TRANSFER LEARNING ì´ë€?
ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œë„ CNNs í•™ìŠµì„ ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²•. 

ë§¤ìš° í° ë°ì´í„°ì…‹(ì˜ˆ. 100ê°€ì§€ ë¶„ë¥˜ì— ëŒ€í•´ 120ë§Œê°œì˜ ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ImageNet)ì—ì„œ í•©ì„±ê³± ì‹ ê²½ë§(ConvNet)ì„ ë¯¸ë¦¬ í•™ìŠµí•œ í›„, ì´ í•©ì„±ê³± ì‹ ê²½ë§ì„ ê´€ì‹¬ìˆëŠ” ì‘ì—… ì„ ìœ„í•œ ì´ˆê¸° ì„¤ì • ë˜ëŠ” ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°(fixed feature extractor)ë¡œ ì‚¬ìš©í•œë‹¤.

### ì‹œë‚˜ë¦¬ì˜¤ 2ê°€ì§€
1. fine tuning - ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ìƒˆë¡œìš´ ë¬¸ì œì— ì ìš©í•˜ê¸° ìœ„í•´ ì¼ë¶€ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì ˆí•˜ëŠ” í•™ìŠµ ê³¼ì •
2. ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œì¨ì˜ í•©ì„±ê³± ì‹ ê²½ë§- ë§ˆì§€ë§‰ì— ì™„ì „íˆ ì—°ê²° ëœ ê³„ì¸µì„ ì œì™¸í•œ ëª¨ë“  ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •. ì´ ë§ˆì§€ë§‰ì˜ ì™„ì „íˆ ì—°ê²°ëœ ê³„ì¸µì€ ìƒˆë¡œìš´ ë¬´ì‘ìœ„ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°–ëŠ” ê³„ì¸µìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ ì´ ê³„ì¸µë§Œ í•™ìŠµ.

### ì¤‘ìš”í•œ ì½”ë“œ ì •ë¦¬ 
#### í•©ì„±ê³± ì‹ ê²½ë§ ë¯¸ì„¸ì¡°ì •(finetuning)
```
model_ft = models.resnet18(pretrained=True)
num_ftrs = model_ft.fc.in_features
# ì—¬ê¸°ì„œ ê° ì¶œë ¥ ìƒ˜í”Œì˜ í¬ê¸°ëŠ” 2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
# ë˜ëŠ”, nn.Linear(num_ftrs, len (class_names))ë¡œ ì¼ë°˜í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë“¤ì´ ìµœì í™”ë˜ì—ˆëŠ”ì§€ ê´€ì°°
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# 7 ì—í­ë§ˆë‹¤ 0.1ì”© í•™ìŠµë¥  ê°ì†Œ
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# í•™ìŠµ ë° í‰ê°€
model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)
```
#### ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œì¨ì˜ í•©ì„±ê³± ì‹ ê²½ë§
```
model_conv = torchvision.models.resnet18(pretrained=True)
for param in model_conv.parameters():
    param.requires_grad = False

# ìƒˆë¡œ ìƒì„±ëœ ëª¨ë“ˆì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ê¸°ë³¸ê°’ì´ requires_grad=True ì„
num_ftrs = model_conv.fc.in_features
model_conv.fc = nn.Linear(num_ftrs, 2)

model_conv = model_conv.to(device)

criterion = nn.CrossEntropyLoss()

# ì´ì „ê³¼ëŠ” ë‹¤ë¥´ê²Œ ë§ˆì§€ë§‰ ê³„ì¸µì˜ ë§¤ê°œë³€ìˆ˜ë“¤ë§Œ ìµœì í™”ë˜ëŠ”ì§€ ê´€ì°°
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)

# 7 ì—í­ë§ˆë‹¤ 0.1ì”© í•™ìŠµë¥  ê°ì†Œ
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

# í•™ìŠµ ë° í‰ê°€ 
model_conv = train_model(model_conv, criterion, optimizer_conv,
                         exp_lr_scheduler, num_epochs=25)

```
