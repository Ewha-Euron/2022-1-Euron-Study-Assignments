{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowionlyseedaylight/2022-1-Euron-Study-Assignments/blob/Week_6/week5_nlp_hw_%EA%B9%80%EB%82%98%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUHfXkPAORh"
      },
      "source": [
        "üìå week5 ÎÇ¥Ïö© Ï£ºÏ∞®Ïóê Ìï¥ÎãπÎêòÎäî Í≥ºÏ†úÎäî 3Ï£ºÏ∞®Ïùò Glove Î™®Îç∏ Ïã§Ïäµ, 4Ï£ºÏ∞®Ïùò NER task Ïã§Ïäµ, 5Ï£ºÏ∞®Ïùò Dependency Parsing task Ïã§ÏäµÏúºÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÏäµÎãàÎã§. (**Ï∞∏Í≥†** : Ï†úÏ∂úÏùÄ week6 branch Î≥µÏäµÍ≥ºÏ†úÎ°ú!) \n",
        "\n",
        "üìå ÏúÑÌÇ§ÎèÖÏä§Ïùò Îî•Îü¨ÎãùÏùÑ Ïù¥Ïö©Ìïú ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÏûÖÎ¨∏ ÍµêÏû¨ Ïã§Ïäµ, Ï∫êÍ∏Ä ÎÖ∏Ìä∏Î∂Å Îì±Ïùò ÏûêÎ£åÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ÏûàÎäî Í≥ºÏ†úÏûÖÎãàÎã§. \n",
        "\n",
        "üìå ÏïàÎÇ¥Îêú ÎßÅÌÅ¨Ïóê ÎßûÏ∂îÏñ¥ **ÏßÅÏ†ë ÏΩîÎìúÎ•º Îî∞Îùº ÏπòÎ©¥ÏÑú (ÌïÑÏÇ¨)** Ìï¥Îãπ nlp task Ïùò Í∏∞Î≥∏Ï†ÅÏù∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ÏôÄ Î©îÏÑúÎìúÎ•º ÏàôÏßÄÌï¥Î≥¥ÏãúÎ©¥ Ï¢ãÏùÑ Í≤É Í∞ôÏäµÎãàÎã§üòä ÌïÑÏàòÎùºÍ≥† Ï≤¥ÌÅ¨Ìïú Î∂ÄÎ∂ÑÏùÄ Í≥ºÏ†úÏóê Î∞òÎìúÏãú Ìè¨Ìï®ÏãúÏºúÏ£ºÏãúÍ≥†, ÏÑ†ÌÉùÏúºÎ°ú Ï≤¥ÌÅ¨Ìïú Î∂ÄÎ∂ÑÏùÄ ÏûêÏú®Ï†ÅÏúºÎ°ú Ïä§ÌÑ∞Îîî ÌïòÏãúÎ©¥ Îê©ÎãàÎã§.\n",
        "\n",
        "üìå Í∂ÅÍ∏àÌïú ÏÇ¨Ìï≠ÏùÄ ÍπÉÌóàÎ∏å Ïù¥ÏäàÎÇò, Ïπ¥ÌÜ°Î∞©, ÏÑ∏ÏÖò Î∞úÌëú ÏãúÏûë Ïù¥Ï†Ñ ÏãúÍ∞Ñ Îì±ÏùÑ ÌôúÏö©ÌïòÏó¨ ÏûêÏú†Î°≠Í≤å Í≥µÏú†Ìï¥Ï£ºÏÑ∏Ïöî!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjTSbcxBB6o",
        "outputId": "b6010e82-c453-46fd-cc27-00e817287a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk colab ÌôòÍ≤ΩÏóêÏÑú Ïã§ÌñâÏãú ÌïÑÏöîÌïú ÏΩîÎìúÏûÖÎãàÎã§. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPZn15zBHIv"
      },
      "source": [
        "### 1Ô∏è‚É£ **Glove**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11biHcUuBaH"
      },
      "source": [
        "üëÄ **ÎÇ¥Ïö© Î≥µÏäµ** \n",
        "* Ïä§ÌÉ†Ìè¨Îìú ÎåÄÌïôÏóêÏÑú Í∞úÎ∞úÌïú Ïπ¥Ïö¥Ìä∏ Í∏∞Î∞òÍ≥º ÏòàÏ∏° Í∏∞Î∞òÏùÑ Î™®Îëê ÏÇ¨Ïö©ÌïòÎäî Îã®Ïñ¥ ÏûÑÎ≤†Îî© Î∞©Î≤ïÎ°† \n",
        "* word2vec Ïùò Îã®Ï†êÏùÑ Î≥¥ÏôÑÌï¥ÏÑú ÎÇòÏò® Î™®Îç∏ \n",
        "* glove model Ïùò **input ÏùÄ Î∞òÎìúÏãú ÎèôÏãúÎì±Ïû•ÌñâÎ†¨ ÌòïÌÉú**Ïó¨Ïïº ÌïúÎã§ ‚≠ê\n",
        "\n",
        "![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ü§î ÌïúÍµ≠Ïñ¥ ÏòàÏ†úÎäî ÏóÜÎäî Í≤É Í∞ôÏäµÎãàÎã§. ÎÖºÎ¨∏ÏóêÏÑúÎäî k-Glove Î°ú ÏÜåÍ∞úÎêòÎäî Ïó∞Íµ¨Í∞Ä ÏûàÍ∏¥ ÌïúÎç∞, Ï¢Ä Îçî ÏïåÏïÑÎ¥êÏïº Ìï† Í≤É Í∞ôÏïÑÏöî!\n",
        "\n",
        "‚ûï [ÎÖºÎ¨∏1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n",
        "\n",
        "\n",
        "‚ûï[ÎÖºÎ¨∏2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asGcGy6fBM1E"
      },
      "source": [
        "üîπ **1-(1)** glove python\n",
        "\n",
        "* [Ïã§Ïäµ : basic code](https://wikidocs.net/22885) üëâ ÌïÑÏàò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31NoJdu5t3p",
        "outputId": "e7b0b776-e486-40ac-c3a3-18b6d8ad0d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glove_python_binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñç                               | 10 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |‚ñä                               | 20 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà                               | 30 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñç                              | 40 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñä                              | 51 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà                              | 61 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñç                             | 71 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñä                             | 81 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà                             | 92 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñå                            | 102 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñâ                            | 112 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñè                           | 122 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñå                           | 133 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 143 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 153 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 163 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 174 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 184 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 194 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 204 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 215 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 225 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 235 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 245 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 256 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 266 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 276 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 286 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 296 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 307 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 317 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 327 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 337 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 348 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 358 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 368 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 378 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 389 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 399 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 409 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 419 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 430 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 440 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 450 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 460 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 471 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 481 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 491 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 501 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 512 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 522 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 532 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 542 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 552 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 563 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 573 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 583 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 593 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 604 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 614 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 624 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 634 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 645 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 655 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 665 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 675 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 686 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 696 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 706 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 716 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 727 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 737 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 747 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 757 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 768 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 778 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 788 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 798 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 808 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 819 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 829 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 839 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 849 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 860 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 870 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 880 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 890 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 901 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 911 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 921 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 931 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 942 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 948 kB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.5)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install glove_python_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "QPO6M4vQ3ddt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRjk-wy-3vNp",
        "outputId": "c9026f2c-e687-424a-f97c-1638f8b64b95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7f3383548050>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml ÌååÏùºÎ°úÎ∂ÄÌÑ∞ <content>ÏôÄ </content> ÏÇ¨Ïù¥Ïùò ÎÇ¥Ïö©Îßå Í∞ÄÏ†∏Ïò®Îã§.\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# Ï†ïÍ∑ú ÌëúÌòÑÏãùÏùò sub Î™®ÎìàÏùÑ ÌÜµÌï¥ content Ï§ëÍ∞ÑÏóê Îì±Ïû•ÌïòÎäî (Audio), (Laughter) Îì±Ïùò Î∞∞Í≤ΩÏùå Î∂ÄÎ∂ÑÏùÑ Ï†úÍ±∞.\n",
        "# Ìï¥Îãπ ÏΩîÎìúÎäî Í¥ÑÌò∏Î°ú Íµ¨ÏÑ±Îêú ÎÇ¥Ïö©ÏùÑ Ï†úÍ±∞.\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# ÏûÖÎ†• ÏΩîÌçºÏä§Ïóê ÎåÄÌï¥ÏÑú NLTKÎ•º Ïù¥Ïö©ÌïòÏó¨ Î¨∏Ïû• ÌÜ†ÌÅ∞ÌôîÎ•º ÏàòÌñâ.\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# Í∞Å Î¨∏Ïû•Ïóê ÎåÄÌï¥ÏÑú Íµ¨ÎëêÏ†êÏùÑ Ï†úÍ±∞ÌïòÍ≥†, ÎåÄÎ¨∏ÏûêÎ•º ÏÜåÎ¨∏ÏûêÎ°ú Î≥ÄÌôò.\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# Í∞Å Î¨∏Ïû•Ïóê ÎåÄÌï¥ÏÑú NLTKÎ•º Ïù¥Ïö©ÌïòÏó¨ Îã®Ïñ¥ ÌÜ†ÌÅ∞ÌôîÎ•º ÏàòÌñâ.\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "metadata": {
        "id": "YKqiLpzm3yut"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ta6QgoKO5uXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668c2833-2759-448c-fc83-c87babd75a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 20 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n"
          ]
        }
      ],
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus() \n",
        "\n",
        "# ÌõàÎ†® Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ GloVeÏóêÏÑú ÏÇ¨Ïö©Ìï† ÎèôÏãú Îì±Ïû• ÌñâÎ†¨ ÏÉùÏÑ±\n",
        "corpus.fit(result, window=5)\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "\n",
        "# ÌïôÏäµÏóê Ïù¥Ïö©Ìï† Ïì∞Î†àÎìúÏùò Í∞úÏàòÎäî 4Î°ú ÏÑ§Ï†ï, ÏóêÌè¨ÌÅ¨Îäî 20.\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"man\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etrrv4zq4UGt",
        "outputId": "e046382f-b288-49e1-dc1f-063539bde452"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.9581033418704747), ('guy', 0.8818607431986919), ('young', 0.8444182670659356), ('girl', 0.8442028051297421)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"boy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_PFrKAL4Uir",
        "outputId": "72ab2df7-818f-4bc4-d162-f160bde5dd1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('girl', 0.9368075825658816), ('kid', 0.8377182024137665), ('lady', 0.8342948176270489), ('woman', 0.8107560914816183)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"university\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP25wle24WSL",
        "outputId": "aed465fe-1598-4478-83b2-556601330750"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('harvard', 0.8802987471886451), ('mit', 0.8503521960472746), ('cambridge', 0.8394960743801057), ('stanford', 0.8351756258102443)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"water\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UBs0Itc4X01",
        "outputId": "6e816393-790b-4570-f3ab-6ab5d1852496"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fresh', 0.8298173482630411), ('clean', 0.8232735212597403), ('air', 0.821438756628592), ('electricity', 0.8172628506518693)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"physics\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgMUFwGK4ZUb",
        "outputId": "8c3c19ce-ce3b-483a-9e0a-311fc9fb30eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('economics', 0.8965688631239828), ('beauty', 0.8901367203054608), ('chemistry', 0.8848410860087903), ('mathematics', 0.8567844440815366)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"muscle\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EKRoFxK4a75",
        "outputId": "59f3a374-42bf-4fd7-9fcc-41358417efd4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tissue', 0.8377493144796648), ('nerve', 0.8166217591937872), ('bone', 0.7764990615554421), ('channel', 0.75458661962369)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"clean\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFDmJwYD4cZZ",
        "outputId": "0d90057b-918b-45e5-befe-01ab8535e6b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('water', 0.8232735212597403), ('wind', 0.8127588239904695), ('fresh', 0.8070736049466734), ('heat', 0.7967777191492716)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ADfVM9lO9NE"
      },
      "source": [
        "üîπ **1-(2)** pre-trained glove \n",
        "\n",
        "* **ÏÇ¨Ï†ÑÌïôÏäµÎ™®Îç∏** : ÏûÑÏùòÏùò Í∞íÏúºÎ°ú Ï¥àÍ∏∞ÌôîÌïòÎçò Î™®Îç∏Ïùò Í∞ÄÏ§ëÏπòÎì§ÏùÑ Îã§Î•∏ Î¨∏Ï†úÏóê ÌïôÏäµÏãúÌÇ® Í∞ÄÏ§ëÏπòÎì§Î°ú Ï¥àÍ∏∞ÌôîÌïòÎäî Î∞©Î≤ïÏù¥Îã§.ÏÇ¨Ï†Ñ ÌïôÏäµÌïú Í∞ÄÏ§ëÏπòÎ•º ÌôúÏö©Ìï¥ ÌïôÏäµÌïòÍ≥†Ïûê ÌïòÎäî Î≥∏Îûò Î¨∏Ï†úÎ•º ÌïòÏúÑÎ¨∏Ï†úÎùºÍ≥† ÌïúÎã§. \n",
        "\n",
        "* [Ïã§Ïäµ : Î¨∏Ïû•Ïùò Í∏çÎ∂ÄÏ†ïÏùÑ ÌåêÎã®ÌïòÎäî Í∞êÏÑ± Î∂ÑÎ•ò Î™®Îç∏ ÎßåÎì§Í∏∞](https://wikidocs.net/33793) üëâ ÌïÑÏàò\n",
        "  * [ÏÑ§Î™ÖÏ∞∏Í≥†](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n",
        "* pre-trained data Î•º Í∞ÄÏ†∏Ïò§ÎäîÎç∞ ÏãúÍ∞ÑÏù¥ Ïò§ÎûòÍ±∏Î¶º\n",
        "* kaggle ÎåÄÌöåÏóêÏÑú Ï£ºÎ°ú Ïù¥ Î∞©ÏãùÏùÑ ÎßéÏù¥ ÏÇ¨Ïö©Ìï®\n",
        "  * [Ï∞∏Í≥†](https://lsjsj92.tistory.com/455)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "IDIP3hPk4pw8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # Ìå®Îî©ÏùÑ Í≥†Î†§ÌïòÏó¨ +1\n",
        "print('Îã®Ïñ¥ ÏßëÌï© :',vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__e-0Llg4rqq",
        "outputId": "a033d524-62fc-4663-a365-2332c98757cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Îã®Ïñ¥ ÏßëÌï© : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print('Ï†ïÏàò Ïù∏ÏΩîÎî© Í≤∞Í≥º :',X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KlCPYUR4ur7",
        "outputId": "5cba45ee-9a0d-482e-cc7f-3613a00b81a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ï†ïÏàò Ïù∏ÏΩîÎî© Í≤∞Í≥º : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('ÏµúÎåÄ Í∏∏Ïù¥ :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUvgtLON4wlb",
        "outputId": "a1e1dcbb-024f-4462-cac1-2f82d7c2061f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏµúÎåÄ Í∏∏Ïù¥ : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_train = np.array(y_train)\n",
        "print('Ìå®Îî© Í≤∞Í≥º :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzEMm4MR4yJM",
        "outputId": "89401ecc-ec3f-4c80-c0a2-9f0469e3c643"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ìå®Îî© Í≤∞Í≥º :\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "embedding_dim = 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGPCilK24z19",
        "outputId": "844ca141-f8cd-46b0-db42-59f3c74276b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 1s - loss: 0.6885 - acc: 0.5714 - 703ms/epoch - 703ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 0.6871 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 0.6858 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 0.6845 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 0.6831 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.6818 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.6804 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.6791 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.6778 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.6764 - acc: 0.7143 - 3ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.6751 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.6737 - acc: 0.7143 - 3ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.6724 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.6710 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.6697 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.6683 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.6670 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.6656 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.6643 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.6629 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.6615 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.6601 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.6588 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.6574 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.6560 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.6546 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.6532 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.6517 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.6503 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.6489 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.6474 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.6460 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.6445 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.6431 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.6416 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.6401 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.6386 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.6371 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.6356 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.6341 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.6325 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.6310 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.6294 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.6279 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.6263 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.6247 - acc: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.6231 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.6215 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.6199 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.6183 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.6166 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.6150 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.6133 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.6117 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.6100 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.6083 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.6066 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.6049 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.6032 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.6014 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.5997 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.5979 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.5962 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.5944 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.5926 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.5908 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.5890 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.5872 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.5854 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.5836 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.5817 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.5799 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.5780 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.5762 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.5743 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.5724 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.5705 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.5686 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.5667 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.5648 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.5629 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.5609 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.5590 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.5570 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.5551 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.5531 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.5511 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.5491 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.5471 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.5451 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.5431 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.5411 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.5391 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.5371 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.5351 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.5330 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.5310 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.5289 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.5269 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.5248 - acc: 1.0000 - 3ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f32f1b1f350>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnaSi31y41lw",
        "outputId": "8ecbe84f-8ccd-4c13-8ebb-a6bc0aa77464"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsCLcdE425I",
        "outputId": "3f6789b2-2683-49cf-cf5c-7b10d23901fc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve, urlopen\n",
        "import gzip\n",
        "import zipfile\n",
        "\n",
        "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
        "zf = zipfile.ZipFile('glove.6B.zip')\n",
        "zf.extractall() \n",
        "zf.close()"
      ],
      "metadata": {
        "id": "v6lDXi2N44Pk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dict = dict()\n",
        "\n",
        "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "\n",
        "    # 100Í∞úÏùò Í∞íÏùÑ Í∞ÄÏßÄÎäî arrayÎ°ú Î≥ÄÌôò\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%sÍ∞úÏùò Embedding vectorÍ∞Ä ÏûàÏäµÎãàÎã§.' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1oLreMj46KO",
        "outputId": "e5e62492-cb1b-4377-c755-a4f262548e66"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000Í∞úÏùò Embedding vectorÍ∞Ä ÏûàÏäµÎãàÎã§.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print('Î≤°ÌÑ∞Ïùò Ï∞®Ïõê Ïàò :',len(embedding_dict['respectable']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dcI29tj4716",
        "outputId": "65e99d84-3058-4f3e-e3f0-d9af4fd77d57"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "Î≤°ÌÑ∞Ïùò Ï∞®Ïõê Ïàò : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('ÏûÑÎ≤†Îî© ÌñâÎ†¨Ïùò ÌÅ¨Í∏∞(shape) :',np.shape(embedding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgsGNU-f49WO",
        "outputId": "2bb105ab-9172-42d0-8c58-96aead9d8dae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏûÑÎ≤†Îî© ÌñâÎ†¨Ïùò ÌÅ¨Í∏∞(shape) : (16, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Jht8-L4-jY",
        "outputId": "16a2806b-04ca-48de-a150-ee7e8547bb15"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Îã®Ïñ¥ greatÏùò ÎßµÌïëÎêú Ï†ïÏàò :',tokenizer.word_index['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAw1FKiv4_6t",
        "outputId": "a79ee93a-c05d-4751-8b31-21a419c245f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Îã®Ïñ¥ greatÏùò ÎßµÌïëÎêú Ï†ïÏàò : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO-04D025BTF",
        "outputId": "3c6c430e-4a96-407a-ee06-e26145226393"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.013786   0.38216    0.53236    0.15261   -0.29694   -0.20558\n",
            " -0.41846   -0.58437   -0.77355   -0.87866   -0.37858   -0.18516\n",
            " -0.128     -0.20584   -0.22925   -0.42599    0.3725     0.26077\n",
            " -1.0702     0.62916   -0.091469   0.70348   -0.4973    -0.77691\n",
            "  0.66045    0.09465   -0.44893    0.018917   0.33146   -0.35022\n",
            " -0.35789    0.030313   0.22253   -0.23236   -0.19719   -0.0053125\n",
            " -0.25848    0.58081   -0.10705   -0.17845   -0.16206    0.087086\n",
            "  0.63029   -0.76649    0.51619    0.14073    1.019     -0.43136\n",
            "  0.46138   -0.43585   -0.47568    0.19226    0.36065    0.78987\n",
            "  0.088945  -2.7814    -0.15366    0.01015    1.1798     0.15168\n",
            " -0.050112   1.2626    -0.77527    0.36031    0.95761   -0.11385\n",
            "  0.28035   -0.02591    0.31246   -0.15424    0.3778    -0.13599\n",
            "  0.2946    -0.31579    0.42943    0.086969   0.019169  -0.27242\n",
            " -0.31696    0.37327    0.61997    0.13889    0.17188    0.30363\n",
            " -1.2776     0.044423  -0.52736   -0.88536   -0.19428   -0.61947\n",
            " -0.10146   -0.26301   -0.061707   0.36627   -0.95223   -0.39346\n",
            " -0.69183   -1.0426     0.28855    0.63056  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # Îã®Ïñ¥ÏôÄ ÎßµÌïëÎêòÎäî ÏÇ¨Ï†Ñ ÌõàÎ†®Îêú ÏûÑÎ≤†Îî© Î≤°ÌÑ∞Í∞í\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ],
      "metadata": {
        "id": "20AjaqLi5C07"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHWBfh0i5EOB",
        "outputId": "3ff10e22-c800-4d47-dd7e-2e1b5a2317dc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.013786  ,  0.38216001,  0.53236002,  0.15261   , -0.29694   ,\n",
              "       -0.20558   , -0.41846001, -0.58437002, -0.77354997, -0.87866002,\n",
              "       -0.37858   , -0.18516   , -0.12800001, -0.20584001, -0.22925   ,\n",
              "       -0.42598999,  0.3725    ,  0.26076999, -1.07019997,  0.62915999,\n",
              "       -0.091469  ,  0.70348001, -0.4973    , -0.77691001,  0.66044998,\n",
              "        0.09465   , -0.44893   ,  0.018917  ,  0.33146   , -0.35021999,\n",
              "       -0.35789001,  0.030313  ,  0.22253001, -0.23236001, -0.19719   ,\n",
              "       -0.0053125 , -0.25848001,  0.58081001, -0.10705   , -0.17845   ,\n",
              "       -0.16205999,  0.087086  ,  0.63028997, -0.76648998,  0.51618999,\n",
              "        0.14072999,  1.01900005, -0.43136001,  0.46138   , -0.43584999,\n",
              "       -0.47567999,  0.19226   ,  0.36065   ,  0.78987002,  0.088945  ,\n",
              "       -2.78139997, -0.15366   ,  0.01015   ,  1.17980003,  0.15167999,\n",
              "       -0.050112  ,  1.26259995, -0.77526999,  0.36030999,  0.95761001,\n",
              "       -0.11385   ,  0.28035   , -0.02591   ,  0.31246001, -0.15424   ,\n",
              "        0.37779999, -0.13598999,  0.29460001, -0.31579   ,  0.42943001,\n",
              "        0.086969  ,  0.019169  , -0.27241999, -0.31696001,  0.37327   ,\n",
              "        0.61997002,  0.13889   ,  0.17188001,  0.30362999, -1.27760005,\n",
              "        0.044423  , -0.52736002, -0.88536   , -0.19428   , -0.61947   ,\n",
              "       -0.10146   , -0.26301   , -0.061707  ,  0.36627001, -0.95222998,\n",
              "       -0.39346001, -0.69182998, -1.04260004,  0.28854999,  0.63055998])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "output_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryB3Yenr5F1H",
        "outputId": "47f97a57-57df-43a5-8487-3b66cf32406f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 0s - loss: 0.7064 - acc: 0.4286 - 472ms/epoch - 472ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 0.6875 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 0.6692 - acc: 0.7143 - 7ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 0.6516 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 0.6346 - acc: 0.7143 - 6ms/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.6181 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.6022 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.5869 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.5721 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.5577 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.5439 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.5304 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.5174 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.5048 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.4925 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.4806 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.4691 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.4578 - acc: 0.8571 - 7ms/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.4469 - acc: 0.8571 - 7ms/epoch - 7ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.4363 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.4260 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.4160 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.4063 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.3968 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.3876 - acc: 0.8571 - 7ms/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.3787 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.3700 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.3615 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.3533 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.3453 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.3375 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.3300 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.3226 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.3155 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.3086 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.3018 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.2953 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.2889 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.2827 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.2767 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.2709 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.2652 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.2597 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.2544 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.2492 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.2441 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.2392 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.2345 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.2298 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.2253 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.2210 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.2167 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.2126 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.2086 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.2047 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.2009 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.1972 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.1936 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.1901 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.1867 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.1834 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.1801 - acc: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.1770 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.1740 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.1710 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.1681 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.1653 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.1625 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.1598 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.1572 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.1547 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.1522 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.1498 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.1474 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.1451 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.1429 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.1407 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.1385 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.1364 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.1344 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.1324 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.1305 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.1286 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.1267 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.1249 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.1231 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.1214 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.1197 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.1180 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.1164 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.1148 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.1133 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.1118 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.1103 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.1088 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.1074 - acc: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.1060 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.1046 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.1033 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.1020 - acc: 1.0000 - 7ms/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f32eb1c7d50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \\\n",
        "                           filename=\"GoogleNews-vectors-negative300.bin.gz\")\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "print('Î™®Îç∏Ïùò ÌÅ¨Í∏∞(shape) :',word2vec_model.vectors.shape) # Î™®Îç∏Ïùò ÌÅ¨Í∏∞ ÌôïÏù∏"
      ],
      "metadata": {
        "id": "sgV9OdPB5HQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "print('ÏûÑÎ≤†Îî© ÌñâÎ†¨Ïùò ÌÅ¨Í∏∞(shape) :',np.shape(embedding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aCTWKiX5I7k",
        "outputId": "9b952dba-64ca-46d0-b792-a93896f5550d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏûÑÎ≤†Îî© ÌñâÎ†¨Ïùò ÌÅ¨Í∏∞(shape) : (16, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "ip1Z4WvH5LIf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # Îã®Ïñ¥ÏôÄ ÎßµÌïëÎêòÎäî ÏÇ¨Ï†Ñ ÌõàÎ†®Îêú ÏûÑÎ≤†Îî© Î≤°ÌÑ∞Í∞í\n",
        "    vector_value = get_vector(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ],
      "metadata": {
        "id": "yoidY3035L3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2vec_model['nice'])"
      ],
      "metadata": {
        "id": "V_9kn0eB5Oei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Îã®Ïñ¥ niceÏùò ÎßµÌïëÎêú Ï†ïÏàò :', tokenizer.word_index['nice'])"
      ],
      "metadata": {
        "id": "CemcC53Z5O7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix[1])"
      ],
      "metadata": {
        "id": "7pCJadPG5R6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(max_len,), dtype='int32'))\n",
        "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWZsBlpI5UUv",
        "outputId": "93b97a56-962c-4fde-f7c0-b2f530a4d0ab"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 0s - loss: 0.6931 - acc: 0.4286 - 430ms/epoch - 430ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 0.6931 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 0.6930 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 0.6929 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 0.6929 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.6928 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.6927 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.6927 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.6926 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.6925 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.6924 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.6924 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.6923 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.6922 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.6922 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.6921 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.6920 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.6920 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.6919 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.6918 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.6918 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.6917 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.6916 - acc: 0.5714 - 3ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.6916 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.6915 - acc: 0.5714 - 3ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.6915 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.6914 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.6913 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.6913 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.6912 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.6911 - acc: 0.5714 - 3ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.6911 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.6910 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.6909 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.6909 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.6908 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.6908 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.6907 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.6906 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.6906 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.6905 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.6905 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.6904 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.6904 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.6903 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.6902 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.6902 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.6901 - acc: 0.5714 - 12ms/epoch - 12ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.6901 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.6900 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.6900 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.6899 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.6898 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.6898 - acc: 0.5714 - 13ms/epoch - 13ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.6897 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.6897 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.6896 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.6896 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.6895 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.6895 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.6894 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.6894 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.6893 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.6893 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.6892 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.6892 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.6891 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.6891 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.6890 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.6890 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.6889 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.6889 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.6888 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.6888 - acc: 0.5714 - 10ms/epoch - 10ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.6887 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.6887 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.6886 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.6886 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.6885 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.6885 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.6884 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.6884 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.6883 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.6883 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.6882 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.6882 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.6882 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.6881 - acc: 0.5714 - 10ms/epoch - 10ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.6881 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.6880 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.6880 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.6879 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.6879 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.6879 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.6878 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.6878 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.6877 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.6877 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.6876 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.6876 - acc: 0.5714 - 5ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f32e8b4e910>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_wcrE5PtLMI"
      },
      "source": [
        "üîπ **1-(3)** fine tuning glove\n",
        "* ÎØ∏ÏÑ∏Ï°∞Ï†ï : ÏÇ¨Ï†Ñ ÌïôÏäµÌïú Î™®Îì† Í∞ÄÏ§ëÏπòÏôÄ ÎçîÎ∂àÏñ¥ ÌïòÏúÑ Î¨∏Ï†úÎ•º ÏúÑÌïú ÏµúÏÜåÌïúÏùò Í∞ÄÏ§ëÏπòÎ•º Ï∂îÍ∞ÄÌï¥ Î™®Îç∏ÏùÑ Ï∂îÍ∞ÄÎ°ú ÌïôÏäµÌïòÎäî Î∞©Î≤ïÏù¥Îã§. \n",
        "\n",
        "* fine tuning Ïù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞ \n",
        "  * pretrained model Ïóê Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÏûàÎäî Îã®Ïñ¥Í∞Ä Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ \n",
        "  * Îç∞Ïù¥ÌÑ∞ ÏßëÌï©Ïù¥ ÎÑàÎ¨¥ ÏûëÏïÑÏÑú Ï†ÑÏ≤¥ Î™®Îç∏ÏùÑ ÌõàÎ†®ÏãúÌÇ§Í∏∞ Ïñ¥Î†§Ïö¥ Í≤ΩÏö∞ \n",
        "\n",
        "* [Mittens ÎùºÏù¥Î∏åÎü¨Î¶¨Î°ú fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) üëâ ÌïÑÏàò\n",
        "  *  GloVe ÏûÑÎ≤†Îî©ÏùÑ fine-tuning ÌïòÍ∏∞ ÏúÑÌïú ÌååÏù¥Ïç¨ ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
        "  * [github](https://github.com/roamanalytics/mittens)\n",
        "\n",
        "* [ÌïúÍµ≠Ïñ¥ ÏÜåÏÑ§ ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÎØ∏ÏÑ∏Ï°∞Ï†ï Î™®Îç∏ ÌïôÏäµ - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) üëâ ÏÑ†ÌÉù (glove Î™®Îç∏ ÏòàÏ†úÎäî ÏïÑÎãôÎãàÎã§. fine-tuning Ïóê Ï¥àÏ†êÏùÑ ÎëêÏñ¥ÏÑú Ï∞∏Í≥†Ìï¥Ï£ºÏãúÎ©¥ Ï¢ãÏùÑ Í≤É Í∞ôÏäµÎãàÎã§.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mittens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x848mRYG9G9Y",
        "outputId": "42e567b2-0e15-421b-aa24-5fe72be66fe7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mittens\n",
            "  Downloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mittens) (1.21.5)\n",
            "Installing collected packages: mittens\n",
            "Successfully installed mittens-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYPbQWzO9jqT",
        "outputId": "5c7f7bdd-9566-4cd3-a382-db8ee6dfdf89"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown\n",
        "from mittens import GloVe, Mittens\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "6S7H7P4C8j7w"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "xDBDn64S58U5"
      },
      "outputs": [],
      "source": [
        "def glove2dict(glove_filename):\n",
        "    with open(glove_filename, encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, delimiter=' ',quoting=csv.QUOTE_NONE)\n",
        "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
        "                for line in reader}\n",
        "    return embed\n",
        "glove_path = \"glove.6B.50d.txt\"\n",
        "pre_glove = glove2dict(glove_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "sw = list(_stop_words.ENGLISH_STOP_WORDS)\n",
        "brown_data = brown.words()[:200000]\n",
        "brown_nonstop = [token.lower() for token in brown_data if (token.lower() not in sw)]\n",
        "oov = [token for token in brown_nonstop if token not in pre_glove.keys()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgB79bP68VgZ",
        "outputId": "6303fab6-7437-4889-9a1f-d8c664afcbe2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "FHiR5mN4577l"
      },
      "outputs": [],
      "source": [
        "def get_rareoov(xdict, val):\n",
        "    return [k for (k,v) in Counter(xdict).items() if v<=val]\n",
        "oov_rare = get_rareoov(oov, 1)\n",
        "corp_vocab = list(set(oov) - set(oov_rare))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown_tokens = [token for token in brown_nonstop if token not in oov_rare]\n",
        "brown_doc = [' '.join(brown_tokens)]\n",
        "corp_vocab = list(set(oov))"
      ],
      "metadata": {
        "id": "bpDAp3jq8YYj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n",
        "X = cv.fit_transform(brown_doc)\n",
        "Xc = (X.T * X)\n",
        "Xc.setdiag(0)\n",
        "coocc_ar = Xc.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pzGDS_x8ZcT",
        "outputId": "0bdf4bb6-e483-41f1-92f1-49215a98b954"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mittens_model = Mittens(n=50, max_iter=1000)\n",
        "new_embeddings = mittens_model.fit(\n",
        "    coocc_ar,\n",
        "    vocab=corp_vocab,\n",
        "    initial_embedding_dict= pre_glove)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_5uzVot8cB5",
        "outputId": "c9b64055-15d9-45c3-94cf-d48a87d0aeae"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/adagrad.py:139: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 1000: loss: 0.004322037100791931"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "GI6SuLRj-nxZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newglove = dict(zip(corp_vocab, new_embeddings))\n",
        "f = open(\"repo_glove.pkl\",\"wb\")\n",
        "pickle.dump(newglove, f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "vq6XqEiS8gLB"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-OB9Siga3G"
      },
      "source": [
        "* (Ï∞∏Í≥†) word2vec pretrained example\n",
        "\n",
        "‚ûï [word2vec ÏÇ¨Ï†ÑÌïôÏäµ Î™®Îç∏ -ÌïúÍµ≠Ïñ¥1](http://doc.mindscale.kr/km/unstructured/11.html)\n",
        "\n",
        "‚ûï [word2vec ÏÇ¨Ï†ÑÌïôÏäµ - ÌïúÍµ≠Ïñ¥2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUWWDwdiPLS9"
      },
      "source": [
        "### **2Ô∏è‚É£ NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N0B4VknPkTk"
      },
      "source": [
        "üëÄ **ÎÇ¥Ïö© Î≥µÏäµ** \n",
        "* Í∞úÏ≤¥Î™Ö Ïù∏ÏãùÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ ÏΩîÌçºÏä§Î°úÎ∂ÄÌÑ∞ Ïñ¥Îñ§ Îã®Ïñ¥Í∞Ä ÏÇ¨Îûå, Ïû•ÏÜå, Ï°∞ÏßÅ Îì±ÏùÑ ÏùòÎØ∏ÌïòÎäî Îã®Ïñ¥Ïù∏ÏßÄÎ•º Ï∞æÏùÑ Ïàò ÏûàÎã§. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgla1BuPRqJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "üîπ **2-(1)** NER task by nltk library\n",
        "\n",
        "\n",
        "* nltk ÏóêÏÑúÎäî Í∞úÏ≤¥Î™Ö Ïù∏ÏãùÍ∏∞ (NER chunker) Î•º ÏßÄÏõêÌïòÍ≥† ÏûàÎã§. \n",
        "* ne_chunk Îäî Í∞úÏ≤¥Î™ÖÏùÑ ÌÉúÍπÖÌïòÍ∏∞ ÏúÑÌï¥ÏÑú ÏïûÏÑú ÌíàÏÇ¨ ÌÉúÍπÖ pos_tag Í∞Ä ÏàòÌñâÎêòÏñ¥Ïïº ÌïúÎã§. \n",
        "\n",
        "\n",
        "üìå [basic code](https://wikidocs.net/30682) üëâ ÌïÑÏàò \n",
        "\n",
        "üìå [BIO ÌëúÌòÑ, LSTMÏùÑ ÌôúÏö©Ìïú NER Ïã§Ïäµ](https://wikidocs.net/24682) üëâ ÏÑ†ÌÉù\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "diaZweMyAxJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e964452-0040-4603-e702-86451ca01e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"James is working at Disney in London\"\n",
        "# ÌÜ†ÌÅ∞Ìôî ÌõÑ ÌíàÏÇ¨ ÌÉúÍπÖ\n",
        "tokenized_sentence = pos_tag(word_tokenize(sentence))\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "1k09tKha3Lgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d01dd1-0e69-448d-d32b-3abbed2186aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ],
      "source": [
        "# Í∞úÏ≤¥Î™Ö Ïù∏Ïãù\n",
        "ner_sentence = ne_chunk(tokenized_sentence)\n",
        "print(ner_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX-WtSvPmm6"
      },
      "source": [
        "üîπ **2-(2)** NER task by spacy library\n",
        "\n",
        "\n",
        "* spaCy Îäî ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨Î•º ÏúÑÌïú ÌååÏù¥Ïç¨ Í∏∞Î∞òÏùò Ïò§Ìîà ÏÜåÏä§ ÎùºÏù¥Î∏åÎü¨Î¶¨Î°ú Îã§ÏùåÍ≥º Í∞ôÏùÄ Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌïúÎã§. \n",
        "  * Tokenization \n",
        "  * POS tagging \n",
        "  * Lemmatization \n",
        "  * Sentence Boundary Detection (SBD)\n",
        "  * Named Entity Recognition (NER)\n",
        "  * Similarity\n",
        "  * Text Classification\n",
        "  * Rule-based Matching\n",
        "  * Training\n",
        "  * Serialization\n",
        "\n",
        "* spaCy ÏôÄ NER\n",
        "  * .ents ‚Üí .label_\n",
        "\n",
        "\n",
        "üìå [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) üëâ ÌïÑÏàò (NER Î∂ÄÎ∂ÑÎßå)\n",
        "\n",
        "üìå [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) üëâ ÏÑ†ÌÉù\n",
        "\n",
        "  * ÌõàÎ†®ÎêòÏßÄ ÏïäÏùÄ Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏Ïóê Î™ÖÎ™ÖÎêú ÏóîÌã∞Ìã∞Î•º ÌïôÏäµÌïòÎäî Î∞©Î≤ï : Ïù¥Î†•ÏÑú pdf Îç∞Ïù¥ÌÑ∞ ÌôúÏö© \n",
        "  * manually labelled \n",
        "\n",
        "üìå [ÌïúÍµ≠Ïñ¥ NER](https://github.com/monologg/KoBERT-NER) üëâ Ï∞∏Í≥†ÌïòÎ©¥ Ï¢ãÏùÑ ÏûêÎ£å\n",
        "\n",
        "‚ûï [Ï∞∏Í≥†](http://aispiration.com/nlp2/nlp-ner-python.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "WXjRfz-qP0Xx"
      },
      "outputs": [],
      "source": [
        "#conda install -c conda-forge spacy\n",
        "#python -m spacy download en\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaNkTMlL_Vku",
        "outputId": "cf8684e1-7a55-43a2-ceba-a7d7397646a0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"\"\"But Google is starting from behind. The company made a late push\n",
        "into hardware, and Apple‚Äôs Siri, available on iPhones, and Amazon‚Äôs Alexa\n",
        "software, which runs on its Echo and Dot devices, have clear leads in\n",
        "consumer adoption.\"\"\".replace(\"\\n\", \" \").strip())\n",
        "\n",
        "## ÏïÑÎûòÏ≤òÎüº Î¨¥ÏóáÏù¥ organizationÏù¥Í≥†, Î¨¥ÏóáÏù¥ productÏù∏ÏßÄ, ÍΩ§ Ïûò Íµ¨Î≥ÑÌï¥Ï£ºÏßÄÎßå, \n",
        "## echo, dot Îì±Ïóê ÎåÄÌï¥ÏÑúÎäî Ï†ïÌôïÌïòÏßÄ Î™ªÌïòÎã§. \n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNAhr6ba_tbz",
        "outputId": "0d7fae2c-c53d-4274-b5ef-310d4162795d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google ORG\n",
            "Apple ORG\n",
            "Siri PRODUCT\n",
            "Amazon ORG\n",
            "Alexa ORG\n",
            "Echo PRODUCT\n",
            "Dot PRODUCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008-V5QsQG25"
      },
      "source": [
        "###**3Ô∏è‚É£ Dependency Parsing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfcodHQQPlt"
      },
      "source": [
        "üëÄ **ÎÇ¥Ïö© Î≥µÏäµ** \n",
        "* Î¨∏Ïû•Ïùò Ï†ÑÏ≤¥Ï†ÅÏù∏ Íµ¨ÏÑ±/Íµ¨Ï°∞ Î≥¥Îã§Îäî Í∞Å Í∞úÎ≥ÑÎã®Ïñ¥ Í∞ÑÏùò 'ÏùòÏ°¥Í¥ÄÍ≥Ñ' ÎòêÎäî 'ÏàòÏãùÍ¥ÄÍ≥Ñ' ÏôÄ Í∞ôÏùÄ Îã®Ïñ¥Í∞Ñ Í¥ÄÍ≥ÑÎ•º ÌååÏïÖÌïòÎäî Í≤ÉÏù¥ Î™©Ï†ÅÏù∏ NLP Task\n",
        "* Î¨∏Ïû• Ìï¥ÏÑùÏùò Î™®Ìò∏ÏÑ±ÏùÑ ÏóÜÏï†Í∏∞ ÏúÑÌï¥ Parsing ÏùÑ ÌïúÎã§."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJLAzZnbRNlL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "üîπ **3-(1)** Dependency Parsing by spacy library\n",
        "\n",
        "\n",
        "* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) üëâ dependecy parsing Î∂ÄÎ∂ÑÎßå ÌïÑÏàò\n",
        "* .dep_ Î©îÏÑúÎìú\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "HbQEYt76bJXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c8c5ba-dc13-4bc9-89d0-9cdeb7ae48ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'generator'>\n",
            "<class 'spacy.tokens.span.Span'>\n",
            "<class 'spacy.tokens.token.Token'>\n",
            "============================================================\n",
            "Text: The original noun chunk text.\n",
            "Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
            "Root dep: Dependency relation connecting the root to its head.\n",
            "Root head text: The text of the root token's head.\n",
            "============================================================\n",
            "          Autonomous cars                     cars                    nsubj                    shift\n",
            "      insurance liability                liability                     dobj                    shift\n",
            "            manufacturers            manufacturers                     pobj                   toward\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "\n",
        "## ÌäπÏ†ï ÌÖçÏä§Ìä∏Î•º nlpÏóê ÎÑòÍ∏∞Î©¥ Î™®Îëê Ìï¥Í≤∞ÎêòÍ∏∞Îäî ÌïòÎäîÎç∞, \n",
        "## noun_chunksÏùò Í≤ΩÏö∞Îäî token ÌÅ¥ÎûòÏä§ÎèÑ ÏïÑÎãàÍ≥†, Doc ÌÅ¥ÎûòÏä§ÎèÑ ÏïÑÎãàÎã§. \n",
        "## SpanÏù¥ÎùºÎäî ÌÅ¥ÎûòÏä§Îäî Í∑∏ÎÉ• DocÏôÄ ÎπÑÏä∑ÌïòÎã§Í≥† ÏÉùÍ∞ÅÌïòÎ©¥ ÎêúÎã§, ÏùºÏ¢ÖÏùò Î≥µÌï©Ïñ¥ Í∞úÎÖê.\n",
        "noun_chunks = doc.noun_chunks\n",
        "print(type(noun_chunks))\n",
        "noun_chunk = list(noun_chunks)[0]\n",
        "print(type(noun_chunk))\n",
        "token = noun_chunk[0]\n",
        "print(type(token))\n",
        "\n",
        "print(\"==\"*30)\n",
        "print(\"\"\"\n",
        "Text: The original noun chunk text.\n",
        "Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
        "Root dep: Dependency relation connecting the root to its head.\n",
        "Root head text: The text of the root token's head.\n",
        "\"\"\".strip())\n",
        "print(\"==\"*30)\n",
        "str_format = \"{:>25}\"*4\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(str_format.format(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "W9QAEsrLAxHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42557b83-df5d-43b1-894b-796506e4247d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomous\n",
            "children: [] head: cars\n",
            "================================\n",
            "cars\n",
            "children: [Autonomous] head: shift\n",
            "================================\n",
            "shift\n",
            "children: [cars, liability] head: !this is root node\n",
            "================================\n",
            "insurance\n",
            "children: [] head: liability\n",
            "================================\n",
            "liability\n",
            "children: [insurance, toward] head: shift\n",
            "================================\n",
            "toward\n",
            "children: [manufacturers] head: liability\n",
            "================================\n",
            "manufacturers\n",
            "children: [] head: toward\n",
            "================================\n"
          ]
        }
      ],
      "source": [
        "## navigiting parse tree\n",
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "for tok in doc:\n",
        "    print(tok.text)\n",
        "    children = list(tok.children)\n",
        "    print('children:', children, 'head:', tok.head if tok.head != tok else \"!this is root node\")\n",
        "    print(\"==\"*16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "nG = nx.Graph()\n",
        "doc[2] ## root node\n",
        "\n",
        "def add_n_to_g(inputG, tok):\n",
        "    inputG.add_node(tok)\n",
        "    children = list(tok.children)\n",
        "    if children != []:\n",
        "        inputG.add_nodes_from(children)\n",
        "        for c in children:\n",
        "            inputG.add_edges_from([(tok, c, {'dependency':c.dep_})])\n",
        "            add_n_to_g(inputG, c)\n",
        "add_n_to_g(nG, doc[2])\n",
        "print(nG.nodes(data=True))\n",
        "print(\"==\"*20)\n",
        "for e in nG.edges(data=True):\n",
        "    print(f\"{e[0]}, {e[1]}, ### dependency: {e[2]['dependency']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoyBGoBq_-50",
        "outputId": "829e9cf1-2367-4353-a327-8ff2cf333b33"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(shift, {}), (cars, {}), (liability, {}), (Autonomous, {}), (insurance, {}), (toward, {}), (manufacturers, {})]\n",
            "========================================\n",
            "shift, cars, ### dependency: nsubj\n",
            "shift, liability, ### dependency: dobj\n",
            "cars, Autonomous, ### dependency: amod\n",
            "liability, insurance, ### dependency: compound\n",
            "liability, toward, ### dependency: prep\n",
            "toward, manufacturers, ### dependency: pobj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQD5oiGgRfHe"
      },
      "source": [
        "üîπ **3-(2)** Spacy (kaggle) \n",
        "\n",
        "* Ï∫êÍ∏Ä ÎÖ∏Ìä∏Î∂Å ÌôòÍ≤ΩÏóêÏÑú Ïã§ÏäµÌï¥Î≥¥Îäî Í≤ÉÏùÑ Í∂åÏû•ÎìúÎ¶ΩÎãàÎã§!\n",
        "\n",
        "* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) üëâ ÌïÑÏàò\n",
        "  * ÎèÑÎÇ†Îìú Ìä∏ÎüºÌîÑ Ìä∏ÏúÑÌÑ∞ Ìä∏Ïúó ÎÇ¥Ïö© Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù\n",
        "\n",
        "\n",
        "üëÄ **ÎÖ∏Ìä∏Î∂Å ÌÇ§Ìè¨Ïù∏Ìä∏** \n",
        "  1. spacy.display Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©Ìïú NER ÏãúÍ∞ÅÌôî \n",
        "  2. Tagging ÏùÑ ÌÜµÌïú Ìä∏ÎüºÌîÑ Ìä∏Ïúó Î∂ÑÏÑù : noun_chunks Îäî dependency graphÎ•º Í≥†Î†§ÌïòÏó¨, noun phraseÎ•º ÎΩëÏïÑÏ§ÄÎã§. \n",
        "  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : ÏßÅÏ†ë Î¨∏Ïû•/Îã®Ïñ¥ Ìå®ÌÑ¥ÏùÑ Îì±Î°ùÌïòÏó¨ parsing\n",
        "  4. Question and answering task using Dependency Parsing\n",
        "    * spacy display :  ``style = 'dep'``\n",
        "    * .dep_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuHGKITRbKYq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMArOUrxAJ8K"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xUWWDwdiPLS9",
        "008-V5QsQG25"
      ],
      "name": "week5_nlp_hw_ÍπÄÎÇòÌòÑ.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}