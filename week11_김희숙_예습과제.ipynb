{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week11_김희숙_예습과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 문장 관계 분류 경진대회 필사"
      ],
      "metadata": {
        "id": "gFTktAuI4E7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 전제 (premise) 문장을 참고해 가설 (hypothesis) 이 참/거짓/알수 없는 문장인지 판별하는 문제 → 한국어 문장 쌍 분석 모델 개발 (Natural language inference) 에 관한 대회\n",
        "- BERT 모델에서 나아가, 연산량 측면에서 개선을 보인 ELECTRA 모델과 RoBERT 모델을 활용한 노트북이 상위권 수상을 차지\n"
      ],
      "metadata": {
        "id": "ribzIUip5zLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1등 노트북"
      ],
      "metadata": {
        "id": "nhD1vbG74H3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PublicLB | 0.896 | Finetuning Electra with Arcface\n",
        "- https://dacon.io/competitions/official/235875/codeshare/4589?page=1&dtype=recent"
      ],
      "metadata": {
        "id": "Onpns_1Y4KDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keypoint**\n",
        "-  2개의 모델 사용; 두 모델 결과값을 Softvoting Ensemble\n",
        "    - (1) Tunib's KoElectra-base finetuned with Arcface Head(Public LB 0.896)\n",
        "    - (2) KLUE Roberta-large finetuned with sentence pooling embeddings and special token embeddings(Public LB 0.902)\n",
        "- KoElectra-base는 #params으로 따지면 Roberta-large의 1/3 규모의 작은 모델로, Attention Layers 수로 따지면 Roberta-large의 절반 정도 깊이 모델\n"
      ],
      "metadata": {
        "id": "xQh_WoBp6AtC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8-iMUFamg4k"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install adamp\n",
        "!pip install wandb\n",
        "!pip install transformers\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" define train data and test data path \"\"\"\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# environment variable settings\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# path definitions\n",
        "ROOT_PATH = os.path.abspath(\".\")\n",
        "TRAIN_FILE_PATH = os.path.join(ROOT_PATH, \"train_dataset_v6_sentiment_and_score_pseudo_labeled_pororo_added.csv\")\n",
        "TEST_FILE_PATH = os.path.join(ROOT_PATH, 'test_dataset_v6_sentiment_and_score_pseudo_labeled_pororo_added.csv')\n",
        "SAMPLE_SUBMISSION_PATH = os.path.join(ROOT_PATH, 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "qsTcORpJlBam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Set configuration as dictionary format \"\"\"\n",
        "\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "from easydict import EasyDict\n",
        "\n",
        "# login wandb and get today's date until hour and minute\n",
        "wandb.login()\n",
        "\n",
        "# CFG Configuration\n",
        "CFG = wandb.config # wandb.config provides functionality of easydict.EasyDict\n",
        "CFG.DEBUG = False\n",
        "\n",
        "# Dataset Config as constants\n",
        "CFG.num_labels = 3\n",
        "CFG.num_workers = 2\n",
        "\n",
        "# Train configuration\n",
        "CFG.user_name = \"snoop2head\"\n",
        "CFG.model_name = \"tunib/electra-ko-base\"\n",
        "\n",
        "# Electra Paper's Hyperparameter for Finetuning GLUE details at Table 7: https://arxiv.org/pdf/2003.10555.pdf\n",
        "CFG.learning_rate = 1e-4\n",
        "CFG.adam_epsilon = 1e-6\n",
        "CFG.weight_decay = 0\n",
        "CFG.num_epochs = 10 \n",
        "CFG.train_batch_size = 32\n",
        "CFG.val_batch_size = CFG.train_batch_size\n",
        "CFG.dropout_rate = 0.1\n",
        "\n",
        "# However, while observing evaluation loss and f1 score, the following parameter resulted in better performance for KLUE NLI dataset.\n",
        "# Partially referenced from KRElectra's KorNLI finetuning Hyperparams: https://github.com/snunlp/KR-ELECTRA/blob/master/finetune/config/kornli/kr-electra.json#L15-L31\n",
        "CFG.learning_rate = 4e-5\n",
        "CFG.adam_epsilon = 1e-8\n",
        "CFG.weight_decay = 1e-2\n",
        "CFG.num_folds = 6 # 1st fold: Movie Review, 2nd fold: Airbnb Review, 3 ~ 6th fold: Other datasets\n",
        "CFG.num_epochs = 20\n",
        "CFG.train_batch_size = 3 * 40\n",
        "CFG.val_batch_size = CFG.train_batch_size"
      ],
      "metadata": {
        "id": "F7P2GMftlBYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed) :\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "EFicj8y-lBVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_num(label):\n",
        "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
        "    num_label = []\n",
        "\n",
        "    for v in label:\n",
        "        num_label.append(label_dict[v])\n",
        "    \n",
        "    return num_label\n"
      ],
      "metadata": {
        "id": "Z76fQUw-lBRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# get tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
        "\n",
        "added_special_tokens = [\"[PREMISE]\", \"[HYPOTHESIS]\"]\n",
        "\n",
        "tokenizer.add_special_tokens({\"additional_special_tokens\":added_special_tokens})\n",
        "\n",
        "len(tokenizer) # 32002"
      ],
      "metadata": {
        "id": "mffdHfbnlBOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def literal_eval_without_error(input_string):\n",
        "    # string [0.2765555, 0.7233189, 6.404926e-05, 6.1491264e-05] into list [0.2765555, 0.7233189, 6.404926e-05, 6.1491264e-05]\n",
        "    input_string = input_string[1:-1]\n",
        "    input_list = input_string.split(\",\")\n",
        "    output_list = [item.strip() for item in input_list]\n",
        "    output_list = [float(item) for item in input_list]\n",
        "    return output_list\n",
        "\n",
        "# read pororo dataset\n",
        "df_pororo_dataset = pd.read_csv(TRAIN_FILE_PATH) \n",
        "display(df_pororo_dataset.head(3))\n",
        "\n",
        "df_pororo_dataset[\"electra_premise_probability\"] = df_pororo_dataset[\"electra_premise_probability\"].apply(literal_eval_without_error)\n",
        "df_pororo_dataset[\"electra_hypothesis_probability\"] = df_pororo_dataset[\"electra_hypothesis_probability\"].apply(literal_eval_without_error)\n",
        "df_pororo_dataset[\"electra_premise_score_probability\"] = df_pororo_dataset[\"electra_premise_score_probability\"].apply(literal_eval_without_error)\n",
        "df_pororo_dataset[\"electra_hypothesis_score_probability\"] = df_pororo_dataset[\"electra_hypothesis_score_probability\"].apply(literal_eval_without_error)"
      ],
      "metadata": {
        "id": "OSgBIcE2lBMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_augmentation_electra(\n",
        "    df:pd.DataFrame, \n",
        "    str_premise_start_special_token = \"^\", \n",
        "    str_premise_end_special_token = \"^\", \n",
        "    str_hypothesis_start_special_token = \"*\",\n",
        "    str_hypothesis_end_special_token = \"*\",\n",
        "    is_test=False\n",
        "    ):\n",
        "  CLS_TOKEN_LEN = 1\n",
        "  SEP_TOKEN_LEN = 1\n",
        "\n",
        "  premise_list = []\n",
        "  hypothesis_list = []\n",
        "  label_list = []\n",
        "  index_list = []\n",
        "\n",
        "  # wrap premise sentence with additional hintings and special tokens\n",
        "  df_return = pd.DataFrame({})\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if is_test:\n",
        "      index = row['index']\n",
        "    else:\n",
        "      pass\n",
        "    premise = row['premise']\n",
        "    hypothesis = row['hypothesis']\n",
        "    label = row['label']\n",
        "    \n",
        "    # source(or categorical) information\n",
        "    source_label = row['source_label']\n",
        "    source_prefix = row['source_label'].split(\"/\")[0]\n",
        "    source_subfix = row['source_label'].split(\"/\")[1]\n",
        "    \n",
        "    if source_label == \"영화후기/영화평가\" or source_label == \"여행후기/여행평가\":\n",
        "      \n",
        "      # make pororo sentiment labels (긍정적 vs 부정적)\n",
        "      premise_sentiment = row[\"premise_sentiment\"] # pororo label\n",
        "      hypothesis_sentiment = row[\"hypothesis_sentiment\"]\n",
        "\n",
        "      electra_premise_sentiment = row[\"electra_premise_label\"] # electra label\n",
        "      electra_hypothesis_sentiment = row[\"electra_hypothesis_label\"]\n",
        "\n",
        "      # if two sentiment labels don't agree then use neutral sentiment label, \n",
        "      if premise_sentiment == electra_premise_sentiment:\n",
        "        pass\n",
        "      else:\n",
        "        premise_sentiment = \"중립적\"\n",
        "      \n",
        "      if hypothesis_sentiment == electra_hypothesis_sentiment:\n",
        "        pass\n",
        "      else:\n",
        "        hypothesis_sentiment = \"중립적\"\n",
        "      \n",
        "\n",
        "      # use naver shopping based scoreing\n",
        "      pororo_premise_score = row[\"premise_score\"]\n",
        "      electra_premise_score = np.dot([1,2,4,5], row[\"electra_premise_score_probability\"]) # score weighted sum\n",
        "      premise_score = pororo_premise_score * 0.5 + electra_premise_score * 0.5\n",
        "      premise_score =  '{:.2f}'.format(round(premise_score, 2))\n",
        "      \n",
        "      pororo_hypothesis_score = row[\"hypothesis_score\"]\n",
        "      electra_hypothesis_score = np.dot([1,2,4,5], row[\"electra_hypothesis_score_probability\"]) # score weighted sum\n",
        "      hypothesis_score = pororo_hypothesis_score * 0.5 + electra_hypothesis_score * 0.5\n",
        "      hypothesis_score = '{:.2f}'.format(round(hypothesis_score, 2))\n",
        "      \n",
        "      # create span + sentence\n",
        "      premise = str_premise_start_special_token + \\\n",
        "                str(premise_score) + \"점 만큼 \" + premise_sentiment + \"인 \" + \\\n",
        "                source_prefix + \":\" + premise + \\\n",
        "                str_premise_end_special_token\n",
        "      hypothesis = str_hypothesis_start_special_token + \\\n",
        "                str(hypothesis_score) + \"점 만큼 \" + hypothesis_sentiment + \"인 \" + \\\n",
        "                source_subfix + \":\" + hypothesis + \\\n",
        "                str_hypothesis_end_special_token\n",
        "\n",
        "    else:\n",
        "      premise = str_premise_start_special_token + \\\n",
        "                source_prefix + \":\" + premise + \\\n",
        "                str_premise_end_special_token\n",
        "      hypothesis = str_hypothesis_start_special_token + \\\n",
        "                source_subfix + \":\" + hypothesis + \\\n",
        "                str_hypothesis_end_special_token\n",
        "    premise_list.append(premise)\n",
        "    hypothesis_list.append(hypothesis)\n",
        "    label_list.append(label)\n",
        "    if is_test:\n",
        "      index_list.append(index)\n",
        "    else:\n",
        "      pass    \n",
        "\n",
        "  df_return[\"premise\"] = premise_list\n",
        "  df_return[\"hypothesis\"] = hypothesis_list\n",
        "  df_return[\"label\"] = label_list \n",
        "  if is_test:\n",
        "    df_return[\"index\"] = index_list\n",
        "  # apply tokenizer for premise\n",
        "  df_return['premise_len'] = df_return['premise'].apply(\n",
        "      lambda x: len(tokenizer.encode(x, add_special_tokens=False))\n",
        "  )\n",
        "  df_return['hypothesis_len'] = df_return['hypothesis'].apply(\n",
        "      lambda x: len(tokenizer.encode(x, add_special_tokens=False))\n",
        "  )\n",
        "\n",
        "  df_return['premise_index'] = CLS_TOKEN_LEN # ^ is next to [CLS] token\n",
        "  df_return['hypothesis_index'] = CLS_TOKEN_LEN + df_return['premise_len'] + SEP_TOKEN_LEN # * is next to [SEP] token\n",
        "  df_return['total_length'] = CLS_TOKEN_LEN + df_return['premise_len'] \\\n",
        "      + SEP_TOKEN_LEN + df_return['hypothesis_len'] + SEP_TOKEN_LEN\n",
        "  return df_return"
      ],
      "metadata": {
        "id": "bYMQOWnylBKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set display options\n",
        "pd.options.display.max_colwidth = None\n",
        "\n",
        "df_pororo_dataset_preprocessed = preprocess_augmentation_electra(\n",
        "    df_pororo_dataset, \n",
        "    str_premise_start_special_token = \"[PREMISE]\", \n",
        "    str_premise_end_special_token = \"[PREMISE]\", \n",
        "    str_hypothesis_start_special_token = \"[HYPOTHESIS]\",\n",
        "    str_hypothesis_end_special_token = \"[HYPOTHESIS]\",\n",
        ")\n",
        "\n",
        "df_pororo_dataset_preprocessed.head(3)"
      ],
      "metadata": {
        "id": "VueR-MEblBHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show distribution of total_length\n",
        "df_pororo_dataset_preprocessed['total_length'].hist(bins=100)\n",
        "print(max(df_pororo_dataset_preprocessed['total_length'])) # tunib electra max token length: 97\n",
        "CFG.max_token_length = max(df_pororo_dataset_preprocessed['total_length'])"
      ],
      "metadata": {
        "id": "28DJzOy1lBFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RBERTDataset(Dataset):\n",
        "    def __init__(self, dataset, is_training:bool=True):\n",
        "        \n",
        "        # object values with string items\n",
        "        self.dataset = dataset\n",
        "        self.premise = self.dataset['premise']\n",
        "        self.hypothesis = self.dataset['hypothesis']\n",
        "        self.sentence = self.dataset['premise'] + ' [SEP] ' + self.dataset['hypothesis']\n",
        "        \n",
        "        # torch values with integer values\n",
        "        if is_training:\n",
        "            self.train_label = label_to_num(self.dataset['label'].values)\n",
        "        if not is_training:\n",
        "            self.train_label = self.dataset['label'].values\n",
        "        self.label = torch.tensor(self.train_label)\n",
        "        self.premise_start_index = torch.tensor(self.dataset['premise_index'].values)\n",
        "        self.premise_len = torch.tensor(self.dataset['premise_len'].values)\n",
        "        self.hypothesis_start_index = torch.tensor(self.dataset['hypothesis_index'].values)\n",
        "        self.hypothesis_len = torch.tensor(self.dataset['hypothesis_len'].values)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # object values with string items\n",
        "        sentence = self.sentence[idx]\n",
        "        \n",
        "        # torch values with integer values\n",
        "        premise_start_index = self.premise_start_index[idx]\n",
        "        premise_len = self.premise_len[idx]\n",
        "        hypothesis_start_index = self.hypothesis_start_index[idx]\n",
        "        hypothesis_len = self.hypothesis_len[idx]\n",
        "        label = self.label[idx]\n",
        "        \n",
        "        # tokenize\n",
        "        item = tokenizer(\n",
        "            sentence,\n",
        "            return_tensors=\"pt\",\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=CFG.max_token_length,\n",
        "            add_special_tokens=True,\n",
        "            return_token_type_ids=False, # for RoBERTa\n",
        "            )\n",
        "        \n",
        "        # RoBERTa's provided masks (do not include token_type_ids for RoBERTa)\n",
        "        item['input_ids'] = item['input_ids'].squeeze(0)\n",
        "        item['attention_mask'] = item['attention_mask'].squeeze(0)\n",
        "        \n",
        "        # add subject and object entity masks where masks notate where the entity is\n",
        "        premise_mask, hypothesis_mask = self.add_entity_mask(\n",
        "            premise_start_index,\n",
        "            hypothesis_start_index,\n",
        "            premise_len, \n",
        "            hypothesis_len,\n",
        "        )\n",
        "        item['premise_mask'] = torch.tensor(premise_mask)\n",
        "        item['hypothesis_mask'] = torch.tensor(hypothesis_mask)\n",
        "\n",
        "        # fill label\n",
        "        item['label'] = label\n",
        "\n",
        "        item['premise_special_token_index'] = premise_start_index\n",
        "        item['hypothesis_special_token_index'] = hypothesis_start_index\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def add_entity_mask(\n",
        "            self,\n",
        "            premise_start_index,\n",
        "            hypothesis_start_index,\n",
        "            premise_len, \n",
        "            hypothesis_len\n",
        "        ):\n",
        "        \"\"\" add entity token to input_ids \"\"\"\n",
        "        # print(\"tokenized input ids: \\n\",item['input_ids'])\n",
        "\n",
        "        # initialize entity masks\n",
        "        premise_mask = np.zeros(CFG.max_token_length, dtype=int)\n",
        "        hypothesis_mask = np.zeros(CFG.max_token_length, dtype=int)\n",
        "\n",
        "        premise_mask[\n",
        "          premise_start_index : premise_start_index + premise_len\n",
        "        ] = 1\n",
        "        \n",
        "        hypothesis_mask[\n",
        "          hypothesis_start_index : hypothesis_start_index + hypothesis_len\n",
        "        ] = 1\n",
        "        \n",
        "        return premise_mask, hypothesis_mask"
      ],
      "metadata": {
        "id": "dNDQehTFlBCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_1 = RBERTDataset(df_pororo_dataset_preprocessed)[0]\n",
        "sample_2 = RBERTDataset(df_pororo_dataset_preprocessed)[1]\n",
        "sample_3 = RBERTDataset(df_pororo_dataset_preprocessed)[2]\n",
        "\n",
        "print(sample_1)"
      ],
      "metadata": {
        "id": "uEFCXAzNlU55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging add_entity_mask_sample function with sample code\n",
        "\n",
        "decoded_item_1 = tokenizer.decode(sample_1['input_ids'])\n",
        "decoded_item_2 = tokenizer.decode(sample_2['input_ids'])\n",
        "decoded_item_3 = tokenizer.decode(sample_3['input_ids'])\n",
        "\n",
        "print(decoded_item_1)\n",
        "print(decoded_item_2)\n",
        "print(decoded_item_3)"
      ],
      "metadata": {
        "id": "Yscgc7V2lU3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nn from torch\n",
        "from torch import nn\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "\"\"\" R-BERT: https://github.com/monologg/R-BERT \"\"\"\n",
        "class FCLayer(nn.Module):\n",
        "    # both attention dropout and fc dropout is 0.1 on Roberta: https://arxiv.org/pdf/1907.11692.pdf\n",
        "    def __init__(self, input_dim, output_dim, dropout_rate=0.1, use_activation=True):\n",
        "        super(FCLayer, self).__init__()\n",
        "        self.use_activation = use_activation\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        self.activation = nn.GELU() # electra uses gelu whereas BERT or Roberta used tanh in fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        return self.linear(x)\n",
        "\n",
        "class RBERT(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        model_name:str=CFG.model_name,\n",
        "        num_labels:int=3,\n",
        "        dropout_rate:float=0.1,\n",
        "        special_tokens_dict:dict=None,\n",
        "        is_train:bool=True,\n",
        "        embedding_resizing_length = len(tokenizer),\n",
        "        ):\n",
        "        super(RBERT, self).__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        config.num_labels = num_labels\n",
        "        self.backbone_model = AutoModel.from_pretrained(model_name, config=config)\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_labels = num_labels\n",
        "        \n",
        "        # add special tokens\n",
        "        self.special_tokens_dict = special_tokens_dict\n",
        "        if embedding_resizing_length != 32000:\n",
        "            self.backbone_model.resize_token_embeddings(embedding_resizing_length)\n",
        "\n",
        "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, self.dropout_rate)\n",
        "        self.entity_fc_layer = FCLayer(config.hidden_size, config.hidden_size, self.dropout_rate)\n",
        "        self.label_classifier = FCLayer(\n",
        "            config.hidden_size * 3,\n",
        "            self.num_labels,\n",
        "            self.dropout_rate,\n",
        "            use_activation=False,\n",
        "        )\n",
        "\n",
        "    def entity_average(self, hidden_output, e_mask):\n",
        "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
        "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
        "\n",
        "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
        "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
        "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
        "        return avg_vector\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask, premise_mask=None, hypothesis_mask=None, labels=None):\n",
        "        \n",
        "        discriminator_hidden_states = self.backbone_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "                \n",
        "        # https://github.com/huggingface/transformers/blob/db7d6a80e82d66127b2a44b6e3382969fdc8b207/src/transformers/models/electra/modeling_electra.py#L932-L951\n",
        "        sequence_output = discriminator_hidden_states[0]\n",
        "        pooled_output = sequence_output[:, 0, :]  # [CLS] token's hidden featrues(hidden state)\n",
        "\n",
        "        # hidden state's average in between entities\n",
        "        # print(sequence_output.shape, premise_mask.shape)\n",
        "        e1_h = self.entity_average(sequence_output, premise_mask) # token in between subject entities -> \n",
        "        e2_h = self.entity_average(sequence_output, hypothesis_mask) # token in between object entities\n",
        "\n",
        "        # Dropout -> gelu -> fc_layer (Share FC layer for e1 and e2)\n",
        "        pooled_output = self.cls_fc_layer(pooled_output) # [CLS] token -> hidden state | green on diagram\n",
        "        e1_h = self.entity_fc_layer(e1_h) # subject entity's fully connected layer | yellow on diagram\n",
        "        e2_h = self.entity_fc_layer(e2_h) # object entity's fully connected layer | red on diagram\n",
        "\n",
        "        # Concat -> fc_layer / [CLS], subject_average, object_average\n",
        "        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-1)\n",
        "        logits = self.label_classifier(concat_h)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "i656xj4RlU1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IBDataset(Dataset):\n",
        "    def __init__(self, dataset, is_training:bool=True):\n",
        "        \n",
        "        # pandas.Dataframe dataset\n",
        "        self.dataset = dataset\n",
        "        self.premise = self.dataset['premise']\n",
        "        self.hypothesis = self.dataset['hypothesis']\n",
        "        self.sentence = self.dataset['premise'] + ' [SEP] ' + self.dataset['hypothesis']\n",
        "        if is_training:\n",
        "            self.train_label = label_to_num(self.dataset['label'].values)\n",
        "        if not is_training:\n",
        "            self.train_label = self.dataset['label'].values\n",
        "        self.label = torch.tensor(self.train_label)\n",
        "        self.premise_special_token_index = torch.tensor(self.dataset['premise_index'].values)\n",
        "        self.hypothesis_special_token_index = torch.tensor(self.dataset['hypothesis_index'].values)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentence[idx]\n",
        "        label = self.label[idx]\n",
        "        premise_special_token_index = self.premise_special_token_index[idx]\n",
        "        hypothesis_special_token_index = self.hypothesis_special_token_index[idx]\n",
        "\n",
        "        # tokenize\n",
        "        item = tokenizer(\n",
        "            sentence,\n",
        "            return_tensors=\"pt\",\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=CFG.max_token_length,\n",
        "            add_special_tokens=True,\n",
        "            return_token_type_ids=False, # for RoBERTa\n",
        "            )\n",
        "        \n",
        "        # RoBERTa's provided masks (do not include token_type_ids for RoBERTa)\n",
        "        item['input_ids'] = item['input_ids'].squeeze(0)\n",
        "        item['attention_mask'] = item['attention_mask'].squeeze(0)\n",
        "\n",
        "        # fill label\n",
        "        item['label'] = label\n",
        "        item['premise_special_token_index'] = premise_special_token_index\n",
        "        item['hypothesis_special_token_index'] = hypothesis_special_token_index\n",
        "        return item"
      ],
      "metadata": {
        "id": "HekQ1UBplUyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_1 = IBDataset(df_pororo_dataset_preprocessed)[0]\n",
        "sample_2 = IBDataset(df_pororo_dataset_preprocessed)[1]\n",
        "sample_3 = IBDataset(df_pororo_dataset_preprocessed)[2]\n",
        "\n",
        "print(sample_1)"
      ],
      "metadata": {
        "id": "JKjqm6TclUvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging add_entity_mask_sample function with sample code\n",
        "\n",
        "decoded_item_1 = tokenizer.decode(sample_1['input_ids'])\n",
        "decoded_item_2 = tokenizer.decode(sample_2['input_ids'])\n",
        "decoded_item_3 = tokenizer.decode(sample_3['input_ids'])\n",
        "\n",
        "print(decoded_item_1)\n",
        "print(decoded_item_2)\n",
        "print(decoded_item_3)"
      ],
      "metadata": {
        "id": "RQ4MpaablUsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nn from torch\n",
        "from torch import nn\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "class IBModel(nn.Module):\n",
        "    \"\"\"\n",
        "    'An Improved Baseline for Sentence-level Relation Extraction'\n",
        "    https://github.com/wzhouad/RE_improved_baseline/blob/main/model.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "        model_name = \"tunib/electra-ko-base\", \n",
        "        dropout_rate = CFG.dropout_rate,\n",
        "        use_arcface = False,\n",
        "        embedding_resizing_length = len(tokenizer),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        config = AutoConfig.from_pretrained(CFG.model_name)\n",
        "        config.num_labels = CFG.num_labels\n",
        "        self.backbone_model = AutoModel.from_pretrained(model_name, config=config)\n",
        "        if embedding_resizing_length != 32000:\n",
        "          self.backbone_model.resize_token_embeddings(embedding_resizing_length)\n",
        "        hidden_size = config.hidden_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_size * 3, hidden_size), # change to hidden_size * 3 if you want to add pooler_output\n",
        "            nn.GELU(), \n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_size, config.num_labels),\n",
        "        )\n",
        "    \n",
        "    def forward(\n",
        "            self, \n",
        "            input_ids, \n",
        "            attention_mask,\n",
        "            premise_special_token_index,\n",
        "            hypothesis_special_token_index,\n",
        "            labels=None):\n",
        "        outputs = self.backbone_model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[\"last_hidden_state\"] # sequence output of the last layer\n",
        "        cls_output = sequence_output[:, 0, :]  # [CLS] token's hidden features(different from pooler output)\n",
        "        # pooler_output = outputs[\"pooler_output\"]  # [CLS] hidden state passed through pooler: https://github.com/huggingface/transformers/blob/2c2a31ffbcfe03339b1721348781aac4fc05bc5e/src/transformers/models/roberta/modeling_roberta.py#L569-L581\n",
        "\n",
        "        # extract embedding for special tokens for each premise and hypothesis\n",
        "        idx_seq = torch.arange(input_ids.size(0)).to(input_ids.device) \n",
        "        premise_emb = sequence_output[idx_seq, premise_special_token_index]\n",
        "        hypothesis_emb = sequence_output[idx_seq, hypothesis_special_token_index]\n",
        "\n",
        "        # concat [CLS], ^, *\n",
        "        concat_hidden_states = torch.cat((cls_output, premise_emb, hypothesis_emb), dim=-1)\n",
        "      \n",
        "        return self.classifier(concat_hidden_states)"
      ],
      "metadata": {
        "id": "wuNsoAKIlUqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nn from torch\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "class IBConcatModel(nn.Module):\n",
        "    def __init__(self, \n",
        "        model_name = \"tunib/electra-ko-base\",\n",
        "        dropout_rate = CFG.dropout_rate,\n",
        "        embedding_resizing_length = len(tokenizer),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        config = AutoConfig.from_pretrained(CFG.model_name)\n",
        "        config.num_labels = CFG.num_labels\n",
        "        self.backbone_model = AutoModel.from_pretrained(model_name, config=config)\n",
        "        if embedding_resizing_length != 32000:\n",
        "          self.backbone_model.resize_token_embeddings(embedding_resizing_length)\n",
        "        hidden_size = config.hidden_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_size * 12, hidden_size * 3), # change to hidden_size * 3 if you want to add pooler_output\n",
        "            # nn.GELU(), \n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_size * 3, config.num_labels),\n",
        "        )\n",
        "\n",
        "    # @autocast() # autocast for FP16\n",
        "    def forward(\n",
        "            self, \n",
        "            input_ids, \n",
        "            attention_mask,\n",
        "            premise_special_token_index,\n",
        "            hypothesis_special_token_index,\n",
        "            labels=None):\n",
        "        \n",
        "        outputs = self.backbone_model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "        \n",
        "        # sequence output of the last layer\n",
        "        # https://github.com/huggingface/transformers/blob/db7d6a80e82d66127b2a44b6e3382969fdc8b207/src/transformers/models/electra/modeling_electra.py#L961\n",
        "        hidden_states = outputs[\"hidden_states\"]\n",
        "        \n",
        "        # extract embedding for [CLS] token\n",
        "        # concating last four hidden states are mentioned in BERT paper: https://github.com/huggingface/transformers/issues/1328\n",
        "        cls_concat = torch.cat(tuple([hidden_states[i][:, 0, :] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "\n",
        "        # extract embedding for special tokens for each premise and hypothesis\n",
        "        idx_seq = torch.arange(input_ids.size(0)).to(input_ids.device) \n",
        "        \n",
        "        # premise special token embedding\n",
        "        # concating last four hidden states are mentioned in BERT paper: https://github.com/huggingface/transformers/issues/1328\n",
        "        premise_concat = torch.cat(tuple([hidden_states[i][idx_seq, premise_special_token_index] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "        \n",
        "        # hypothesis special token embedding\n",
        "        # concating last four hidden states are mentioned in BERT paper: https://github.com/huggingface/transformers/issues/1328\n",
        "        hypothesis_concat = torch.cat(tuple([hidden_states[i][idx_seq, hypothesis_special_token_index] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "\n",
        "        # concat embeddings for [CLS], ^, *\n",
        "        knit_hidden_states = torch.cat((\n",
        "            cls_concat,\n",
        "            premise_concat,\n",
        "            hypothesis_concat,\n",
        "        ), dim=-1)\n",
        "        \n",
        "        return self.classifier(knit_hidden_states)"
      ],
      "metadata": {
        "id": "gqJuNnPElUnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from torch.cuda.amp import autocast\n",
        "from torch.nn import Parameter\n",
        "import math\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    \"\"\"  \n",
        "    Reference: https://github.com/ronghuaiyang/arcface-pytorch/blob/master/models/metrics.py\n",
        "    Implement of large margin arc distance: :\n",
        "    Args:\n",
        "        in_features: size of each input sample\n",
        "        out_features: size of each output sample\n",
        "        s: norm of input feature: scaling ratio from a small number to a final logit\n",
        "        m: the additional angular margin\n",
        "        cos(theta + m)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "    \n",
        "    # @autocast() for FP16 (Automatic Mixed Precision)\n",
        "    def forward(self, input, label=None):\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "    \n",
        "        if label is not None:\n",
        "          one_hot = torch.zeros(cosine.size(), device='cuda')\n",
        "          one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "          output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        else:\n",
        "          output = cosine\n",
        "        \n",
        "        output *= self.s\n",
        "        return output"
      ],
      "metadata": {
        "id": "KNbZckSKlh5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nn from torch\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "class ArcFaceIBModel(nn.Module):\n",
        "    \"\"\" Modified IBmodel with Arcmarginproduct head \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        model_name, \n",
        "        dropout_rate = CFG.dropout_rate,\n",
        "        embedding_resizing_length = len(tokenizer)\n",
        "    ):\n",
        "        super().__init__()\n",
        "        config = AutoConfig.from_pretrained(CFG.model_name)\n",
        "        config.num_labels = CFG.num_labels\n",
        "        self.backbone_model = AutoModel.from_pretrained(model_name, config=config)\n",
        "        if embedding_resizing_length != 32000:\n",
        "          self.backbone_model.resize_token_embeddings(embedding_resizing_length)\n",
        "        hidden_size = config.hidden_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.arcface = ArcMarginProduct(config.hidden_size, config.num_labels)\n",
        "        self.neck = nn.Sequential(\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_size * 3, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "        )\n",
        "        self.proj_fc_layer = FCLayer(config.hidden_size * 4, config.hidden_size, self.dropout_rate)\n",
        "\n",
        "    # @autocast()\n",
        "    def forward(\n",
        "            self, \n",
        "            input_ids, \n",
        "            attention_mask,\n",
        "            premise_special_token_index,\n",
        "            hypothesis_special_token_index,\n",
        "            labels=None):\n",
        "        outputs = self.backbone_model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "        hidden_states = outputs[\"hidden_states\"]\n",
        "        cls_concat = torch.cat(tuple([hidden_states[i][:, 0, :] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "        cls_output = self.proj_fc_layer(cls_concat)\n",
        "        \n",
        "        # extract embedding for special tokens for each premise and hypothesis\n",
        "        idx_seq = torch.arange(input_ids.size(0)).to(input_ids.device) \n",
        "        premise_concat = torch.cat(tuple([hidden_states[i][idx_seq, premise_special_token_index] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "        premise_output = self.proj_fc_layer(premise_concat)\n",
        "        hypothesis_concat = torch.cat(tuple([hidden_states[i][idx_seq, hypothesis_special_token_index] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "        hypothesis_output = self.proj_fc_layer(hypothesis_concat)\n",
        "\n",
        "        # concat [CLS], ^, *\n",
        "        concat_hidden_states = torch.cat((cls_output, premise_output, hypothesis_output), dim=-1)\n",
        "      \n",
        "        # goes through neck for projection\n",
        "        out_proj = self.neck(concat_hidden_states)\n",
        "        \n",
        "        # input to the arcface head for logit\n",
        "        if labels is not None:\n",
        "            logits = self.arcface(out_proj, labels)\n",
        "        else:\n",
        "            logits = self.arcface(out_proj)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "t5mr2rGdlh3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() and CFG.DEBUG == False else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "i7xiG5u6lh1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics(object):\n",
        "    \"\"\" \n",
        "    Averaging metrics collected across batches such as loss, f1 and accuracy\n",
        "    Reference: https://github.com/pytorch/examples/blob/21c240b814658e590b4fa9d4682d39831060c5b9/imagenet/main.py#L367-L385    \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        \n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "tShRv3jdlhyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = f\"ArcfaceIBModel-Electra-4-concat-Augmentation-v7-not-shuffled-CrossEntropyLoss-{CFG.train_batch_size}\""
      ],
      "metadata": {
        "id": "BjiWEbBOlhv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scikit-learn metrics and folds\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# torch data utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "# optimizers and schedulers\n",
        "from adamp import AdamP\n",
        "from transformers import AdamW # or from torch.optim import AdamW\n",
        "from transformers import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
        "\n",
        "# tqdm progress bar repetition error fixed on jupyter notebook\n",
        "from tqdm.notebook import tqdm \n",
        "\n",
        "wandb.init(\n",
        "    project='KLUE-NLI', \n",
        "    name=run_name,\n",
        "    config=CFG\n",
        "  )\n",
        "\n",
        "train_data = IBDataset(df_pororo_dataset_preprocessed)\n",
        "dev_data = IBDataset(df_pororo_dataset_preprocessed)\n",
        "\n",
        "kfd = KFold(n_splits = CFG.num_folds, shuffle=False)\n",
        "\n",
        "for fold_num, (train_idx, dev_idx) in enumerate(kfd.split(df_pororo_dataset_preprocessed)):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    print(\"using CE loss function\")\n",
        "\n",
        "    print(f\"#################### Fold: {fold_num + 1} ######################\")\n",
        "\n",
        "    RESULT_PATH = f\"./results\"\n",
        "    if not os.path.exists(RESULT_PATH):\n",
        "      os.mkdir(RESULT_PATH)\n",
        "    \n",
        "    SAVE_PATH = f\"./results/{run_name}\"\n",
        "    if not os.path.exists(SAVE_PATH):\n",
        "      os.mkdir(SAVE_PATH)\n",
        "\n",
        "    train_set = Subset(train_data, train_idx)\n",
        "    dev_set = Subset(dev_data, dev_idx)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_set, \n",
        "        batch_size=CFG.train_batch_size, \n",
        "        shuffle=False, \n",
        "        num_workers=CFG.num_workers,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    dev_loader = DataLoader(\n",
        "        dev_set, \n",
        "        batch_size=CFG.val_batch_size, \n",
        "        shuffle=False, \n",
        "        num_workers=CFG.num_workers,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    # fetch model\n",
        "    model = ArcFaceIBModel(\n",
        "        CFG.model_name, \n",
        "        dropout_rate = CFG.dropout_rate,\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    # fetch loss function, optimizer, scheduler outside of torch library\n",
        "    # https://github.com/clovaai/AdamP\n",
        "    optimizer = AdamP(\n",
        "        model.parameters(), # training all params\n",
        "        lr=CFG.learning_rate,\n",
        "        weight_decay=CFG.weight_decay,\n",
        "        eps=CFG.adam_epsilon,\n",
        "        betas=(0.9, 0.999),\n",
        "    )\n",
        "\n",
        "    CFG.logging_steps = len(train_loader) // 3 # set logging steps according to the length of train_loader\n",
        "    CFG.warmup_steps = CFG.logging_steps # warmup steps as 1/3 of first epoch\n",
        "    \n",
        "    # https://huggingface.co/transformers/main_classes/optimizer_schedules.html\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=CFG.warmup_steps, num_training_steps=len(train_loader)*CFG.num_epochs)\n",
        "\n",
        "    # class for accumulative metrics calculation over batches iteration\n",
        "    train_acc = Metrics()\n",
        "    train_loss = Metrics()\n",
        "    dev_acc = Metrics()\n",
        "    dev_loss = Metrics()\n",
        "    train_f1 = Metrics()\n",
        "    dev_f1 = Metrics()\n",
        "\n",
        "    best_eval_loss = 5.0\n",
        "    best_eval_accuracy = 0.80\n",
        "    best_f1_score = 0.80\n",
        "    \n",
        "    steps = 0\n",
        "    \n",
        "    # fetch training loop\n",
        "    for epoch in range(CFG.num_epochs):\n",
        "        for _ , item in enumerate(tqdm(train_loader)):\n",
        "            \n",
        "            # model to training mode\n",
        "            model.train()\n",
        "            \n",
        "            input_ids = item['input_ids'].to(device)\n",
        "            attention_mask = item['attention_mask'].to(device)\n",
        "            premise_special_token_index = item['premise_special_token_index'].to(device)\n",
        "            hypothesis_special_token_index = item['hypothesis_special_token_index'].to(device)\n",
        "            label = item['label'].to(device)\n",
        "            \n",
        "            # assign forward() arguments to the device\n",
        "            logits = model(\n",
        "                input_ids, \n",
        "                attention_mask,\n",
        "                premise_special_token_index=premise_special_token_index, \n",
        "                hypothesis_special_token_index=hypothesis_special_token_index, \n",
        "                labels=label\n",
        "            )\n",
        "            \n",
        "            loss = criterion(logits, label)\n",
        "\n",
        "            optimizer.zero_grad() # replacing model.zero_grad() with optimizer_zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # update loss\n",
        "            train_loss.update(loss.item(), len(input_ids))\n",
        "            \n",
        "            # accuracy\n",
        "            predict = logits.argmax(-1)\t\n",
        "            train_accuracy_score = accuracy_score(label.detach().cpu().numpy(), predict.detach().cpu().numpy())\n",
        "            train_acc.update(train_accuracy_score, len(input_ids))\n",
        "            \n",
        "            # f1 score\n",
        "            train_f1_score = f1_score(label.detach().cpu().numpy(), predict.detach().cpu().numpy(), average=\"macro\") # macro for even classes: https://www.baeldung.com/cs/multi-class-f1-score\n",
        "            train_f1.update(train_f1_score, len(input_ids))\n",
        "            \n",
        "            steps += 1\n",
        "\n",
        "            if steps % CFG.logging_steps == 0: # batch\n",
        "                print('Epoch: {}/{}'.format(epoch+1, CFG.num_epochs), 'Step: {}'.format(steps), 'Train Loss: {:.4f}'.format(train_loss.avg), 'Train Acc: {:.4f}'.format(train_acc.avg))\n",
        "                for _, dev_item in enumerate(tqdm(dev_loader)):\n",
        "                    dev_input_ids = dev_item['input_ids'].to(device)\n",
        "                    dev_attention_mask = dev_item['attention_mask'].to(device)\n",
        "                    dev_premise_special_token_index = dev_item['premise_special_token_index'].to(device)\n",
        "                    dev_hypothesis_special_token_index = dev_item['hypothesis_special_token_index'].to(device)\n",
        "                    dev_label = dev_item['label'].to(device)\n",
        "                    \n",
        "                    # switch model to eval mode\n",
        "                    model.eval()\n",
        "                    dev_logits = model(\n",
        "                        dev_input_ids, \n",
        "                        dev_attention_mask,\n",
        "                        premise_special_token_index=dev_premise_special_token_index, \n",
        "                        hypothesis_special_token_index=dev_hypothesis_special_token_index, \n",
        "                        labels=dev_label\n",
        "                    )\n",
        "\n",
        "                    # update loss\n",
        "                    loss = criterion(dev_logits, dev_label)\n",
        "                    dev_loss.update(loss.item(), len(dev_input_ids))\n",
        "                    \n",
        "                    # accuracy\n",
        "                    dev_predict = dev_logits.argmax(-1)\n",
        "                    dev_accuracy_score = accuracy_score(dev_label.detach().cpu().numpy(), dev_predict.detach().cpu().numpy())\n",
        "                    dev_acc.update(dev_accuracy_score, len(dev_input_ids))\n",
        "\n",
        "                    # f1 score\n",
        "                    dev_f1_score = f1_score(dev_label.detach().cpu().numpy(), dev_predict.detach().cpu().numpy(), average=\"macro\") # macro for even classes: https://www.baeldung.com/cs/multi-class-f1-score\n",
        "                    dev_f1.update(dev_f1_score, len(input_ids))\n",
        "\n",
        "                # print metrics\n",
        "                print('Epoch: {}/{}'.format(epoch+1, CFG.num_epochs), \n",
        "                      'Step: {}'.format(steps), \n",
        "                      'Dev Loss: {:.4f}'.format(dev_loss.avg), \n",
        "                      'Dev Acc: {:.4f}'.format(dev_acc.avg), \n",
        "                      'Dev f1: {:.4f}'.format(dev_f1.avg)\n",
        "                )\n",
        "                wandb.log(\n",
        "                    {\n",
        "                        'train/loss':train_loss.avg, \n",
        "                        'train/accuracy':train_acc.avg, \n",
        "                        'train/f1': train_f1.avg,\n",
        "                        'train/learning_rate':optimizer.param_groups[0]['lr'], \n",
        "                        'eval/loss':dev_loss.avg,\n",
        "                        'eval/accuracy':dev_acc.avg,\n",
        "                        'eval/f1':dev_f1.avg,\n",
        "                        'Step':steps\n",
        "                    }\n",
        "                )\n",
        "                    \n",
        "                if best_eval_loss > dev_loss.avg:\n",
        "                    best_eval_loss = dev_loss.avg\n",
        "                    torch.save(model.state_dict(), f'{SAVE_PATH}/{fold_num+1}-fold-{CFG.num_folds}-best-eval-loss-model.pt')\n",
        "                    print('Saved model with lowest validation loss: {:.4f}'.format(best_eval_loss))\n",
        "                    wandb.log({'best_eval_loss':best_eval_loss})\n",
        "                  \n",
        "                if best_eval_accuracy < dev_acc.avg:\n",
        "                    best_eval_accuracy = dev_acc.avg\n",
        "                    torch.save(model.state_dict(), f'{SAVE_PATH}/{fold_num+1}-fold-{CFG.num_folds}-best-eval-accuracy-model.pt')\n",
        "                    print('Saved model with highest validation accuracy: {:.4f}'.format(best_eval_accuracy))\n",
        "                    wandb.log({'best_eval_accuracy':best_eval_accuracy})\n",
        "                \n",
        "                if best_f1_score < dev_f1.avg:\n",
        "                    best_f1_score = dev_f1.avg\n",
        "                    torch.save(model.state_dict(), f'{SAVE_PATH}/{fold_num+1}-fold-{CFG.num_folds}-best-eval-f1-model.pt')\n",
        "                    print('Saved model with highest validation f1: {:.4f}'.format(best_f1_score))\n",
        "                    wandb.log({'best_f1_score':best_f1_score})\n",
        "\n",
        "                # reset metrics\n",
        "                dev_loss.reset()\n",
        "                dev_acc.reset()\n",
        "                dev_f1.reset()\n",
        "                \n",
        "                train_acc.reset()\n",
        "                train_loss.reset()\n",
        "                train_f1.reset()\n",
        "                \n",
        "\n",
        "    # Prevent OOM error\n",
        "    model.cpu()\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    clear_output()"
      ],
      "metadata": {
        "id": "6quLf6ysloL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_to_label(label):\n",
        "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
        "    list_str_label = []\n",
        "\n",
        "    for i, v in enumerate(label):\n",
        "        list_str_label.append(label_dict[v])\n",
        "    \n",
        "    return list_str_label"
      ],
      "metadata": {
        "id": "wpKufvfEloJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "test_dataset = pd.read_csv(TEST_FILE_PATH)\n",
        "display(test_dataset.head(2))"
      ],
      "metadata": {
        "id": "2WpSsF32loHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_dataset_shuffled = test_dataset.sort_values(by=[\"source_label\"]).iloc[::-1] # order by source label: 영화 -> 여행 -> 일반\n",
        "test_dataset_shuffled.head(3)"
      ],
      "metadata": {
        "id": "rqldTzAFloEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def literal_eval_without_error(input_string):\n",
        "    # string [0.2765555, 0.7233189, 6.404926e-05, 6.1491264e-05] into list [0.2765555, 0.7233189, 6.404926e-05, 6.1491264e-05]\n",
        "    input_string = input_string[1:-1]\n",
        "    input_list = input_string.split(\",\")\n",
        "    output_list = [item.strip() for item in input_list]\n",
        "    output_list = [float(item) for item in input_list]\n",
        "    return output_list\n",
        "\n",
        "\n",
        "test_dataset_shuffled[\"electra_premise_probability\"] = test_dataset_shuffled[\"electra_premise_probability\"].apply(literal_eval_without_error)\n",
        "test_dataset_shuffled[\"electra_hypothesis_probability\"] = test_dataset_shuffled[\"electra_hypothesis_probability\"].apply(literal_eval_without_error)\n",
        "test_dataset_shuffled[\"electra_premise_score_probability\"] = test_dataset_shuffled[\"electra_premise_score_probability\"].apply(literal_eval_without_error)\n",
        "test_dataset_shuffled[\"electra_hypothesis_score_probability\"] = test_dataset_shuffled[\"electra_hypothesis_score_probability\"].apply(literal_eval_without_error)\n",
        "\n",
        "display(test_dataset_shuffled.head(6))\n",
        "display(test_dataset_shuffled.tail(6))"
      ],
      "metadata": {
        "id": "OraMSpM8lBAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_dataset = preprocess_augmentation_electra(\n",
        "    test_dataset_shuffled, \n",
        "    str_premise_start_special_token = \"[PREMISE]\", \n",
        "    str_premise_end_special_token = \"[PREMISE]\", \n",
        "    str_hypothesis_start_special_token = \"[HYPOTHESIS]\",\n",
        "    str_hypothesis_end_special_token = \"[HYPOTHESIS]\",\n",
        "    is_test = True\n",
        ")\n",
        "\n",
        "# set label as 100 \n",
        "df_test_dataset['label'] = 100"
      ],
      "metadata": {
        "id": "d1NWHoL3lvw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = IBDataset(df_test_dataset, is_training=False)\n",
        "print(len(test_set))\n",
        "test_data_loader = DataLoader(\n",
        "    test_set, \n",
        "    batch_size=CFG.val_batch_size, \n",
        "    num_workers=CFG.num_workers, \n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "len(test_data_loader)"
      ],
      "metadata": {
        "id": "laDefPoglvuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn import functional as F\n",
        "import shutil\n",
        "\n",
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]\n",
        "\n",
        "CRITERIA_LIST = [\"accuracy\", \"f1\", \"loss\" ]\n",
        "CRITERIA =\"f1\"\n",
        "DIR_PATH = f\"/content/results/{run_name}\" # or \"/content/\"\n",
        "\n",
        "oof_pred = [] # out of fold prediction list\n",
        "for i in range(CFG.num_folds) :\n",
        "    model_path = f'{DIR_PATH}/{i+1}-fold-{CFG.num_folds}-best-eval-{CRITERIA}-model.pt'\n",
        "    model = ArcFaceIBModel(\n",
        "        CFG.model_name, \n",
        "        dropout_rate = CFG.dropout_rate,\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    list_logits = []\n",
        "    for i, data in enumerate(tqdm(test_data_loader)) :\n",
        "        with torch.no_grad():\n",
        "            logit_output = model(\n",
        "              input_ids = data['input_ids'].to(device),\n",
        "              attention_mask = data['attention_mask'].to(device),\n",
        "              premise_special_token_index = data['premise_special_token_index'].to(device),\n",
        "              hypothesis_special_token_index = data['hypothesis_special_token_index'].to(device),\n",
        "              labels=None\n",
        "            )\n",
        "        list_logits.extend(logit_output.cpu().detach().numpy())\n",
        "    output_probs = F.softmax(torch.Tensor(list_logits), dim=1)\n",
        "    oof_pred.append(np.array(output_probs)[:,np.newaxis])\n",
        "\n",
        "    # Prevent OOM error\n",
        "    model.cpu()\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "SyLQA2T_lvrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean probability of fold predictions\n",
        "oof_pred_mean = np.mean(oof_pred, axis=0)\n",
        "print(oof_pred_mean.shape) # (1666, 1, 3)\n",
        "print(oof_pred_mean[:10])"
      ],
      "metadata": {
        "id": "0BeSNCO-l0qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_label = []\n",
        "all_probability = []\n",
        "for pred in oof_pred_mean:\n",
        "  probability = flatten(pred)\n",
        "  all_probability.append(probability)\n",
        "  single_label = np.argmax(probability)\n",
        "  all_label.append(single_label)\n",
        "\n",
        "df_oof = df_test_dataset.copy()\n",
        "df_oof[\"label\"] = num_to_label(all_label)\n",
        "df_oof[\"label\"] = df_oof[\"label\"].str.strip()\n",
        "df_oof[\"probability\"] = all_probability\n",
        "df_oof = df_oof.sort_values(by=['index']).reset_index(drop=True)\n",
        "df_oof.head(24)"
      ],
      "metadata": {
        "id": "5axpERGjl0oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_oof['label'].value_counts()"
      ],
      "metadata": {
        "id": "dK1xqlABl0lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_name = DIR_PATH.split(\"/\")[-1]\n",
        "print(save_model_name)\n",
        "\n",
        "result_save_path = f'./result-{save_model_name}-{CFG.num_epochs}-epochs-best-{CRITERIA}.csv'\n",
        "df_oof.to_csv(result_save_path, index=False)\n",
        "\n",
        "df_submission = df_oof.copy()\n",
        "df_submission = df_submission.sort_values(by=['index'])\n",
        "df_submission.reset_index(drop=True, inplace=True)\n",
        "df_submission = df_submission[[\"index\", \"label\"]]\n",
        "display(df_submission.head(6))\n",
        "display(df_submission.tail(6))\n",
        "\n",
        "submission_save_path = f'./submission-{save_model_name}-{CFG.num_epochs}-epochs-best-{CRITERIA}.csv'\n",
        "df_submission.to_csv(submission_save_path, index=False)"
      ],
      "metadata": {
        "id": "_cEoJdsWl0iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kglZIbR5lvon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2등 노트북"
      ],
      "metadata": {
        "id": "MZrbF6BN4Oe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Private 3등 | 0.89915 | 2.Custom Model R-Roberta\n",
        "- https://dacon.io/competitions/official/235875/codeshare/4631?page=1&dtype=recent"
      ],
      "metadata": {
        "id": "7QJt3Ey04Z2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keypoint**\n",
        "- 학습 KLUE Official Dev Data를 추가 사용\n",
        "- R-BERT 모델 구조 차용하여 모델 아키텍처 수정\n",
        "-  5-Fold Soft Ensemble 을 시도하려 했지만 4번째와 5번째 Fold만 학습완료\n",
        "- 이들 중 Public Score 0.897을 기록한 4번째 Fold 모델만을 Inference에 사용"
      ],
      "metadata": {
        "id": "p31NnPWY46SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers wandb"
      ],
      "metadata": {
        "id": "bmPzeqnw4ucH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle as pickle\n",
        "import os\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "tqdm.pandas()\n",
        "# Step 4. 한글 글꼴 설정\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pprint import  pprint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from collections import defaultdict, Counter\n",
        "from itertools import chain\n",
        "from pprint import pprint\n",
        "import wandb\n",
        "# from pycaret.classification import *\n",
        "# from pycaret.regression import *\n",
        "# from pycaret.utils import check_metric\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoConfig\n",
        "from transformers import BertConfig, BertForSequenceClassification, Trainer, TrainingArguments, BertModel, ElectraModel, RobertaModel\n",
        "from importlib import import_module\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "def seed_everything(seed: int = 42, contain_cuda: bool = False):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    print(f\"Seed set as {seed}\")\n",
        "\n",
        "seed=42\n",
        "seed_everything(seed)\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "project_folder = \"Konli\"\n",
        "os.chdir(os.path.join(root_dir,project_folder))\n"
      ],
      "metadata": {
        "id": "_0cBrBqSmAhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrong_batch_for_wandb(tokenizer,\n",
        "                          wrong_sample_index,\n",
        "                          input_ids,\n",
        "                          valid_labels,\n",
        "                          valid_predict,\n",
        "                          valid_output,\n",
        "                          ):\n",
        "    num_to_label_dict = {0:'entailment',1:'contradiction',2:'neutral',}\n",
        "\n",
        "    wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n",
        "    wrong_sample_text = [tokenizer.decode(element, skip_special_tokens=False) for element in input_ids[wrong_sample_index]]\n",
        "    wrong_sample_label = [num_to_label_dict[lab] for lab in list(valid_labels[wrong_sample_index])]\n",
        "    wrong_sample_pred = [num_to_label_dict[pred] for pred in list(valid_predict[wrong_sample_index])]\n",
        "    wrong_sample_output = valid_output[wrong_sample_index].tolist()\n",
        "\n",
        "    entailment_prob, contradiction_prob, neutral_prob = [], [], []\n",
        "    for element in wrong_sample_output:\n",
        "        entailment_prob.append(element[0])\n",
        "        contradiction_prob.append(element[1])\n",
        "        neutral_prob.append(element[2])\n",
        "\n",
        "    return wrong_sample_text, wrong_sample_label, wrong_sample_pred, entailment_prob, contradiction_prob, neutral_prob\n"
      ],
      "metadata": {
        "id": "Oi6VzVWwmAfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 구성.\n",
        "class NLI_Dataset(Dataset):\n",
        "    def __init__(self, tokenized_dataset, labels):\n",
        "        self.tokenized_dataset = tokenized_dataset\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.tokenized_dataset.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "6zUCmKmdmAdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_dataset(args, dataset):\n",
        "\n",
        "    if 'answer' not in dataset.label: # Train Data일 때에만\n",
        "        dataset = dataset.loc[dataset.label.isnull()==False,:] # label 기준으로 결측치 있는 행 제거\n",
        "        dataset = dataset.drop_duplicates(['premise','hypothesis','label']) # 중복되는 데이터가 있었네.. 중복제거\n",
        "\n",
        "        # # Test Set에는 없는 특수문자 포함한 문장들이 Train Set에 존재.\n",
        "        # # 오히려 학습에 혼란을 주는 것 같은데.. 제거할지 말지 고민중\n",
        "        # dataset = dataset.loc[dataset.premise.apply(lambda x: '\"' in x)==False]\n",
        "        # dataset = dataset.loc[dataset.premise.apply(lambda x: '\"' in x)==False]\n",
        "        # dataset = dataset.loc[dataset.premise.apply(lambda x: '%' in x)==False] # 제거해야하나..\n",
        "        # dataset = dataset.loc[dataset.premise.apply(lambda x: '~' in x)==False] # 제거해야하나..\n",
        "\n",
        "        # Label Encoding\n",
        "        label_to_num_dict = {'entailment':0,'contradiction':1,'neutral':2,}\n",
        "        dataset['labels'] = dataset.label.map(label_to_num_dict)\n",
        "\n",
        "    return dataset.reset_index(drop=True)\n",
        "\n",
        "def load_data(args, dataset_dir):\n",
        "    print(\"===================loading data=====================\")\n",
        "    # load dataset\n",
        "    dataset = pd.read_csv(dataset_dir)\n",
        "    \n",
        "    # preprecessing dataset\n",
        "    dataset = preprocessing_dataset(args, dataset)\n",
        "    # print(dataset)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# bert input을 위한 tokenizing.\n",
        "def tokenized_dataset(args, dataset, tokenizer):\n",
        "    lst_premise = dataset['premise'].tolist()\n",
        "    lst_hypothesis = dataset['hypothesis'].tolist()\n",
        "\n",
        "    tokenized_sentences = tokenizer(\n",
        "        lst_premise,\n",
        "        lst_hypothesis,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=args.seq_max_len,\n",
        "        add_special_tokens=True\n",
        "    )\n",
        "\n",
        "    return tokenized_sentences\n",
        "\n",
        "    all_dataset = load_data(args, dataset_dir = f'./data/{args.train_file}')\n",
        "\n",
        "def add_extra_data(args, dataset, label):\n",
        "    if args.add_klue_data==True:\n",
        "        klue_extra_data = load_data(args, dataset_dir = f'./data/klue_extra_data.csv')\n",
        "        klue_extra_label = klue_extra_data['labels'].values\n",
        "        dataset = pd.concat([dataset, klue_extra_data],axis=0)\n",
        "        label = np.hstack([label, klue_extra_label])\n",
        "    if args.add_nikl_data==True:\n",
        "        nikl_extra_data = load_data(args, dataset_dir = f'./data/nikl_extra_data.csv')\n",
        "        nikl_extra_label = nikl_extra_data['labels'].values\n",
        "        dataset = pd.concat([dataset, nikl_extra_data],axis=0)\n",
        "        label = np.hstack([label, nikl_extra_label])\n",
        "    dataset.reset_index(drop=True, inplace=True)\n",
        "    return dataset, label"
      ],
      "metadata": {
        "id": "Jqbr5eYMmAa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainLoader(args, train_data, valid_data, train_label, valid_label, tokenizer):\n",
        "\n",
        "    # entity_between = '</s></s>' if args.model == 'r_roberta' or args.model == 'roberta' else '[SEP]'\n",
        "    tokenized_train = tokenized_dataset(args, train_data, tokenizer)\n",
        "    tokenized_valid = tokenized_dataset(args, valid_data, tokenizer)\n",
        "\n",
        "    # make dataset for pytorch.\n",
        "    NLI_train_dataset = NLI_Dataset(tokenized_train, train_label)\n",
        "    NLI_valid_dataset = NLI_Dataset(tokenized_valid, valid_label)\n",
        "\n",
        "    trainloader = DataLoader(NLI_train_dataset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             shuffle=True,\n",
        "                             num_workers=args.num_workers,\n",
        "                             )\n",
        "\n",
        "    validloader = DataLoader(NLI_valid_dataset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             shuffle=False,\n",
        "                             num_workers=args.num_workers,\n",
        "                             )\n",
        "\n",
        "    return trainloader, validloader\n"
      ],
      "metadata": {
        "id": "Zqa9e7OfmAYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import math\n",
        "\n",
        "class AdamP(Optimizer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        params,\n",
        "        lr=1e-3,\n",
        "        betas=(0.9, 0.999),\n",
        "        eps=1e-8,\n",
        "        weight_decay=0,\n",
        "        delta=0.1,\n",
        "        wd_ratio=0.1,\n",
        "        nesterov=False,\n",
        "    ):\n",
        "        defaults = dict(\n",
        "            lr=lr,\n",
        "            betas=betas,\n",
        "            eps=eps,\n",
        "            weight_decay=weight_decay,\n",
        "            delta=delta,\n",
        "            wd_ratio=wd_ratio,\n",
        "            nesterov=nesterov,\n",
        "        )\n",
        "        super(AdamP, self).__init__(params, defaults)\n",
        "\n",
        "    def _channel_view(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "    def _layer_view(self, x):\n",
        "        return x.view(1, -1)\n",
        "\n",
        "    def _cosine_similarity(self, x, y, eps, view_func):\n",
        "        x = view_func(x)\n",
        "        y = view_func(y)\n",
        "\n",
        "        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n",
        "\n",
        "    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n",
        "        wd = 1\n",
        "        expand_size = [-1] + [1] * (len(p.shape) - 1)\n",
        "        for view_func in [self._channel_view, self._layer_view]:\n",
        "\n",
        "            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n",
        "\n",
        "            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n",
        "                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n",
        "                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n",
        "                wd = wd_ratio\n",
        "\n",
        "                return perturb, wd\n",
        "\n",
        "        return perturb, wd\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad.data\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "                nesterov = group[\"nesterov\"]\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state[\"step\"] = 0\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(p.data)\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n",
        "\n",
        "                # Adam\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "                bias_correction1 = 1 - beta1 ** state[\"step\"]\n",
        "                bias_correction2 = 1 - beta2 ** state[\"step\"]\n",
        "\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
        "\n",
        "                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(\n",
        "                    group[\"eps\"]\n",
        "                )\n",
        "                step_size = group[\"lr\"] / bias_correction1\n",
        "\n",
        "                if nesterov:\n",
        "                    perturb = (beta1 * exp_avg + (1 - beta1) * grad) / denom\n",
        "                else:\n",
        "                    perturb = exp_avg / denom\n",
        "\n",
        "                # Projection\n",
        "                wd_ratio = 1\n",
        "                if len(p.shape) > 1:\n",
        "                    perturb, wd_ratio = self._projection(\n",
        "                        p,\n",
        "                        grad,\n",
        "                        perturb,\n",
        "                        group[\"delta\"],\n",
        "                        group[\"wd_ratio\"],\n",
        "                        group[\"eps\"],\n",
        "                    )\n",
        "\n",
        "                # Weight decay\n",
        "                if group[\"weight_decay\"] > 0:\n",
        "                    p.data.mul_(1 - group[\"lr\"] * group[\"weight_decay\"] * wd_ratio)\n",
        "\n",
        "                # Step\n",
        "                p.data.add_(perturb, alpha=-step_size)\n",
        "\n",
        "        return loss\n",
        "\n",
        "def get_optimizer(model, args):\n",
        "    if args.optimizer == \"Adam\":\n",
        "        optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=0.01)\n",
        "    elif args.optimizer == \"AdamW\":\n",
        "        optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=0.01)\n",
        "    elif args.optimizer == \"AdamP\":\n",
        "        optimizer = AdamP(\n",
        "            model.parameters(),\n",
        "            lr=args.lr,\n",
        "            betas=(0.9, 0.999),\n",
        "            weight_decay=0.01,\n",
        "            delta=0.1,\n",
        "            wd_ratio=0.1,\n",
        "            nesterov=False,\n",
        "        )\n",
        "\n",
        "\n",
        "    # 모든 parameter들의 grad값을 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "dlp60e5vmAV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, _LRScheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup/blob/master/cosine_annearing_with_warmup.py\n",
        "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
        "    \"\"\"\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        first_cycle_steps (int): First cycle step size.\n",
        "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
        "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
        "        min_lr(float): Min learning rate. Default: 0.001.\n",
        "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
        "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 optimizer : torch.optim.Optimizer,\n",
        "                 first_cycle_steps : int,\n",
        "                 cycle_mult : float = 1.,\n",
        "                 max_lr : float = 0.1,\n",
        "                 min_lr : float = 0.001,\n",
        "                 warmup_steps : int = 0,\n",
        "                 gamma : float = 1.,\n",
        "                 last_epoch : int = -1\n",
        "        ):\n",
        "        assert warmup_steps < first_cycle_steps\n",
        "        \n",
        "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
        "        self.base_max_lr = max_lr # first max learning rate\n",
        "        self.max_lr = max_lr # max learning rate in the current cycle\n",
        "        self.min_lr = min_lr # min learning rate\n",
        "        self.warmup_steps = warmup_steps # warmup step size\n",
        "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
        "        \n",
        "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle = 0 # cycle count\n",
        "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
        "        \n",
        "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "        # set learning rate min_lr\n",
        "        self.init_lr()\n",
        "    \n",
        "    def init_lr(self):\n",
        "        self.base_lrs = []\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.min_lr\n",
        "            self.base_lrs.append(self.min_lr)\n",
        "    \n",
        "    def get_lr(self):\n",
        "        if self.step_in_cycle == -1:\n",
        "            return self.base_lrs\n",
        "        elif self.step_in_cycle < self.warmup_steps:\n",
        "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr + (self.max_lr - base_lr) \\\n",
        "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
        "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "            self.step_in_cycle = self.step_in_cycle + 1\n",
        "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
        "                self.cycle += 1\n",
        "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
        "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
        "        else:\n",
        "            if epoch >= self.first_cycle_steps:\n",
        "                if self.cycle_mult == 1.:\n",
        "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
        "                    self.cycle = epoch // self.first_cycle_steps\n",
        "                else:\n",
        "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
        "                    self.cycle = n\n",
        "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
        "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
        "            else:\n",
        "                self.cur_cycle_steps = self.first_cycle_steps\n",
        "                self.step_in_cycle = epoch\n",
        "                \n",
        "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
        "        self.last_epoch = math.floor(epoch)\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, args, total_batch_):\n",
        "    if args.scheduler == \"plateau\":\n",
        "        scheduler = ReduceLROnPlateau(\n",
        "            optimizer, patience=2, factor=0.85, mode=\"max\", verbose=True\n",
        "        )\n",
        "    elif args.scheduler == \"linear\":\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            # num_warmup_steps=int(total_batch_*args.epochs*0.1),\n",
        "            num_warmup_steps=args.warmup_steps,\n",
        "            num_training_steps=int(total_batch_*args.epochs),\n",
        "        )\n",
        "    elif args.scheduler == \"cosine\":\n",
        "        scheduler = CosineAnnealingWarmupRestarts( # ver1: first_cycle=20, warmup_steps=5, cycle_mult=1.0, max_lr=args.lr, min_lr=args.lr/100, gamma=0.8, patience=7, \n",
        "            optimizer,                             # ver2: first_cycle=30, warmup_steps=5, cycle_mult=0.8, max_lr=args.lr, min_lr=args.lr/100, gamma=0.8, patience=5\n",
        "            first_cycle_steps=300,                  # ver3: first_cycle=50, warmup_steps=10, cycle_mult=1.0, max_lr=args.lr, min_lr=args.lr/100, gamma=0.8, patience=7\n",
        "            warmup_steps=args.warmup_steps,\n",
        "            cycle_mult=args.cycle_mult,\n",
        "            max_lr=args.lr,\n",
        "            min_lr=args.lr * 0.01,\n",
        "            gamma=0.8,\n",
        "        )\n",
        "\n",
        "    return scheduler\n",
        "\n"
      ],
      "metadata": {
        "id": "cqBRSSUUmMCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class kobert_Classifier(nn.Module):\n",
        "    def __init__(self, bert, hidden_size=768, num_classes=3, dr_rate=0.0):\n",
        "        super(kobert_Classifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.pooler = nn.Linear(hidden_size, hidden_size)\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def forward(self, token_ids, attention_mask, segment_ids):\n",
        "        # TypeError: dropout(): argument 'input' (position 1) must be Tensor, not tuple\n",
        "        out = self.bert(input_ids=token_ids, attention_mask=attention_mask, token_type_ids=segment_ids)[0]\n",
        "        out = out[:, 0, :]\n",
        "        out = self.pooler(out)\n",
        "        out = torch.nn.functional.tanh(out)  # although BERT uses tanh here, it seems Electra authors used gelu here\n",
        "\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(out)\n",
        "        \n",
        "        return self.classifier(out)\n",
        "    \n",
        "\n",
        "class roberta_large_Classifier(nn.Module):\n",
        "    def __init__(self, roberta, hidden_size=1024, num_classes=3, dr_rate=0.0):\n",
        "        super(roberta_large_Classifier, self).__init__()\n",
        "        self.roberta = roberta\n",
        "        self.dr_rate = dr_rate\n",
        "        \n",
        "        self.pooler = FCLayer(hidden_size, hidden_size//2, self.dr_rate)\n",
        "        self.classifier = FCLayer(hidden_size//2, num_classes, self.dr_rate, False)\n",
        "\n",
        "    def forward(self, token_ids, attention_mask, segment_ids=None):\n",
        "        out = self.roberta(input_ids=token_ids, attention_mask=attention_mask)[0]\n",
        "        \n",
        "        out = out[:, 0, :] # take <s> token (equiv. to [CLS])\n",
        "        out = self.pooler(out)\n",
        "\n",
        "        return self.classifier(out)\n",
        "\n",
        "\n",
        "# Relation Extraction R-BERT 아이디어 차용\n",
        "# https://github.com/monologg/R-BERT/blob/master/model.py#L21\n",
        "class r_roberta_Classifier(nn.Module):\n",
        "    def __init__(self, roberta, hidden_size=1024, num_classes=3, dr_rate=0.0):\n",
        "        super(r_roberta_Classifier, self).__init__()\n",
        "        self.roberta = roberta\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.cls_fc = FCLayer(hidden_size, hidden_size//2, self.dr_rate)\n",
        "        self.sentence_fc = FCLayer(hidden_size, hidden_size//2, self.dr_rate)\n",
        "        self.label_classifier = FCLayer(hidden_size//2 * 3, num_classes, self.dr_rate, False)\n",
        "\n",
        "    def forward(self, token_ids, attention_mask, segment_ids=None):\n",
        "        out = self.roberta(input_ids=token_ids, attention_mask=attention_mask)[0]\n",
        "        \n",
        "        sentence_end_position = torch.where(token_ids == 2)[1]\n",
        "        sent1_end, sent2_end = sentence_end_position[0], sentence_end_position[1]\n",
        "        \n",
        "        cls_vector = out[:, 0, :] # take <s> token (equiv. to [CLS])\n",
        "        prem_vector = out[:,1:sent1_end]              # Get Premise vector\n",
        "        hypo_vector = out[:,sent1_end+1:sent2_end]    # Get Hypothesis vector\n",
        "\n",
        "        prem_vector = torch.mean(prem_vector, dim=1) # Average\n",
        "        hypo_vector = torch.mean(hypo_vector, dim=1)\n",
        "\n",
        "        \n",
        "        # Dropout -> tanh -> fc_layer (Share FC layer for premise and hypothesis)\n",
        "        cls_embedding = self.cls_fc(cls_vector)\n",
        "        prem_embedding = self.sentence_fc(prem_vector)\n",
        "        hypo_embedding = self.sentence_fc(hypo_vector)\n",
        "        \n",
        "        # Concat -> fc_layer\n",
        "        concat_embedding = torch.cat([cls_embedding, prem_embedding, hypo_embedding], dim=-1)\n",
        "        \n",
        "        return self.label_classifier(concat_embedding)\n",
        "\n",
        "\n",
        "class FCLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
        "        super(FCLayer, self).__init__()\n",
        "        self.use_activation = use_activation\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        if self.use_activation:\n",
        "            x = self.tanh(x)\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "Mp_xnuqbmL_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(args):\n",
        "    if args.model == 'kobert':\n",
        "        # tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
        "        \n",
        "    elif args.model == 'klue_roberta_large':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "    elif args.model == 'r_klue_roberta':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "    elif args.model == 'r_roberta':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "\n",
        "    else:\n",
        "    \traise NotImplementedError('Tokenizer & Model not available')\n",
        "\n",
        "    return tokenizer\n"
      ],
      "metadata": {
        "id": "EOHSFmTXmL9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(args):\n",
        "    if args.model == 'kobert':\n",
        "    \t# feature_model = BertModel.from_pretrained(\"monologg/kobert\")\n",
        "    \tfeature_model = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "    \tmodel = kobert_Classifier(feature_model, dr_rate=args.dp)\n",
        "\n",
        "    elif args.model == 'klue_roberta_large':\t# 1024\n",
        "        feature_model = RobertaModel.from_pretrained(\"klue/roberta-large\", add_pooling_layer=False)\n",
        "        model = roberta_large_Classifier(feature_model, dr_rate=args.dp)\n",
        "\n",
        "    elif args.model == 'r_roberta':\n",
        "        feature_model = RobertaModel.from_pretrained(\"xlm-roberta-large\", add_pooling_layer=False)\n",
        "        model = r_roberta_Classifier(feature_model, dr_rate=args.dp)\n",
        "    \n",
        "    elif args.model == 'r_klue_roberta':\n",
        "        feature_model = RobertaModel.from_pretrained(\"klue/roberta-large\", add_pooling_layer=False)\n",
        "        model = r_roberta_Classifier(feature_model, dr_rate=args.dp)\n",
        "\n",
        "    else:\n",
        "    \traise NotImplementedError('Tokenizer & Model not available')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "JDSZe0MgmL61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None,\n",
        "                 gamma=2., reduction='mean'):\n",
        "        nn.Module.__init__(self)\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input_tensor, target_tensor):\n",
        "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
        "        prob = torch.exp(log_prob)\n",
        "        return F.nll_loss(\n",
        "            ((1 - prob) ** self.gamma) * log_prob,\n",
        "            target_tensor,\n",
        "            weight=self.weight,\n",
        "            reduction=self.reduction\n",
        "        )\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
        "\n",
        "\n",
        "def get_criterion(args):\n",
        "    if args.smoothing!=0 and args.criterion == 'smoothing':\n",
        "        criterion = LabelSmoothingLoss(smoothing=args.smoothing)\n",
        "    elif args.criterion == 'cross':\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    elif args.criterion == 'focal':\n",
        "        criterion = FocalLoss(gamma=2.0)\n",
        "    else:\n",
        "        raise NotImplementedError('Criterion not available')\n",
        "    return criterion"
      ],
      "metadata": {
        "id": "79onVVu4mL3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, wandb, fold_lst=[4,5]):\n",
        "    criterion = get_criterion(args)\n",
        "    tokenizer = get_tokenizer(args)\n",
        "    all_dataset = load_data(args, dataset_dir = f'./data/{args.train_file}')\n",
        "    all_label = all_dataset['labels'].values\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=args.n_splits, random_state=42, shuffle=True)\n",
        "    fold_idx = 1\n",
        "    best_val_acc_list = []\n",
        "    for train_index, test_index in kf.split(all_dataset, all_label):\n",
        "        if fold_idx not in fold_lst:\n",
        "            fold_idx+=1\n",
        "            continue\n",
        "\n",
        "        run = wandb.init(project=args.project_name)\n",
        "        wandb.run.name = f'{args.model_name}/{fold_idx}-fold'\n",
        "        wandb.config.update(args)\n",
        "\n",
        "        os.makedirs(f'./models/{args.model_name}/{fold_idx}-fold', exist_ok=True)\n",
        "        ### Model Select\n",
        "        model = get_model(args)\n",
        "        print('===================get model===================')\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        train_data, valid_data = all_dataset.iloc[train_index], all_dataset.iloc[test_index]\n",
        "        train_label, valid_label = all_label[train_index], all_label[test_index]\n",
        "        \n",
        "        print(f\"len(train_label) : {len(train_label)}\")\n",
        "        print(f\"len(train_data) : {len(train_data)}\")\n",
        "        if args.add_klue_data or args.add_nikl_data: # 외부 데이터 활용\n",
        "            train_data, train_label = add_extra_data(args, train_data, train_label)\n",
        "            print('='*15,'Extra Data Added','='*15)\n",
        "        print(f\"len(train_label) : {len(train_label)}\")\n",
        "        print(f\"len(train_data) : {len(train_data)}\")\n",
        "\n",
        "        trainloader, validloader = get_trainLoader(args, train_data, valid_data, train_label, valid_label, tokenizer)\t\n",
        "        total_batch_ = len(trainloader)\n",
        "        valid_batch_ = len(validloader)\n",
        "\n",
        "        ### Optimizer\n",
        "        optimizer = get_optimizer(model, args)\n",
        "\n",
        "        ### Scheduler\n",
        "        scheduler = get_scheduler(optimizer, args, total_batch_)\n",
        "\n",
        "        best_val_loss, best_val_acc, = np.inf, 0\n",
        "        early_stopping_counter = 0\n",
        "\n",
        "        print(f\"---------------------------------- {fold_idx} fold----------------------------------\")\t\n",
        "        for i in tqdm(range(1, args.epochs+1)):\n",
        "            model.train()\n",
        "            epoch_perform, batch_perform = np.zeros(2), np.zeros(2)\t\n",
        "            print()\n",
        "            progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), leave=True, position=0,)\n",
        "            for j, v in progress_bar:\n",
        "                input_ids, attention_mask, labels = v['input_ids'].to(device), v['attention_mask'].to(device), v['labels'].to(device)\n",
        "\n",
        "                if 'roberta' in args.model:\n",
        "                    token_type_ids = None\n",
        "                else:\n",
        "                    token_type_ids = v['token_type_ids'].to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                output = model(input_ids, attention_mask, token_type_ids) ## label을 안 넣어서 logits값만 출력\t\n",
        "\n",
        "                loss = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                for learning_rate in scheduler.get_lr():\n",
        "                    wandb.log({\"learning_rate\": learning_rate})\n",
        "\n",
        "\n",
        "                predict = output.argmax(dim=-1)\n",
        "                predict = predict.detach().cpu().numpy()\n",
        "                labels = labels.detach().cpu().numpy()\t\n",
        "                acc = accuracy_score(labels, predict)\n",
        "\n",
        "                batch_perform += np.array([loss.item(), acc])\n",
        "                epoch_perform += np.array([loss.item(), acc])\n",
        "\n",
        "                if (j + 1) % 50 == 0:\n",
        "                    print(\n",
        "                        f\"Epoch {i:#04d} #{j + 1:#03d} -- loss: {batch_perform[0] / 50:#.5f}, acc: {batch_perform[1] / 50:#.4f}\"\n",
        "                        )\n",
        "                    batch_perform = np.zeros(2)\n",
        "            print()\n",
        "            print(\n",
        "                f\"Epoch {i:#04d} loss: {epoch_perform[0] / total_batch_:#.5f}, acc: {epoch_perform[1] / total_batch_:#.2f}\"\n",
        "                )\n",
        "            wandb.log({\n",
        "                \"epoch\": i,\n",
        "                \"Train epoch Loss\": epoch_perform[0] / total_batch_,\n",
        "                \"Train epoch Acc\": epoch_perform[1] / total_batch_}\n",
        "                )\n",
        "            \n",
        "            ###### Validation\t\n",
        "            model.eval()\n",
        "            valid_perform = np.zeros(2)\n",
        "\n",
        "            all_valid_predict_lst = []\n",
        "            all_valid_labels_lst = []\n",
        "\n",
        "            # 틀린 데이터들을 wandb 기록하기 위함.\n",
        "            wrong_sample_dict = defaultdict(list)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for v in validloader:\n",
        "                    input_ids, attention_mask, valid_labels = v['input_ids'].to(device), v['attention_mask'].to(device), v['labels'].to(device)\n",
        "\n",
        "                    if 'roberta' in args.model:\n",
        "                        token_type_ids = None\n",
        "                    else:\n",
        "                        token_type_ids = v['token_type_ids'].to(device)\n",
        "\n",
        "                    valid_output = model(input_ids, attention_mask, token_type_ids)\n",
        "                    valid_loss = criterion(valid_output, valid_labels)\t\n",
        "\n",
        "                    valid_predict = valid_output.argmax(dim=-1)\n",
        "                    valid_predict = valid_predict.detach().cpu().numpy()\n",
        "                    valid_labels = valid_labels.detach().cpu().numpy()\t\n",
        "\n",
        "                    ###########################\n",
        "                    # valid eval 결과, 틀린 데이터들은 wandb에 Logging\n",
        "                    if args.logging_wrong_samples:\n",
        "                        wrong_sample_index = np.where(valid_labels!=valid_predict)[0]\n",
        "                        if len(wrong_sample_index)>0:\n",
        "                            wrong_sample_text, wrong_sample_label, wrong_sample_pred, entailment_prob, contradiction_prob, neutral_prob = wrong_batch_for_wandb(tokenizer, wrong_sample_index, input_ids, valid_labels, valid_predict, valid_output)\n",
        "\n",
        "                            wrong_sample_dict['입력 문장 Pair'] += wrong_sample_text\n",
        "                            wrong_sample_dict['실제값'] += wrong_sample_label\n",
        "                            wrong_sample_dict['예측값'] += wrong_sample_pred\n",
        "                            wrong_sample_dict['entailment_logit'] += entailment_prob\n",
        "                            wrong_sample_dict['contradiction_logit'] += contradiction_prob\n",
        "                            wrong_sample_dict['neutral_logit'] += neutral_prob\n",
        "                    ###########################\n",
        "\n",
        "                    valid_acc = accuracy_score(valid_labels, valid_predict)\t\n",
        "                    valid_perform += np.array([valid_loss.item(), valid_acc])\n",
        "\n",
        "                    all_valid_predict_lst += list(valid_predict)\n",
        "                    all_valid_labels_lst += list(valid_labels)\n",
        "            \n",
        "            ###### Model save\n",
        "            val_total_loss = valid_perform[0] / valid_batch_\n",
        "            val_total_acc = valid_perform[1] / valid_batch_\n",
        "            best_val_loss = min(best_val_loss, val_total_loss)\n",
        "        \n",
        "            if val_total_acc > best_val_acc:    #  and val_total_acc >= 0.25\n",
        "                print(f\"New best model for val accuracy : {val_total_acc:#.4f}! saving the best model..\")\n",
        "                torch.save(model.state_dict(), f\"./models/{args.model_name}/{fold_idx}-fold/best.pt\")\n",
        "                \n",
        "                # 참고 : Model 추가 재학습을 위한 모델을 저장하는 코드\n",
        "                # https://tutorials.pytorch.kr/beginner/saving_loading_models.html#checkpoint\n",
        "\n",
        "                best_val_acc = val_total_acc\n",
        "                early_stopping_counter = 0\n",
        "\n",
        "                ### Confusion Matrix\n",
        "                class_names = ['entailment','contradiction','neutral'] # (0,1,2)\n",
        "                # https://wandb.ai/wandb/plots/reports/Confusion-Matrix--VmlldzozMDg1NTM\n",
        "                wandb.log({f\"{i}th_epoch_conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                            y_true=all_valid_labels_lst, preds=all_valid_predict_lst,\n",
        "                            class_names=class_names)})\n",
        "                \n",
        "                if args.logging_wrong_samples and val_total_acc > 0.91:\n",
        "                    ########### Logging Wrong Samples ##########\n",
        "                    # Save Wrong DataFrame\n",
        "                    wrong_sample_df = pd.DataFrame(wrong_sample_dict)\n",
        "                    wrong_sample_df.to_csv(f\"./models/{args.model_name}/{fold_idx}-fold/wrong_df.csv\",index=False)\n",
        "                    print('='*15,f'{fold_idx}-Fold Wrong DataFrame Saved','='*15)\n",
        "                    # Loggin Wandb\n",
        "                    text_table = wandb.Table(data = wrong_sample_df)\n",
        "                    run.log({f\"{fold_idx}th_fold_wrong_samples\" : text_table})\n",
        "                    ###########################\n",
        "            \n",
        "            else: # best보다 score가 안 좋을 때, early stopping check\n",
        "                early_stopping_counter += 1\n",
        "                if early_stopping_counter >= args.patience:\n",
        "                    print(\n",
        "                        f\"EarlyStopping counter: {early_stopping_counter} out of {args.patience}\"\n",
        "                    )\n",
        "                    break\n",
        "\n",
        "            print()\n",
        "            print(\n",
        "                f\">>>> Validation loss: {val_total_loss:#.5f}, Acc: {val_total_acc:#.4f}\"\n",
        "                )\n",
        "            print()\n",
        "            wandb.log({\n",
        "                \"epoch\": i,\n",
        "                \"Valid Loss\": val_total_loss,\n",
        "                \"Valid Acc\": val_total_acc}\n",
        "                )\n",
        "\n",
        "        best_val_acc_list.append(best_val_acc)\n",
        "        fold_idx +=1\n",
        "    print('='*50)\n",
        "    print(f\"{args.n_splits}-fold best_val_acc_list : {best_val_acc_list}\")\n",
        "    print('='*15, f'{args.n_splits}-fold Final Score(ACC) : {np.mean(best_val_acc_list)}', '='*15)\n",
        "    wandb.log({\n",
        "    f\"Total Mean ACC ({args.n_splits}-fold)\": np.mean(best_val_acc_list)}\n",
        "    )"
      ],
      "metadata": {
        "id": "Cd3QnXRimATK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easydict\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'current device : {device}')\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "        \"seed\":42,\n",
        "        \"optimizer\":\"AdamW\",    # help = (AdamW, Adam, AdamP)\n",
        "        \"scheduler\":\"linear\",     # help= (linear, cosine, plateau ...)\n",
        "        \"warmup_steps\":500,\n",
        "        \"cycle_mult\":1.2,\n",
        "        \"seq_max_len\":128,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 20,\n",
        "        \"patience\":5,\n",
        "        \"n_splits\" : 5,\n",
        "        \"lr\": 1e-05,\n",
        "        \"num_workers\":2,\n",
        "        \"criterion\":'cross', # 'smoothing','focal','cross'\n",
        "        \"smoothing\": 0.0,\n",
        "        \"dp\": 0.0,\n",
        "        \"model\": \"r_klue_roberta\",  # help='model type (kobert, koelectra, mbert, \n",
        "                                                        # roberta_base, roberta_large, \n",
        "                                                        # klue_roberta_small, klue_roberta_base, klue_roberta_large, klue_roberta_base_nli\n",
        "                                                        # r_roberta, r_klue_roberta)'\n",
        "\n",
        "        \"logging_wrong_samples\":True,\n",
        "        \"train_file\":'train_data.csv',\n",
        "        \"test_file\":'test_data.csv',\n",
        "        \"add_klue_data\":True,\n",
        "        'add_nikl_data':False,\n",
        "    })\n",
        "\n",
        "project_name = f\"{args.model}_Scdu{args.scheduler}_Dp{args.dp}_add_klue_data{args.add_klue_data}_{args.n_splits}Fd_Sm{args.smoothing}_Bs{args.batch_size}_Lr{args.lr}_Ep{args.epochs}_Cy{args.cycle_mult}\"\n",
        "args.update(\n",
        "            {\n",
        "                \"project_name\":project_name,\n",
        "                \"model_name\":project_name,\n",
        "             }\n",
        "            )\n",
        "\n",
        "seed_everything(args.seed)\n"
      ],
      "metadata": {
        "id": "GxMvtU_jmWrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "id": "7YKv1sJBmWm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb logging\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "id": "c4HEZM1vmWkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(args, wandb, fold_lst=[4,5])"
      ],
      "metadata": {
        "id": "fCAGDz-8mWhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_dataset(args, tokenizer):\n",
        "    test_dataset = load_data(args, dataset_dir = f\"./data/{args.test_file}\")\n",
        "    test_label = test_dataset['labels'].values\n",
        "\n",
        "    # # tokenizing dataset\n",
        "    # entity_between = '</s></s>' if 'roberta' in args.model else '[SEP]'\n",
        "\n",
        "    tokenized_test = tokenized_dataset(args, test_dataset, tokenizer)\n",
        "    return tokenized_test, test_label\n",
        "\n",
        "def test_single_main(args, idx):\n",
        "    model = get_model(args)\n",
        "    tokenizer = get_tokenizer(args)\n",
        "    # load test datset\n",
        "    test_dataset, test_label = load_test_dataset(args, tokenizer)\n",
        "    test_dataset = NLI_Dataset(test_dataset, test_label)\n",
        "    testloader = DataLoader(test_dataset,\n",
        "                    shuffle=False,\n",
        "                    batch_size=args.batch_size,\n",
        "                    num_workers=args.num_workers,\n",
        "                    )\n",
        "\n",
        "    load_path = f'./models/{args.model_name}/{idx}-fold/best.pt'\n",
        "    model.load_state_dict(torch.load(load_path,map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    progress_bar = tqdm(enumerate(testloader), total=len(testloader), leave=True, position=0,)\n",
        "    for i, data in progress_bar:\n",
        "        with torch.no_grad():\n",
        "            logits = model(\n",
        "                data['input_ids'].to(device),\n",
        "                data['attention_mask'].to(device),\n",
        "                data['token_type_ids'].to(device)\n",
        "            )\n",
        "        if i==0:\n",
        "            one_fold_logits = logits\n",
        "        else:\n",
        "            one_fold_logits = torch.cat([one_fold_logits,logits],dim=0) # (batchsize,3) + (batchsize,3) -> (batchsize+batchsize,3)\n",
        "\n",
        "    # torch tensor를 저장하기 위한 numpy 변환\n",
        "    one_fold_logits = one_fold_logits.squeeze(0).detach().cpu().numpy()\n",
        "    # numpy array 저장\n",
        "    np.save(f'./models/{args.model_name}/{idx}-fold/numpy_logits', one_fold_logits)\n",
        "    # np_load = np.load(f'./models/{args.model_name}/{idx}-fold/numpy_logits.npy')\n",
        "        \n",
        "    return np.argmax(one_fold_logits, axis=1)"
      ],
      "metadata": {
        "id": "U1Cg1t7FmWen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_path = \"./data/sample_submission.csv\"\n",
        "submission = pd.read_csv(submission_path)"
      ],
      "metadata": {
        "id": "pekaTKermWbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 4\n",
        "single_pred = test_single_main(args, idx)\n",
        "\n",
        "label_to_num_dict = {'entailment':0,'contradiction':1,'neutral':2,}\n",
        "num_to_label_dict = {v:k for k,v in label_to_num_dict.items()}\n",
        "print(f\"len(single_pred) : {len(single_pred)}\")\n",
        "print('='*50)\n",
        "submission['label'] = single_pred\n",
        "# submission['label'] = hard_output\n",
        "submission['label'] = submission['label'].map(num_to_label_dict)\n",
        "submission['label'].value_counts()"
      ],
      "metadata": {
        "id": "z29tNGMgmqYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ky5ub-bmqVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}