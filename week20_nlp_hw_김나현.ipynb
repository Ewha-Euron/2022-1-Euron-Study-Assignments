{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week20_nlp_hw_ê¹€ë‚˜í˜„.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowionlyseedaylight/2022-1-Euron-Study-Assignments/blob/Week_20/week20_nlp_hw_%EA%B9%80%EB%82%98%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ week20 ê³¼ì œëŠ” **18ì£¼ì°¨ì˜ Constituency Parsing TreeRNNS ì‹¤ìŠµ**ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Œ ìœ„í‚¤ë…ìŠ¤ì˜ ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ êµì¬ ì‹¤ìŠµ, ê´€ë ¨ ë¸”ë¡œê·¸ ë“±ì˜ ë¬¸ì„œ ìë£Œë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ” ê³¼ì œì…ë‹ˆë‹¤. \n",
        "\n",
        "ğŸ“Œ ì•ˆë‚´ëœ ë§í¬ì— ë§ì¶”ì–´ **ì§ì ‘ ì½”ë“œë¥¼ ë”°ë¼ ì¹˜ë©´ì„œ (í•„ì‚¬)** í•´ë‹¹ nlp task ì˜ ê¸°ë³¸ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë©”ì„œë“œë¥¼ ìˆ™ì§€í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ğŸ˜Š í•„ìˆ˜ë¼ê³  ì²´í¬í•œ ë¶€ë¶„ì€ ê³¼ì œì— ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì£¼ì‹œê³ , ì„ íƒìœ¼ë¡œ ì²´í¬í•œ ë¶€ë¶„ì€ ììœ¨ì ìœ¼ë¡œ ìŠ¤í„°ë”” í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Œ ê¶ê¸ˆí•œ ì‚¬í•­ì€ ê¹ƒí—ˆë¸Œ ì´ìŠˆë‚˜, ì¹´í†¡ë°©, ì„¸ì…˜ ë°œí‘œ ì‹œì‘ ì´ì „ ì‹œê°„ ë“±ì„ í™œìš©í•˜ì—¬ ììœ ë¡­ê²Œ ê³µìœ í•´ì£¼ì„¸ìš”!"
      ],
      "metadata": {
        "id": "BX3ac8Ag1RPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¥° **ì´í•˜ ì˜ˆì œë¥¼ ì‹¤ìŠµí•˜ì‹œë©´ ë©ë‹ˆë‹¤.**\n",
        "\n",
        "**1-2ëŠ” í•„ìˆ˜ê³¼ì œì…ë‹ˆë‹¤.**\n",
        "\n",
        "ì‹¤ìŠµë³´ë‹¤ëŠ” ê°œë… ì´í•´ê°€ ì£¼ì¸ ë‹¨ì›ì´ë¼, ì‹¤ìŠµ ê³¼ì œëŠ” ì ìŠµë‹ˆë‹¤. TreeRNNì€ í˜„ì‹¤ì ìœ¼ë¡œ ì˜ ì“°ì´ì§€ ì•Šê¸° ë•Œë¬¸ì´ì£ . ì™œ ì˜ ì“°ì´ì§€ ì•Šì„ê¹Œìš”? ì´ ì§ˆë¬¸ì— ëŒ€í•´ ìƒê°í•´ ë³´ëŠ” ê²ƒìœ¼ë¡œ ì´ë²ˆ ê³¼ì œë¥¼ ì‹œì‘í•´ ë´…ì‹œë‹¤."
      ],
      "metadata": {
        "id": "Kq8aMYKGPQR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`your answer here`"
      ],
      "metadata": {
        "id": "ZJLIfgQ9vlNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1ï¸âƒ£ Probabilistic Parsing ì‹¤ìŠµ**"
      ],
      "metadata": {
        "id": "SHTPAk95iNtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ [Probabilistic Context Free Grammars](https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/pcfg/nochunks.html#pcfg) \n",
        "\n",
        "TreeRNNì— PCFG ruleì„ ì ìš©í•´ ë§Œë“  ê²ƒì´ Syntactically-United RNNì´ì£ . PCFG ruleì„ ì‹¤ìŠµí•´ ë´…ì‹œë‹¤."
      ],
      "metadata": {
        "id": "9L-jAHPkiBV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì˜¤ë¥˜ ë¯¸í•´ê²° ìƒíƒœ..."
      ],
      "metadata": {
        "id": "80M7kAPWWk0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import Tree\n",
        "import nltk\n",
        "import argparse\n",
        "from nltk import Nonterminal\n",
        "#from nltk.corpus import treebank\n",
        "#from nltk import treetransforms\n",
        "from nltk import induce_pcfg\n",
        "from nltk.parse import pchart\n",
        "import pandas as pd\n",
        "\n",
        "# Define some nonterminals\n",
        "(NP, V, VP) = [Nonterminal(s) for s in 'S NP VP'.split()]\n",
        "\n",
        "# Create some PCFG rules\n",
        "rule1 = PCFG_Rule(0.23, VP, V, NP)\n",
        "rule2 = PCFG_Rule(0.12, V, 'saw')\n",
        "rule3 = PCFG_Rule(0.04, NP, 'cookie')"
      ],
      "metadata": {
        "id": "Klj6gjETZdgS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "28e21044-3b03-43d2-df5d-b300de7e12eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-db3ad05ff788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create some PCFG rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrule1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCFG_Rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mrule2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCFG_Rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mrule3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCFG_Rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cookie'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PCFG_Rule' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print rule1.p(), rule2.p(), rule3.p()"
      ],
      "metadata": {
        "id": "xxZb8lvFS_ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules = [PCFG_Rule(1.0, S, VP, NP),\n",
        "             PCFG_Rule(0.4, VP, 'saw', NP),\n",
        "             PCFG_Rule(0.3, VP, 'ate'),\n",
        "             PCFG_Rule(0.3, VP, 'gave', NP, NP),\n",
        "             PCFG_Rule(0.8, NP, 'the', 'cookie'),\n",
        "             PCFG_Rule(0.2, NP, 'Jack')]\n",
        "grammar = PCFG(S, rules)"
      ],
      "metadata": {
        "id": "MsJZ9ldFiARK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grammar.start()\n",
        "grammar.rules()"
      ],
      "metadata": {
        "id": "kHnDXc72UPwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2ï¸âƒ£ Tree Based Algorithm**"
      ],
      "metadata": {
        "id": "HfTr_BPwGc8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ [Decision Tree](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/ml-decision-tree/tutorial/) ì‹¤ìŠµ\n",
        "\n",
        "ì°¸ê³ : [Embedding Graphs with Deep Learning ì½ê¸° ìë£Œ](https://towardsdatascience.com/embedding-graphs-with-deep-learning-55e0c66d7752)\n",
        "\n",
        "Decision TreeëŠ” ë¨¸ì‹  ëŸ¬ë‹ì—ì„œ ìì£¼ ì“°ì´ëŠ” Tree Algorithì…ë‹ˆë‹¤. Decision Treeë¥¼ ì‹¤ìŠµí•´ ë³´ë©° Tree êµ¬ì¡°ì™€ ì•Œê³ ë¦¬ì¦˜ì„ ì´í•´í•´ ë´…ì‹œë‹¤.\n"
      ],
      "metadata": {
        "id": "0HnXNyCAwSHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "svtikbdZatBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the iris data\n",
        "from google.colab import files\n",
        "data = files.upload()\n",
        "print('Classes to predict: ', data.target_names)"
      ],
      "metadata": {
        "id": "EcPIZc8GXCsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting data attributes\n",
        "X = data.data\n",
        "### Extracting target/ class labels\n",
        "y = data.target\n",
        "\n",
        "print('Number of examples in the data:', X.shape[0])"
      ],
      "metadata": {
        "id": "s2l9Pw0vXyDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First four rows in the variable 'X'\n",
        "X[:4]\n",
        "\n",
        "#Output\n",
        "Out: array([[5.1, 3.5, 1.4, 0.2],\n",
        "       [4.9, 3. , 1.4, 0.2],\n",
        "       [4.7, 3.2, 1.3, 0.2],\n",
        "       [4.6, 3.1, 1.5, 0.2]])"
      ],
      "metadata": {
        "id": "O7lpcCxBXz9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the train_test_split to create train and test sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 47, test_size = 0.25)"
      ],
      "metadata": {
        "id": "sndI6Bx5X3ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Decision tree classifier from the sklearn library.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(criterion = 'entropy')"
      ],
      "metadata": {
        "id": "eE6drUsBX4XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the decision tree classifier. \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Output:\n",
        "Out:DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "            splitter='best')"
      ],
      "metadata": {
        "id": "P0shnzAqX7aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting labels on the test set.\n",
        "y_pred =  clf.predict(X_test)"
      ],
      "metadata": {
        "id": "wZz6zOMNX94S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the accuracy metric from sklearn.metrics library\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy Score on train data: ', accuracy_score(y_true=y_train, y_pred=clf.predict(X_train)))\n",
        "print('Accuracy Score on test data: ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
        "\n",
        "#Output:\n",
        "Out: Accuracy Score on train data:  1.0\n",
        "    Accuracy Score on test data:  0.9473684210526315"
      ],
      "metadata": {
        "id": "GYoWWt5IX_jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=50)\n",
        "clf.fit(X_train, y_train)\n",
        "print('Accuracy Score on train data: ', accuracy_score(y_true=y_train, y_pred=clf.predict(X_train)))\n",
        "print('Accuracy Score on the test data: ', accuracy_score(y_true=y_test, y_pred=clf.predict(X_test)))\n",
        "\n",
        "#Output:\n",
        "Out: Accuracy Score on train data:  0.9553571428571429\n",
        "    Accuracy Score on test data:  0.9736842105263158"
      ],
      "metadata": {
        "id": "IFNHxKjZYBCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ì°¸ê³  ìë£Œ\n",
        "\n",
        "- [RNTN](https://ratsgo.github.io/deep%20learning/2017/06/24/RNTN/)\n",
        "\n",
        "- [When and Why Tree-Based Models (Often) Outperform Neural Networks](https://towardsdatascience.com/when-and-why-tree-based-models-often-outperform-neural-networks-ceba9ecd0fd8)\n",
        "\n",
        "- ì €ë²ˆ ì£¼ì°¨ ë‚´ìš©ê³¼ ê´€ë ¨ëœ í˜ì´í¼ [Parsing with Compositional Vector Grammars](https://nlp.stanford.edu/pubs/SocherBauerManningNg_ACL2013.pdf) ë„ ë„ì›€ì´ ë  ê±°ì˜ˆìš”! :)\n",
        "\n",
        "- [RNNê³¼ LSTMì´ ì™œ ì˜ ì•ˆ ì“°ì´ëŠ”ì§€ì— ëŒ€í•œ ì¹¼ëŸ¼](https://medium.com/towards-data-science/the-fall-of-rnn-lstm-2d1594c74ce0)ë„ í•œë²ˆ ì½ì–´ ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "pNDTxHF3sxo8"
      }
    }
  ]
}