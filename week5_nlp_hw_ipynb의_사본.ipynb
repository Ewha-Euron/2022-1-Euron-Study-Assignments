{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffffff-990917/2022-1-Euron-Study-Assignments/blob/Week_6/week5_nlp_hw_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUHfXkPAORh"
      },
      "source": [
        "📌 week5 내용 주차에 해당되는 과제는 3주차의 Glove 모델 실습, 4주차의 NER task 실습, 5주차의 Dependency Parsing task 실습으로 구성되어 있습니다. (**참고** : 제출은 week6 branch 복습과제로!) \n",
        "\n",
        "📌 위키독스의 딥러닝을 이용한 자연어 처리 입문 교재 실습, 캐글 노트북 등의 자료로 구성되어있는 과제입니다. \n",
        "\n",
        "📌 안내된 링크에 맞추어 **직접 코드를 따라 치면서 (필사)** 해당 nlp task 의 기본적인 라이브러리와 메서드를 숙지해보시면 좋을 것 같습니다😊 필수라고 체크한 부분은 과제에 반드시 포함시켜주시고, 선택으로 체크한 부분은 자율적으로 스터디 하시면 됩니다.\n",
        "\n",
        "📌 궁금한 사항은 깃허브 이슈나, 카톡방, 세션 발표 시작 이전 시간 등을 활용하여 자유롭게 공유해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjTSbcxBB6o",
        "outputId": "cc4530f2-2e95-4721-b8d1-443b8fd5af11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk colab 환경에서 실행시 필요한 코드입니다. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPZn15zBHIv"
      },
      "source": [
        "### 1️⃣ **Glove**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11biHcUuBaH"
      },
      "source": [
        "👀 **내용 복습** \n",
        "* 스탠포드 대학에서 개발한 카운트 기반과 예측 기반을 모두 사용하는 단어 임베딩 방법론 \n",
        "* word2vec 의 단점을 보완해서 나온 모델 \n",
        "* glove model 의 **input 은 반드시 동시등장행렬 형태**여야 한다 ⭐\n",
        "\n",
        "![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "🤔 한국어 예제는 없는 것 같습니다. 논문에서는 k-Glove 로 소개되는 연구가 있긴 한데, 좀 더 알아봐야 할 것 같아요!\n",
        "\n",
        "➕ [논문1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n",
        "\n",
        "\n",
        "➕[논문2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asGcGy6fBM1E"
      },
      "source": [
        "🔹 **1-(1)** glove python\n",
        "\n",
        "* [실습 : basic code](https://wikidocs.net/22885) 👉 필수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31NoJdu5t3p",
        "outputId": "d9372b81-621b-491f-8a98-89f7bde68e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glove_python_binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 102 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 112 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 122 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 133 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 194 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 204 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 215 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 225 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 235 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 245 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 256 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 266 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 276 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 286 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 307 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 317 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 337 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 348 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 368 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 378 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 389 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 399 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 409 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 419 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 430 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 440 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 450 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 460 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 471 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 481 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 491 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 501 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 512 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 522 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 532 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 542 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 552 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 563 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 573 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 583 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 593 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 604 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 614 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 624 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 634 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 645 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 655 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 665 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 675 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 686 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 696 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 706 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 716 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 727 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 737 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 747 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 757 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 768 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 778 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 788 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 798 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 808 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 819 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 829 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 839 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 849 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 860 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 870 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 880 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 890 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 901 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 911 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 921 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 931 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 942 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 948 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.4.1)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install glove_python_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "892HWyUA8DzU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLXI6GT8HD2",
        "outputId": "7b6fdd1f-7d94-4357-8b51-27d07637519c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7f7359834d50>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "metadata": {
        "id": "hi9iLBWE8SSV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n"
      ],
      "metadata": {
        "id": "miw-pnv58XP3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ta6QgoKO5uXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3134882b-4fac-44ec-c713-e5ffa8186cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 20 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n"
          ]
        }
      ],
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus() \n",
        "\n",
        "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n",
        "corpus.fit(result, window=5)\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "\n",
        "# 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20.\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"man\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTAQFc2T-FOW",
        "outputId": "d3abed33-e4e0-4551-d5fa-4357b23e00df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.9559094109715531), ('guy', 0.8741184184126037), ('girl', 0.8606195933304777), ('young', 0.8422164942402133)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"boy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6CG6sFb8B-Y",
        "outputId": "869644ee-249e-41e2-fe61-5c5bc377fca5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('girl', 0.9356188983134577), ('woman', 0.8484545837042662), ('kid', 0.8191819749594064), ('man', 0.8160057192289812)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"university\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQCeUZSN-5dU",
        "outputId": "482ae1e4-79c3-4d4c-f54d-58d0dd0a337c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('harvard', 0.8996833680801852), ('cambridge', 0.8479653746935998), ('mit', 0.8474664193791818), ('stanford', 0.8471945455119274)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"water\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEKgEar1-9gr",
        "outputId": "13bca922-78be-4aa4-ecf4-b55f68e8f10c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('air', 0.8403620992805466), ('clean', 0.8365725718884546), ('fresh', 0.8341815547578887), ('food', 0.8128734435111281)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"physics\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zWeUnXm-_kU",
        "outputId": "c6d1c616-13b7-41b5-f1e3-9febd9d5ca3d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('chemistry', 0.88505321795099), ('economics', 0.8740865968926251), ('beauty', 0.8643784093635186), ('mathematics', 0.8585187948793694)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"muscle\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N40Cpph_CRs",
        "outputId": "a3b3a65b-5f5d-495a-9ee1-9c4998506351"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tissue', 0.8297660188805107), ('nerve', 0.8147653595943043), ('channel', 0.7860179607228286), ('stem', 0.7653359979828239)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"clean\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5LD5O22_Igq",
        "outputId": "7eaf714f-da7e-4751-809d-84e3fa03f562"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fresh', 0.8393722527260793), ('water', 0.8365725718884547), ('wind', 0.8111498493005345), ('heat', 0.8011436024811395)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ADfVM9lO9NE"
      },
      "source": [
        "🔹 **1-(2)** pre-trained glove \n",
        "\n",
        "* **사전학습모델** : 임의의 값으로 초기화하던 모델의 가중치들을 다른 문제에 학습시킨 가중치들로 초기화하는 방법이다.사전 학습한 가중치를 활용해 학습하고자 하는 본래 문제를 하위문제라고 한다. \n",
        "\n",
        "* [실습 : 문장의 긍부정을 판단하는 감성 분류 모델 만들기](https://wikidocs.net/33793) 👉 필수\n",
        "  * [설명참고](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n",
        "* pre-trained data 를 가져오는데 시간이 오래걸림\n",
        "* kaggle 대회에서 주로 이 방식을 많이 사용함\n",
        "  * [참고](https://lsjsj92.tistory.com/455)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "id": "6sy91m2jB3TP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZlngY35O53sk"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "output_dim = 128\n",
        "input_length = 500\n",
        "\n",
        "v = Embedding(vocab_size, output_dim, input_length = input_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "N_iP5rM-vZAF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yREDjAgevhg4",
        "outputId": "e48e80e2-7e86-4ef3-dd05-239b1d7473f9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print('정수 인코딩 결과 :',X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRosktDVvkoq",
        "outputId": "efd3df84-3730-40cc-bb22-b6a79c1b4706"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 결과 : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('최대 길이 :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osiWeHVyvoBM",
        "outputId": "d1ff976d-acb1-4842-9a2a-c88e3d4a641e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_train = np.array(y_train)\n",
        "print('패딩 결과 :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8IyS69UvtcZ",
        "outputId": "ed9fa85f-b479-489a-ffcc-3bcca68cf2a7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 결과 :\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "embedding_dim = 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b90taTBvzSI",
        "outputId": "1e2505f2-d88f-4314-b291-87b0524149cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 7 samples\n",
            "Epoch 1/100\n",
            "7/7 - 0s - loss: 0.6926 - acc: 0.5714 - 139ms/epoch - 20ms/sample\n",
            "Epoch 2/100\n",
            "7/7 - 0s - loss: 0.6915 - acc: 0.7143 - 6ms/epoch - 925us/sample\n",
            "Epoch 3/100\n",
            "7/7 - 0s - loss: 0.6905 - acc: 0.7143 - 5ms/epoch - 754us/sample\n",
            "Epoch 4/100\n",
            "7/7 - 0s - loss: 0.6894 - acc: 0.7143 - 6ms/epoch - 885us/sample\n",
            "Epoch 5/100\n",
            "7/7 - 0s - loss: 0.6884 - acc: 0.7143 - 9ms/epoch - 1ms/sample\n",
            "Epoch 6/100\n",
            "7/7 - 0s - loss: 0.6873 - acc: 0.7143 - 5ms/epoch - 648us/sample\n",
            "Epoch 7/100\n",
            "7/7 - 0s - loss: 0.6862 - acc: 0.8571 - 3ms/epoch - 485us/sample\n",
            "Epoch 8/100\n",
            "7/7 - 0s - loss: 0.6852 - acc: 0.8571 - 4ms/epoch - 616us/sample\n",
            "Epoch 9/100\n",
            "7/7 - 0s - loss: 0.6841 - acc: 0.8571 - 4ms/epoch - 562us/sample\n",
            "Epoch 10/100\n",
            "7/7 - 0s - loss: 0.6830 - acc: 0.8571 - 3ms/epoch - 484us/sample\n",
            "Epoch 11/100\n",
            "7/7 - 0s - loss: 0.6820 - acc: 0.8571 - 6ms/epoch - 841us/sample\n",
            "Epoch 12/100\n",
            "7/7 - 0s - loss: 0.6809 - acc: 0.8571 - 3ms/epoch - 359us/sample\n",
            "Epoch 13/100\n",
            "7/7 - 0s - loss: 0.6798 - acc: 0.8571 - 4ms/epoch - 578us/sample\n",
            "Epoch 14/100\n",
            "7/7 - 0s - loss: 0.6787 - acc: 0.8571 - 4ms/epoch - 620us/sample\n",
            "Epoch 15/100\n",
            "7/7 - 0s - loss: 0.6776 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 16/100\n",
            "7/7 - 0s - loss: 0.6765 - acc: 1.0000 - 4ms/epoch - 507us/sample\n",
            "Epoch 17/100\n",
            "7/7 - 0s - loss: 0.6755 - acc: 1.0000 - 5ms/epoch - 761us/sample\n",
            "Epoch 18/100\n",
            "7/7 - 0s - loss: 0.6743 - acc: 1.0000 - 5ms/epoch - 646us/sample\n",
            "Epoch 19/100\n",
            "7/7 - 0s - loss: 0.6732 - acc: 1.0000 - 3ms/epoch - 491us/sample\n",
            "Epoch 20/100\n",
            "7/7 - 0s - loss: 0.6721 - acc: 1.0000 - 6ms/epoch - 848us/sample\n",
            "Epoch 21/100\n",
            "7/7 - 0s - loss: 0.6710 - acc: 1.0000 - 3ms/epoch - 415us/sample\n",
            "Epoch 22/100\n",
            "7/7 - 0s - loss: 0.6699 - acc: 1.0000 - 4ms/epoch - 552us/sample\n",
            "Epoch 23/100\n",
            "7/7 - 0s - loss: 0.6687 - acc: 1.0000 - 3ms/epoch - 450us/sample\n",
            "Epoch 24/100\n",
            "7/7 - 0s - loss: 0.6676 - acc: 1.0000 - 4ms/epoch - 520us/sample\n",
            "Epoch 25/100\n",
            "7/7 - 0s - loss: 0.6664 - acc: 1.0000 - 4ms/epoch - 553us/sample\n",
            "Epoch 26/100\n",
            "7/7 - 0s - loss: 0.6653 - acc: 1.0000 - 4ms/epoch - 507us/sample\n",
            "Epoch 27/100\n",
            "7/7 - 0s - loss: 0.6641 - acc: 1.0000 - 4ms/epoch - 522us/sample\n",
            "Epoch 28/100\n",
            "7/7 - 0s - loss: 0.6629 - acc: 1.0000 - 4ms/epoch - 582us/sample\n",
            "Epoch 29/100\n",
            "7/7 - 0s - loss: 0.6617 - acc: 1.0000 - 4ms/epoch - 604us/sample\n",
            "Epoch 30/100\n",
            "7/7 - 0s - loss: 0.6605 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 31/100\n",
            "7/7 - 0s - loss: 0.6593 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 32/100\n",
            "7/7 - 0s - loss: 0.6581 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 33/100\n",
            "7/7 - 0s - loss: 0.6569 - acc: 1.0000 - 11ms/epoch - 2ms/sample\n",
            "Epoch 34/100\n",
            "7/7 - 0s - loss: 0.6556 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 35/100\n",
            "7/7 - 0s - loss: 0.6544 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 36/100\n",
            "7/7 - 0s - loss: 0.6531 - acc: 1.0000 - 5ms/epoch - 771us/sample\n",
            "Epoch 37/100\n",
            "7/7 - 0s - loss: 0.6518 - acc: 1.0000 - 4ms/epoch - 510us/sample\n",
            "Epoch 38/100\n",
            "7/7 - 0s - loss: 0.6505 - acc: 1.0000 - 4ms/epoch - 605us/sample\n",
            "Epoch 39/100\n",
            "7/7 - 0s - loss: 0.6492 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 40/100\n",
            "7/7 - 0s - loss: 0.6479 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 41/100\n",
            "7/7 - 0s - loss: 0.6466 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 42/100\n",
            "7/7 - 0s - loss: 0.6453 - acc: 1.0000 - 3ms/epoch - 480us/sample\n",
            "Epoch 43/100\n",
            "7/7 - 0s - loss: 0.6439 - acc: 1.0000 - 3ms/epoch - 469us/sample\n",
            "Epoch 44/100\n",
            "7/7 - 0s - loss: 0.6425 - acc: 1.0000 - 3ms/epoch - 482us/sample\n",
            "Epoch 45/100\n",
            "7/7 - 0s - loss: 0.6412 - acc: 1.0000 - 4ms/epoch - 587us/sample\n",
            "Epoch 46/100\n",
            "7/7 - 0s - loss: 0.6398 - acc: 1.0000 - 6ms/epoch - 823us/sample\n",
            "Epoch 47/100\n",
            "7/7 - 0s - loss: 0.6384 - acc: 1.0000 - 5ms/epoch - 660us/sample\n",
            "Epoch 48/100\n",
            "7/7 - 0s - loss: 0.6370 - acc: 1.0000 - 5ms/epoch - 652us/sample\n",
            "Epoch 49/100\n",
            "7/7 - 0s - loss: 0.6355 - acc: 1.0000 - 4ms/epoch - 522us/sample\n",
            "Epoch 50/100\n",
            "7/7 - 0s - loss: 0.6341 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 51/100\n",
            "7/7 - 0s - loss: 0.6326 - acc: 1.0000 - 5ms/epoch - 707us/sample\n",
            "Epoch 52/100\n",
            "7/7 - 0s - loss: 0.6312 - acc: 1.0000 - 6ms/epoch - 839us/sample\n",
            "Epoch 53/100\n",
            "7/7 - 0s - loss: 0.6297 - acc: 1.0000 - 5ms/epoch - 675us/sample\n",
            "Epoch 54/100\n",
            "7/7 - 0s - loss: 0.6282 - acc: 1.0000 - 5ms/epoch - 717us/sample\n",
            "Epoch 55/100\n",
            "7/7 - 0s - loss: 0.6267 - acc: 1.0000 - 5ms/epoch - 708us/sample\n",
            "Epoch 56/100\n",
            "7/7 - 0s - loss: 0.6252 - acc: 1.0000 - 4ms/epoch - 501us/sample\n",
            "Epoch 57/100\n",
            "7/7 - 0s - loss: 0.6236 - acc: 1.0000 - 3ms/epoch - 435us/sample\n",
            "Epoch 58/100\n",
            "7/7 - 0s - loss: 0.6221 - acc: 1.0000 - 6ms/epoch - 927us/sample\n",
            "Epoch 59/100\n",
            "7/7 - 0s - loss: 0.6205 - acc: 1.0000 - 5ms/epoch - 722us/sample\n",
            "Epoch 60/100\n",
            "7/7 - 0s - loss: 0.6189 - acc: 1.0000 - 4ms/epoch - 642us/sample\n",
            "Epoch 61/100\n",
            "7/7 - 0s - loss: 0.6174 - acc: 1.0000 - 6ms/epoch - 838us/sample\n",
            "Epoch 62/100\n",
            "7/7 - 0s - loss: 0.6158 - acc: 1.0000 - 5ms/epoch - 666us/sample\n",
            "Epoch 63/100\n",
            "7/7 - 0s - loss: 0.6142 - acc: 1.0000 - 4ms/epoch - 573us/sample\n",
            "Epoch 64/100\n",
            "7/7 - 0s - loss: 0.6125 - acc: 1.0000 - 5ms/epoch - 730us/sample\n",
            "Epoch 65/100\n",
            "7/7 - 0s - loss: 0.6109 - acc: 1.0000 - 4ms/epoch - 612us/sample\n",
            "Epoch 66/100\n",
            "7/7 - 0s - loss: 0.6093 - acc: 1.0000 - 4ms/epoch - 565us/sample\n",
            "Epoch 67/100\n",
            "7/7 - 0s - loss: 0.6076 - acc: 1.0000 - 5ms/epoch - 713us/sample\n",
            "Epoch 68/100\n",
            "7/7 - 0s - loss: 0.6059 - acc: 1.0000 - 6ms/epoch - 842us/sample\n",
            "Epoch 69/100\n",
            "7/7 - 0s - loss: 0.6042 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 70/100\n",
            "7/7 - 0s - loss: 0.6025 - acc: 1.0000 - 5ms/epoch - 711us/sample\n",
            "Epoch 71/100\n",
            "7/7 - 0s - loss: 0.6008 - acc: 1.0000 - 5ms/epoch - 656us/sample\n",
            "Epoch 72/100\n",
            "7/7 - 0s - loss: 0.5991 - acc: 1.0000 - 4ms/epoch - 506us/sample\n",
            "Epoch 73/100\n",
            "7/7 - 0s - loss: 0.5974 - acc: 1.0000 - 4ms/epoch - 631us/sample\n",
            "Epoch 74/100\n",
            "7/7 - 0s - loss: 0.5956 - acc: 1.0000 - 4ms/epoch - 597us/sample\n",
            "Epoch 75/100\n",
            "7/7 - 0s - loss: 0.5939 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 76/100\n",
            "7/7 - 0s - loss: 0.5921 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 77/100\n",
            "7/7 - 0s - loss: 0.5903 - acc: 1.0000 - 5ms/epoch - 645us/sample\n",
            "Epoch 78/100\n",
            "7/7 - 0s - loss: 0.5885 - acc: 1.0000 - 5ms/epoch - 660us/sample\n",
            "Epoch 79/100\n",
            "7/7 - 0s - loss: 0.5867 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 80/100\n",
            "7/7 - 0s - loss: 0.5849 - acc: 1.0000 - 6ms/epoch - 892us/sample\n",
            "Epoch 81/100\n",
            "7/7 - 0s - loss: 0.5831 - acc: 1.0000 - 4ms/epoch - 615us/sample\n",
            "Epoch 82/100\n",
            "7/7 - 0s - loss: 0.5813 - acc: 1.0000 - 4ms/epoch - 643us/sample\n",
            "Epoch 83/100\n",
            "7/7 - 0s - loss: 0.5794 - acc: 1.0000 - 6ms/epoch - 908us/sample\n",
            "Epoch 84/100\n",
            "7/7 - 0s - loss: 0.5776 - acc: 1.0000 - 7ms/epoch - 941us/sample\n",
            "Epoch 85/100\n",
            "7/7 - 0s - loss: 0.5757 - acc: 1.0000 - 4ms/epoch - 616us/sample\n",
            "Epoch 86/100\n",
            "7/7 - 0s - loss: 0.5738 - acc: 1.0000 - 4ms/epoch - 561us/sample\n",
            "Epoch 87/100\n",
            "7/7 - 0s - loss: 0.5719 - acc: 1.0000 - 4ms/epoch - 641us/sample\n",
            "Epoch 88/100\n",
            "7/7 - 0s - loss: 0.5700 - acc: 1.0000 - 4ms/epoch - 541us/sample\n",
            "Epoch 89/100\n",
            "7/7 - 0s - loss: 0.5681 - acc: 1.0000 - 3ms/epoch - 432us/sample\n",
            "Epoch 90/100\n",
            "7/7 - 0s - loss: 0.5662 - acc: 1.0000 - 6ms/epoch - 836us/sample\n",
            "Epoch 91/100\n",
            "7/7 - 0s - loss: 0.5643 - acc: 1.0000 - 6ms/epoch - 801us/sample\n",
            "Epoch 92/100\n",
            "7/7 - 0s - loss: 0.5623 - acc: 1.0000 - 5ms/epoch - 685us/sample\n",
            "Epoch 93/100\n",
            "7/7 - 0s - loss: 0.5604 - acc: 1.0000 - 4ms/epoch - 631us/sample\n",
            "Epoch 94/100\n",
            "7/7 - 0s - loss: 0.5584 - acc: 1.0000 - 3ms/epoch - 480us/sample\n",
            "Epoch 95/100\n",
            "7/7 - 0s - loss: 0.5565 - acc: 1.0000 - 4ms/epoch - 605us/sample\n",
            "Epoch 96/100\n",
            "7/7 - 0s - loss: 0.5545 - acc: 1.0000 - 7ms/epoch - 959us/sample\n",
            "Epoch 97/100\n",
            "7/7 - 0s - loss: 0.5525 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 98/100\n",
            "7/7 - 0s - loss: 0.5505 - acc: 1.0000 - 5ms/epoch - 699us/sample\n",
            "Epoch 99/100\n",
            "7/7 - 0s - loss: 0.5486 - acc: 1.0000 - 6ms/epoch - 795us/sample\n",
            "Epoch 100/100\n",
            "7/7 - 0s - loss: 0.5465 - acc: 1.0000 - 4ms/epoch - 533us/sample\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7339a21ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUAnYybOwLIA",
        "outputId": "c72bd10c-56a8-4ff0-cd0c-f46995967944"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3PfPdt7wOa1",
        "outputId": "21fd6511-c0fb-4b3d-9c23-e1c8ea8683f6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve, urlopen\n",
        "import gzip\n",
        "import zipfile\n",
        "\n",
        "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
        "zf = zipfile.ZipFile('glove.6B.zip')\n",
        "zf.extractall() \n",
        "zf.close()"
      ],
      "metadata": {
        "id": "TxugoFoJwcA9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dict = dict()\n",
        "\n",
        "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "\n",
        "    # 100개의 값을 가지는 array로 변환\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSSZl698x_mA",
        "outputId": "0647bd0f-90d8-4805-f623-7bbe9cb03f4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000개의 Embedding vector가 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print('벡터의 차원 수 :',len(embedding_dict['respectable']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5Vj5TZ3YzK",
        "outputId": "caec383f-07e7-4735-dbe0-7ad7aff39311"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "벡터의 차원 수 : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('임베딩 행렬의 크기(shape) :',np.shape(embedding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kIG_aWe3ftL",
        "outputId": "34959db8-1260-498b-86da-bd6026761ba4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 행렬의 크기(shape) : (16, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIrJYizu3pO8",
        "outputId": "4496f420-1d5b-4a6c-b185-0dd16e712eff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 great의 맵핑된 정수 :',tokenizer.word_index['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rKyie3P3rzp",
        "outputId": "a287e050-d2bf-4f79-ad7a-0e7f4f7f6dcf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 great의 맵핑된 정수 : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXXjK-gr3wHV",
        "outputId": "fc24ce21-3331-4553-c810-1be4b0f5c11a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.013786   0.38216    0.53236    0.15261   -0.29694   -0.20558\n",
            " -0.41846   -0.58437   -0.77355   -0.87866   -0.37858   -0.18516\n",
            " -0.128     -0.20584   -0.22925   -0.42599    0.3725     0.26077\n",
            " -1.0702     0.62916   -0.091469   0.70348   -0.4973    -0.77691\n",
            "  0.66045    0.09465   -0.44893    0.018917   0.33146   -0.35022\n",
            " -0.35789    0.030313   0.22253   -0.23236   -0.19719   -0.0053125\n",
            " -0.25848    0.58081   -0.10705   -0.17845   -0.16206    0.087086\n",
            "  0.63029   -0.76649    0.51619    0.14073    1.019     -0.43136\n",
            "  0.46138   -0.43585   -0.47568    0.19226    0.36065    0.78987\n",
            "  0.088945  -2.7814    -0.15366    0.01015    1.1798     0.15168\n",
            " -0.050112   1.2626    -0.77527    0.36031    0.95761   -0.11385\n",
            "  0.28035   -0.02591    0.31246   -0.15424    0.3778    -0.13599\n",
            "  0.2946    -0.31579    0.42943    0.086969   0.019169  -0.27242\n",
            " -0.31696    0.37327    0.61997    0.13889    0.17188    0.30363\n",
            " -1.2776     0.044423  -0.52736   -0.88536   -0.19428   -0.61947\n",
            " -0.10146   -0.26301   -0.061707   0.36627   -0.95223   -0.39346\n",
            " -0.69183   -1.0426     0.28855    0.63056  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ],
      "metadata": {
        "id": "dT6aweRr3zQq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_3kaMRy33an",
        "outputId": "ce7dc708-cb25-4c71-b342-1b046a4ca94c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.013786  ,  0.38216001,  0.53236002,  0.15261   , -0.29694   ,\n",
              "       -0.20558   , -0.41846001, -0.58437002, -0.77354997, -0.87866002,\n",
              "       -0.37858   , -0.18516   , -0.12800001, -0.20584001, -0.22925   ,\n",
              "       -0.42598999,  0.3725    ,  0.26076999, -1.07019997,  0.62915999,\n",
              "       -0.091469  ,  0.70348001, -0.4973    , -0.77691001,  0.66044998,\n",
              "        0.09465   , -0.44893   ,  0.018917  ,  0.33146   , -0.35021999,\n",
              "       -0.35789001,  0.030313  ,  0.22253001, -0.23236001, -0.19719   ,\n",
              "       -0.0053125 , -0.25848001,  0.58081001, -0.10705   , -0.17845   ,\n",
              "       -0.16205999,  0.087086  ,  0.63028997, -0.76648998,  0.51618999,\n",
              "        0.14072999,  1.01900005, -0.43136001,  0.46138   , -0.43584999,\n",
              "       -0.47567999,  0.19226   ,  0.36065   ,  0.78987002,  0.088945  ,\n",
              "       -2.78139997, -0.15366   ,  0.01015   ,  1.17980003,  0.15167999,\n",
              "       -0.050112  ,  1.26259995, -0.77526999,  0.36030999,  0.95761001,\n",
              "       -0.11385   ,  0.28035   , -0.02591   ,  0.31246001, -0.15424   ,\n",
              "        0.37779999, -0.13598999,  0.29460001, -0.31579   ,  0.42943001,\n",
              "        0.086969  ,  0.019169  , -0.27241999, -0.31696001,  0.37327   ,\n",
              "        0.61997002,  0.13889   ,  0.17188001,  0.30362999, -1.27760005,\n",
              "        0.044423  , -0.52736002, -0.88536   , -0.19428   , -0.61947   ,\n",
              "       -0.10146   , -0.26301   , -0.061707  ,  0.36627001, -0.95222998,\n",
              "       -0.39346001, -0.69182998, -1.04260004,  0.28854999,  0.63055998])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "output_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFl0SXN1352C",
        "outputId": "79d60beb-3d22-4c3d-c572-21a8cf37a9a4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 7 samples\n",
            "Epoch 1/100\n",
            "7/7 - 0s - loss: 0.5499 - acc: 0.7143 - 31ms/epoch - 4ms/sample\n",
            "Epoch 2/100\n",
            "7/7 - 0s - loss: 0.5317 - acc: 0.7143 - 6ms/epoch - 828us/sample\n",
            "Epoch 3/100\n",
            "7/7 - 0s - loss: 0.5144 - acc: 0.8571 - 4ms/epoch - 627us/sample\n",
            "Epoch 4/100\n",
            "7/7 - 0s - loss: 0.4979 - acc: 0.8571 - 4ms/epoch - 617us/sample\n",
            "Epoch 5/100\n",
            "7/7 - 0s - loss: 0.4821 - acc: 1.0000 - 4ms/epoch - 584us/sample\n",
            "Epoch 6/100\n",
            "7/7 - 0s - loss: 0.4672 - acc: 1.0000 - 4ms/epoch - 613us/sample\n",
            "Epoch 7/100\n",
            "7/7 - 0s - loss: 0.4529 - acc: 1.0000 - 5ms/epoch - 653us/sample\n",
            "Epoch 8/100\n",
            "7/7 - 0s - loss: 0.4394 - acc: 1.0000 - 5ms/epoch - 668us/sample\n",
            "Epoch 9/100\n",
            "7/7 - 0s - loss: 0.4265 - acc: 1.0000 - 4ms/epoch - 639us/sample\n",
            "Epoch 10/100\n",
            "7/7 - 0s - loss: 0.4142 - acc: 1.0000 - 5ms/epoch - 679us/sample\n",
            "Epoch 11/100\n",
            "7/7 - 0s - loss: 0.4025 - acc: 1.0000 - 5ms/epoch - 647us/sample\n",
            "Epoch 12/100\n",
            "7/7 - 0s - loss: 0.3913 - acc: 1.0000 - 4ms/epoch - 586us/sample\n",
            "Epoch 13/100\n",
            "7/7 - 0s - loss: 0.3807 - acc: 1.0000 - 4ms/epoch - 600us/sample\n",
            "Epoch 14/100\n",
            "7/7 - 0s - loss: 0.3705 - acc: 1.0000 - 5ms/epoch - 651us/sample\n",
            "Epoch 15/100\n",
            "7/7 - 0s - loss: 0.3607 - acc: 1.0000 - 4ms/epoch - 615us/sample\n",
            "Epoch 16/100\n",
            "7/7 - 0s - loss: 0.3514 - acc: 1.0000 - 4ms/epoch - 585us/sample\n",
            "Epoch 17/100\n",
            "7/7 - 0s - loss: 0.3424 - acc: 1.0000 - 4ms/epoch - 582us/sample\n",
            "Epoch 18/100\n",
            "7/7 - 0s - loss: 0.3338 - acc: 1.0000 - 10ms/epoch - 1ms/sample\n",
            "Epoch 19/100\n",
            "7/7 - 0s - loss: 0.3255 - acc: 1.0000 - 4ms/epoch - 616us/sample\n",
            "Epoch 20/100\n",
            "7/7 - 0s - loss: 0.3175 - acc: 1.0000 - 4ms/epoch - 573us/sample\n",
            "Epoch 21/100\n",
            "7/7 - 0s - loss: 0.3098 - acc: 1.0000 - 4ms/epoch - 558us/sample\n",
            "Epoch 22/100\n",
            "7/7 - 0s - loss: 0.3023 - acc: 1.0000 - 6ms/epoch - 914us/sample\n",
            "Epoch 23/100\n",
            "7/7 - 0s - loss: 0.2951 - acc: 1.0000 - 5ms/epoch - 660us/sample\n",
            "Epoch 24/100\n",
            "7/7 - 0s - loss: 0.2882 - acc: 1.0000 - 5ms/epoch - 651us/sample\n",
            "Epoch 25/100\n",
            "7/7 - 0s - loss: 0.2814 - acc: 1.0000 - 5ms/epoch - 705us/sample\n",
            "Epoch 26/100\n",
            "7/7 - 0s - loss: 0.2749 - acc: 1.0000 - 6ms/epoch - 801us/sample\n",
            "Epoch 27/100\n",
            "7/7 - 0s - loss: 0.2686 - acc: 1.0000 - 5ms/epoch - 693us/sample\n",
            "Epoch 28/100\n",
            "7/7 - 0s - loss: 0.2624 - acc: 1.0000 - 5ms/epoch - 742us/sample\n",
            "Epoch 29/100\n",
            "7/7 - 0s - loss: 0.2565 - acc: 1.0000 - 5ms/epoch - 769us/sample\n",
            "Epoch 30/100\n",
            "7/7 - 0s - loss: 0.2507 - acc: 1.0000 - 4ms/epoch - 568us/sample\n",
            "Epoch 31/100\n",
            "7/7 - 0s - loss: 0.2451 - acc: 1.0000 - 4ms/epoch - 571us/sample\n",
            "Epoch 32/100\n",
            "7/7 - 0s - loss: 0.2396 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 33/100\n",
            "7/7 - 0s - loss: 0.2344 - acc: 1.0000 - 4ms/epoch - 555us/sample\n",
            "Epoch 34/100\n",
            "7/7 - 0s - loss: 0.2292 - acc: 1.0000 - 4ms/epoch - 510us/sample\n",
            "Epoch 35/100\n",
            "7/7 - 0s - loss: 0.2243 - acc: 1.0000 - 4ms/epoch - 558us/sample\n",
            "Epoch 36/100\n",
            "7/7 - 0s - loss: 0.2194 - acc: 1.0000 - 3ms/epoch - 486us/sample\n",
            "Epoch 37/100\n",
            "7/7 - 0s - loss: 0.2147 - acc: 1.0000 - 4ms/epoch - 588us/sample\n",
            "Epoch 38/100\n",
            "7/7 - 0s - loss: 0.2102 - acc: 1.0000 - 4ms/epoch - 513us/sample\n",
            "Epoch 39/100\n",
            "7/7 - 0s - loss: 0.2058 - acc: 1.0000 - 4ms/epoch - 527us/sample\n",
            "Epoch 40/100\n",
            "7/7 - 0s - loss: 0.2015 - acc: 1.0000 - 4ms/epoch - 614us/sample\n",
            "Epoch 41/100\n",
            "7/7 - 0s - loss: 0.1973 - acc: 1.0000 - 4ms/epoch - 562us/sample\n",
            "Epoch 42/100\n",
            "7/7 - 0s - loss: 0.1933 - acc: 1.0000 - 3ms/epoch - 491us/sample\n",
            "Epoch 43/100\n",
            "7/7 - 0s - loss: 0.1893 - acc: 1.0000 - 3ms/epoch - 481us/sample\n",
            "Epoch 44/100\n",
            "7/7 - 0s - loss: 0.1855 - acc: 1.0000 - 5ms/epoch - 655us/sample\n",
            "Epoch 45/100\n",
            "7/7 - 0s - loss: 0.1818 - acc: 1.0000 - 4ms/epoch - 607us/sample\n",
            "Epoch 46/100\n",
            "7/7 - 0s - loss: 0.1782 - acc: 1.0000 - 4ms/epoch - 597us/sample\n",
            "Epoch 47/100\n",
            "7/7 - 0s - loss: 0.1747 - acc: 1.0000 - 4ms/epoch - 605us/sample\n",
            "Epoch 48/100\n",
            "7/7 - 0s - loss: 0.1714 - acc: 1.0000 - 5ms/epoch - 658us/sample\n",
            "Epoch 49/100\n",
            "7/7 - 0s - loss: 0.1681 - acc: 1.0000 - 4ms/epoch - 598us/sample\n",
            "Epoch 50/100\n",
            "7/7 - 0s - loss: 0.1649 - acc: 1.0000 - 4ms/epoch - 597us/sample\n",
            "Epoch 51/100\n",
            "7/7 - 0s - loss: 0.1618 - acc: 1.0000 - 5ms/epoch - 710us/sample\n",
            "Epoch 52/100\n",
            "7/7 - 0s - loss: 0.1587 - acc: 1.0000 - 6ms/epoch - 841us/sample\n",
            "Epoch 53/100\n",
            "7/7 - 0s - loss: 0.1558 - acc: 1.0000 - 6ms/epoch - 888us/sample\n",
            "Epoch 54/100\n",
            "7/7 - 0s - loss: 0.1530 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 55/100\n",
            "7/7 - 0s - loss: 0.1502 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 56/100\n",
            "7/7 - 0s - loss: 0.1475 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 57/100\n",
            "7/7 - 0s - loss: 0.1449 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 58/100\n",
            "7/7 - 0s - loss: 0.1423 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 59/100\n",
            "7/7 - 0s - loss: 0.1398 - acc: 1.0000 - 13ms/epoch - 2ms/sample\n",
            "Epoch 60/100\n",
            "7/7 - 0s - loss: 0.1374 - acc: 1.0000 - 5ms/epoch - 699us/sample\n",
            "Epoch 61/100\n",
            "7/7 - 0s - loss: 0.1351 - acc: 1.0000 - 5ms/epoch - 658us/sample\n",
            "Epoch 62/100\n",
            "7/7 - 0s - loss: 0.1328 - acc: 1.0000 - 4ms/epoch - 505us/sample\n",
            "Epoch 63/100\n",
            "7/7 - 0s - loss: 0.1306 - acc: 1.0000 - 7ms/epoch - 971us/sample\n",
            "Epoch 64/100\n",
            "7/7 - 0s - loss: 0.1284 - acc: 1.0000 - 10ms/epoch - 1ms/sample\n",
            "Epoch 65/100\n",
            "7/7 - 0s - loss: 0.1263 - acc: 1.0000 - 4ms/epoch - 514us/sample\n",
            "Epoch 66/100\n",
            "7/7 - 0s - loss: 0.1242 - acc: 1.0000 - 4ms/epoch - 625us/sample\n",
            "Epoch 67/100\n",
            "7/7 - 0s - loss: 0.1222 - acc: 1.0000 - 4ms/epoch - 569us/sample\n",
            "Epoch 68/100\n",
            "7/7 - 0s - loss: 0.1202 - acc: 1.0000 - 4ms/epoch - 565us/sample\n",
            "Epoch 69/100\n",
            "7/7 - 0s - loss: 0.1183 - acc: 1.0000 - 4ms/epoch - 599us/sample\n",
            "Epoch 70/100\n",
            "7/7 - 0s - loss: 0.1165 - acc: 1.0000 - 4ms/epoch - 547us/sample\n",
            "Epoch 71/100\n",
            "7/7 - 0s - loss: 0.1147 - acc: 1.0000 - 4ms/epoch - 579us/sample\n",
            "Epoch 72/100\n",
            "7/7 - 0s - loss: 0.1129 - acc: 1.0000 - 5ms/epoch - 690us/sample\n",
            "Epoch 73/100\n",
            "7/7 - 0s - loss: 0.1112 - acc: 1.0000 - 5ms/epoch - 671us/sample\n",
            "Epoch 74/100\n",
            "7/7 - 0s - loss: 0.1095 - acc: 1.0000 - 5ms/epoch - 721us/sample\n",
            "Epoch 75/100\n",
            "7/7 - 0s - loss: 0.1078 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 76/100\n",
            "7/7 - 0s - loss: 0.1062 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 77/100\n",
            "7/7 - 0s - loss: 0.1047 - acc: 1.0000 - 11ms/epoch - 2ms/sample\n",
            "Epoch 78/100\n",
            "7/7 - 0s - loss: 0.1031 - acc: 1.0000 - 5ms/epoch - 683us/sample\n",
            "Epoch 79/100\n",
            "7/7 - 0s - loss: 0.1016 - acc: 1.0000 - 4ms/epoch - 533us/sample\n",
            "Epoch 80/100\n",
            "7/7 - 0s - loss: 0.1002 - acc: 1.0000 - 4ms/epoch - 642us/sample\n",
            "Epoch 81/100\n",
            "7/7 - 0s - loss: 0.0988 - acc: 1.0000 - 4ms/epoch - 613us/sample\n",
            "Epoch 82/100\n",
            "7/7 - 0s - loss: 0.0974 - acc: 1.0000 - 5ms/epoch - 673us/sample\n",
            "Epoch 83/100\n",
            "7/7 - 0s - loss: 0.0960 - acc: 1.0000 - 5ms/epoch - 666us/sample\n",
            "Epoch 84/100\n",
            "7/7 - 0s - loss: 0.0947 - acc: 1.0000 - 5ms/epoch - 679us/sample\n",
            "Epoch 85/100\n",
            "7/7 - 0s - loss: 0.0934 - acc: 1.0000 - 3ms/epoch - 499us/sample\n",
            "Epoch 86/100\n",
            "7/7 - 0s - loss: 0.0921 - acc: 1.0000 - 5ms/epoch - 675us/sample\n",
            "Epoch 87/100\n",
            "7/7 - 0s - loss: 0.0908 - acc: 1.0000 - 4ms/epoch - 613us/sample\n",
            "Epoch 88/100\n",
            "7/7 - 0s - loss: 0.0896 - acc: 1.0000 - 4ms/epoch - 563us/sample\n",
            "Epoch 89/100\n",
            "7/7 - 0s - loss: 0.0884 - acc: 1.0000 - 4ms/epoch - 526us/sample\n",
            "Epoch 90/100\n",
            "7/7 - 0s - loss: 0.0873 - acc: 1.0000 - 4ms/epoch - 549us/sample\n",
            "Epoch 91/100\n",
            "7/7 - 0s - loss: 0.0861 - acc: 1.0000 - 4ms/epoch - 594us/sample\n",
            "Epoch 92/100\n",
            "7/7 - 0s - loss: 0.0850 - acc: 1.0000 - 4ms/epoch - 574us/sample\n",
            "Epoch 93/100\n",
            "7/7 - 0s - loss: 0.0839 - acc: 1.0000 - 5ms/epoch - 645us/sample\n",
            "Epoch 94/100\n",
            "7/7 - 0s - loss: 0.0828 - acc: 1.0000 - 4ms/epoch - 536us/sample\n",
            "Epoch 95/100\n",
            "7/7 - 0s - loss: 0.0818 - acc: 1.0000 - 4ms/epoch - 576us/sample\n",
            "Epoch 96/100\n",
            "7/7 - 0s - loss: 0.0808 - acc: 1.0000 - 4ms/epoch - 593us/sample\n",
            "Epoch 97/100\n",
            "7/7 - 0s - loss: 0.0797 - acc: 1.0000 - 4ms/epoch - 582us/sample\n",
            "Epoch 98/100\n",
            "7/7 - 0s - loss: 0.0788 - acc: 1.0000 - 4ms/epoch - 559us/sample\n",
            "Epoch 99/100\n",
            "7/7 - 0s - loss: 0.0778 - acc: 1.0000 - 4ms/epoch - 546us/sample\n",
            "Epoch 100/100\n",
            "7/7 - 0s - loss: 0.0768 - acc: 1.0000 - 4ms/epoch - 607us/sample\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7338905150>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_wcrE5PtLMI"
      },
      "source": [
        "🔹 **1-(3)** fine tuning glove\n",
        "* 미세조정 : 사전 학습한 모든 가중치와 더불어 하위 문제를 위한 최소한의 가중치를 추가해 모델을 추가로 학습하는 방법이다. \n",
        "\n",
        "* fine tuning 이 필요한 경우 \n",
        "  * pretrained model 에 데이터셋에 있는 단어가 포함되지 않은 경우 \n",
        "  * 데이터 집합이 너무 작아서 전체 모델을 훈련시키기 어려운 경우 \n",
        "\n",
        "* [Mittens 라이브러리로 fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) 👉 필수\n",
        "  *  GloVe 임베딩을 fine-tuning 하기 위한 파이썬 라이브러리\n",
        "  * [github](https://github.com/roamanalytics/mittens)\n",
        "\n",
        "* [한국어 소설 텍스트 데이터 미세조정 모델 학습 - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) 👉 선택 (glove 모델 예제는 아닙니다. fine-tuning 에 초점을 두어서 참고해주시면 좋을 것 같습니다.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U mittens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQy8h1PpAbUN",
        "outputId": "b1b211ad-e0b6-4ccc-f387-20ea28e302cb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mittens in /usr/local/lib/python3.7/dist-packages (0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mittens) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "from mittens import GloVe, Mittens\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pickle\n",
        "\n",
        "\n",
        "def glove2dict(glove_filename):\n",
        "    with open(glove_filename, encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
        "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
        "                for line in reader}\n",
        "    return embed\n",
        "\n",
        "glove_path = \"glove.6B.50d.txt\" # get it from https://nlp.stanford.edu/projects/glove\n",
        "pre_glove = glove2dict(glove_path)\n",
        "\n",
        "sw = list(_stop_words.ENGLISH_STOP_WORDS)\n",
        "brown_data = brown.words()[:200000]\n",
        "brown_nonstop = [token.lower() for token in brown_data if (token.lower() not in sw)]\n",
        "oov = [token for token in brown_nonstop if token not in pre_glove.keys()]\n",
        "\n",
        "def get_rareoov(xdict, val):\n",
        "    return [k for (k,v) in Counter(xdict).items() if v<=val]\n",
        "\n",
        "#oov_rare = get_rareoov(oov, 1)\n",
        "#corp_vocab = list(set(oov) - set(oov_rare))\n",
        "#brown_tokens = [token for token in brown_nonstop if token not in oov_rare]\n",
        "#brown_doc = [' '.join(brown_tokens)]\n",
        "\n",
        "corp_vocab = list(set(oov))\n",
        "brown_doc = [' '.join(brown_nonstop)]\n",
        "\n",
        "cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n",
        "X = cv.fit_transform(brown_doc)\n",
        "Xc = (X.T * X)\n",
        "Xc.setdiag(0)\n",
        "coocc_ar = Xc.toarray()\n",
        "\n",
        "mittens_model = Mittens(n=50, max_iter=1000)\n",
        "\n",
        "new_embeddings = mittens_model.fit(\n",
        "    coocc_ar,\n",
        "    vocab=corp_vocab,\n",
        "    initial_embedding_dict= pre_glove)\n",
        "\n",
        "newglove = dict(zip(corp_vocab, new_embeddings))\n",
        "f = open(\"repo_glove.pkl\",\"wb\")\n",
        "pickle.dump(newglove, f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "d0NLK-aXAVXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zz90bW_-MmIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-OB9Siga3G"
      },
      "source": [
        "* (참고) word2vec pretrained example\n",
        "\n",
        "➕ [word2vec 사전학습 모델 -한국어1](http://doc.mindscale.kr/km/unstructured/11.html)\n",
        "\n",
        "➕ [word2vec 사전학습 - 한국어2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUWWDwdiPLS9"
      },
      "source": [
        "### **2️⃣ NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N0B4VknPkTk"
      },
      "source": [
        "👀 **내용 복습** \n",
        "* 개체명 인식을 사용하면 코퍼스로부터 어떤 단어가 사람, 장소, 조직 등을 의미하는 단어인지를 찾을 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgla1BuPRqJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "🔹 **2-(1)** NER task by nltk library\n",
        "\n",
        "\n",
        "* nltk 에서는 개체명 인식기 (NER chunker) 를 지원하고 있다. \n",
        "* ne_chunk 는 개체명을 태깅하기 위해서 앞서 품사 태깅 pos_tag 가 수행되어야 한다. \n",
        "\n",
        "\n",
        "📌 [basic code](https://wikidocs.net/30682) 👉 필수 \n",
        "\n",
        "📌 [BIO 표현, LSTM을 활용한 NER 실습](https://wikidocs.net/24682) 👉 선택\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "diaZweMyAxJz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k09tKha3Lgi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX-WtSvPmm6"
      },
      "source": [
        "🔹 **2-(2)** NER task by spacy library\n",
        "\n",
        "\n",
        "* spaCy 는 자연어처리를 위한 파이썬 기반의 오픈 소스 라이브러리로 다음과 같은 기능을 제공한다. \n",
        "  * Tokenization \n",
        "  * POS tagging \n",
        "  * Lemmatization \n",
        "  * Sentence Boundary Detection (SBD)\n",
        "  * Named Entity Recognition (NER)\n",
        "  * Similarity\n",
        "  * Text Classification\n",
        "  * Rule-based Matching\n",
        "  * Training\n",
        "  * Serialization\n",
        "\n",
        "* spaCy 와 NER\n",
        "  * .ents → .label_\n",
        "\n",
        "\n",
        "📌 [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) 👉 필수 (NER 부분만)\n",
        "\n",
        "📌 [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) 👉 선택\n",
        "\n",
        "  * 훈련되지 않은 데이터 세트에 명명된 엔티티를 학습하는 방법 : 이력서 pdf 데이터 활용 \n",
        "  * manually labelled \n",
        "\n",
        "📌 [한국어 NER](https://github.com/monologg/KoBERT-NER) 👉 참고하면 좋을 자료\n",
        "\n",
        "➕ [참고](http://aispiration.com/nlp2/nlp-ner-python.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXjRfz-qP0Xx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008-V5QsQG25"
      },
      "source": [
        "###**3️⃣ Dependency Parsing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfcodHQQPlt"
      },
      "source": [
        "👀 **내용 복습** \n",
        "* 문장의 전체적인 구성/구조 보다는 각 개별단어 간의 '의존관계' 또는 '수식관계' 와 같은 단어간 관계를 파악하는 것이 목적인 NLP Task\n",
        "* 문장 해석의 모호성을 없애기 위해 Parsing 을 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJLAzZnbRNlL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "🔹 **3-(1)** Dependency Parsing by spacy library\n",
        "\n",
        "\n",
        "* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) 👉 dependecy parsing 부분만 필수\n",
        "* .dep_ 메서드\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbQEYt76bJXz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9QAEsrLAxHP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQD5oiGgRfHe"
      },
      "source": [
        "🔹 **3-(2)** Spacy (kaggle) \n",
        "\n",
        "* 캐글 노트북 환경에서 실습해보는 것을 권장드립니다!\n",
        "\n",
        "* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) 👉 필수\n",
        "  * 도날드 트럼프 트위터 트윗 내용 데이터 분석\n",
        "\n",
        "\n",
        "👀 **노트북 키포인트** \n",
        "  1. spacy.display 메서드를 사용한 NER 시각화 \n",
        "  2. Tagging 을 통한 트럼프 트윗 분석 : noun_chunks 는 dependency graph를 고려하여, noun phrase를 뽑아준다. \n",
        "  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : 직접 문장/단어 패턴을 등록하여 parsing\n",
        "  4. Question and answering task using Dependency Parsing\n",
        "    * spacy display :  ``style = 'dep'``\n",
        "    * .dep_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuHGKITRbKYq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uMArOUrxAJ8K"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xUWWDwdiPLS9",
        "008-V5QsQG25"
      ],
      "name": "week5_nlp_hw.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}