{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffffff-990917/2022-1-Euron-Study-Assignments/blob/Week_6/week5_nlp_hw_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUHfXkPAORh"
      },
      "source": [
        "üìå week5 ÎÇ¥Ïö© Ï£ºÏ∞®Ïóê Ìï¥ÎãπÎêòÎäî Í≥ºÏ†úÎäî 3Ï£ºÏ∞®Ïùò Glove Î™®Îç∏ Ïã§Ïäµ, 4Ï£ºÏ∞®Ïùò NER task Ïã§Ïäµ, 5Ï£ºÏ∞®Ïùò Dependency Parsing task Ïã§ÏäµÏúºÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÏäµÎãàÎã§. (**Ï∞∏Í≥†** : Ï†úÏ∂úÏùÄ week6 branch Î≥µÏäµÍ≥ºÏ†úÎ°ú!) \n",
        "\n",
        "üìå ÏúÑÌÇ§ÎèÖÏä§Ïùò Îî•Îü¨ÎãùÏùÑ Ïù¥Ïö©Ìïú ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÏûÖÎ¨∏ ÍµêÏû¨ Ïã§Ïäµ, Ï∫êÍ∏Ä ÎÖ∏Ìä∏Î∂Å Îì±Ïùò ÏûêÎ£åÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ÏûàÎäî Í≥ºÏ†úÏûÖÎãàÎã§. \n",
        "\n",
        "üìå ÏïàÎÇ¥Îêú ÎßÅÌÅ¨Ïóê ÎßûÏ∂îÏñ¥ **ÏßÅÏ†ë ÏΩîÎìúÎ•º Îî∞Îùº ÏπòÎ©¥ÏÑú (ÌïÑÏÇ¨)** Ìï¥Îãπ nlp task Ïùò Í∏∞Î≥∏Ï†ÅÏù∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ÏôÄ Î©îÏÑúÎìúÎ•º ÏàôÏßÄÌï¥Î≥¥ÏãúÎ©¥ Ï¢ãÏùÑ Í≤É Í∞ôÏäµÎãàÎã§üòä ÌïÑÏàòÎùºÍ≥† Ï≤¥ÌÅ¨Ìïú Î∂ÄÎ∂ÑÏùÄ Í≥ºÏ†úÏóê Î∞òÎìúÏãú Ìè¨Ìï®ÏãúÏºúÏ£ºÏãúÍ≥†, ÏÑ†ÌÉùÏúºÎ°ú Ï≤¥ÌÅ¨Ìïú Î∂ÄÎ∂ÑÏùÄ ÏûêÏú®Ï†ÅÏúºÎ°ú Ïä§ÌÑ∞Îîî ÌïòÏãúÎ©¥ Îê©ÎãàÎã§.\n",
        "\n",
        "üìå Í∂ÅÍ∏àÌïú ÏÇ¨Ìï≠ÏùÄ ÍπÉÌóàÎ∏å Ïù¥ÏäàÎÇò, Ïπ¥ÌÜ°Î∞©, ÏÑ∏ÏÖò Î∞úÌëú ÏãúÏûë Ïù¥Ï†Ñ ÏãúÍ∞Ñ Îì±ÏùÑ ÌôúÏö©ÌïòÏó¨ ÏûêÏú†Î°≠Í≤å Í≥µÏú†Ìï¥Ï£ºÏÑ∏Ïöî!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjTSbcxBB6o",
        "outputId": "cc4530f2-2e95-4721-b8d1-443b8fd5af11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk colab ÌôòÍ≤ΩÏóêÏÑú Ïã§ÌñâÏãú ÌïÑÏöîÌïú ÏΩîÎìúÏûÖÎãàÎã§. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPZn15zBHIv"
      },
      "source": [
        "### 1Ô∏è‚É£ **Glove**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11biHcUuBaH"
      },
      "source": [
        "üëÄ **ÎÇ¥Ïö© Î≥µÏäµ** \n",
        "* Ïä§ÌÉ†Ìè¨Îìú ÎåÄÌïôÏóêÏÑú Í∞úÎ∞úÌïú Ïπ¥Ïö¥Ìä∏ Í∏∞Î∞òÍ≥º ÏòàÏ∏° Í∏∞Î∞òÏùÑ Î™®Îëê ÏÇ¨Ïö©ÌïòÎäî Îã®Ïñ¥ ÏûÑÎ≤†Îî© Î∞©Î≤ïÎ°† \n",
        "* word2vec Ïùò Îã®Ï†êÏùÑ Î≥¥ÏôÑÌï¥ÏÑú ÎÇòÏò® Î™®Îç∏ \n",
        "* glove model Ïùò **input ÏùÄ Î∞òÎìúÏãú ÎèôÏãúÎì±Ïû•ÌñâÎ†¨ ÌòïÌÉú**Ïó¨Ïïº ÌïúÎã§ ‚≠ê\n",
        "\n",
        "![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ü§î ÌïúÍµ≠Ïñ¥ ÏòàÏ†úÎäî ÏóÜÎäî Í≤É Í∞ôÏäµÎãàÎã§. ÎÖºÎ¨∏ÏóêÏÑúÎäî k-Glove Î°ú ÏÜåÍ∞úÎêòÎäî Ïó∞Íµ¨Í∞Ä ÏûàÍ∏¥ ÌïúÎç∞, Ï¢Ä Îçî ÏïåÏïÑÎ¥êÏïº Ìï† Í≤É Í∞ôÏïÑÏöî!\n",
        "\n",
        "‚ûï [ÎÖºÎ¨∏1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n",
        "\n",
        "\n",
        "‚ûï[ÎÖºÎ¨∏2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asGcGy6fBM1E"
      },
      "source": [
        "üîπ **1-(1)** glove python\n",
        "\n",
        "* [Ïã§Ïäµ : basic code](https://wikidocs.net/22885) üëâ ÌïÑÏàò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31NoJdu5t3p",
        "outputId": "d9372b81-621b-491f-8a98-89f7bde68e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glove_python_binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñç                               | 10 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |‚ñä                               | 20 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà                               | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñç                              | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñä                              | 51 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà                              | 61 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñç                             | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñä                             | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà                             | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñå                            | 102 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñâ                            | 112 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñè                           | 122 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñå                           | 133 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 143 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 153 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 163 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 174 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 184 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 194 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 204 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 215 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 225 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 235 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 245 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 256 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 266 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 276 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 286 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 296 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 307 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 317 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 327 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 337 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 348 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 358 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 368 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 378 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 389 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 399 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 409 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 419 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 430 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 440 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 450 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 460 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 471 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 481 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 491 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 501 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 512 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 522 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 532 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 542 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 552 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 563 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 573 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 583 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 593 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 604 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 614 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 624 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 634 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 645 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 655 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 665 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 675 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 686 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 696 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 706 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 716 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 727 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 737 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 747 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 757 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 768 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 778 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 788 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 798 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 808 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 819 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 829 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 839 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 849 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 860 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 870 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 880 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 890 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 901 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 911 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 921 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 931 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 942 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 948 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.4.1)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install glove_python_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "892HWyUA8DzU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLXI6GT8HD2",
        "outputId": "7b6fdd1f-7d94-4357-8b51-27d07637519c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7f7359834d50>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml ÌååÏùºÎ°úÎ∂ÄÌÑ∞ <content>ÏôÄ </content> ÏÇ¨Ïù¥Ïùò ÎÇ¥Ïö©Îßå Í∞ÄÏ†∏Ïò®Îã§.\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# Ï†ïÍ∑ú ÌëúÌòÑÏãùÏùò sub Î™®ÎìàÏùÑ ÌÜµÌï¥ content Ï§ëÍ∞ÑÏóê Îì±Ïû•ÌïòÎäî (Audio), (Laughter) Îì±Ïùò Î∞∞Í≤ΩÏùå Î∂ÄÎ∂ÑÏùÑ Ï†úÍ±∞.\n",
        "# Ìï¥Îãπ ÏΩîÎìúÎäî Í¥ÑÌò∏Î°ú Íµ¨ÏÑ±Îêú ÎÇ¥Ïö©ÏùÑ Ï†úÍ±∞.\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# ÏûÖÎ†• ÏΩîÌçºÏä§Ïóê ÎåÄÌï¥ÏÑú NLTKÎ•º Ïù¥Ïö©ÌïòÏó¨ Î¨∏Ïû• ÌÜ†ÌÅ∞ÌôîÎ•º ÏàòÌñâ.\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# Í∞Å Î¨∏Ïû•Ïóê ÎåÄÌï¥ÏÑú Íµ¨ÎëêÏ†êÏùÑ Ï†úÍ±∞ÌïòÍ≥†, ÎåÄÎ¨∏ÏûêÎ•º ÏÜåÎ¨∏ÏûêÎ°ú Î≥ÄÌôò.\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# Í∞Å Î¨∏Ïû•Ïóê ÎåÄÌï¥ÏÑú NLTKÎ•º Ïù¥Ïö©ÌïòÏó¨ Îã®Ïñ¥ ÌÜ†ÌÅ∞ÌôîÎ•º ÏàòÌñâ.\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "metadata": {
        "id": "hi9iLBWE8SSV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n"
      ],
      "metadata": {
        "id": "miw-pnv58XP3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ta6QgoKO5uXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3134882b-4fac-44ec-c713-e5ffa8186cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 20 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n"
          ]
        }
      ],
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus() \n",
        "\n",
        "# ÌõàÎ†® Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ GloVeÏóêÏÑú ÏÇ¨Ïö©Ìï† ÎèôÏãú Îì±Ïû• ÌñâÎ†¨ ÏÉùÏÑ±\n",
        "corpus.fit(result, window=5)\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "\n",
        "# ÌïôÏäµÏóê Ïù¥Ïö©Ìï† Ïì∞Î†àÎìúÏùò Í∞úÏàòÎäî 4Î°ú ÏÑ§Ï†ï, ÏóêÌè¨ÌÅ¨Îäî 20.\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"man\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTAQFc2T-FOW",
        "outputId": "d3abed33-e4e0-4551-d5fa-4357b23e00df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.9559094109715531), ('guy', 0.8741184184126037), ('girl', 0.8606195933304777), ('young', 0.8422164942402133)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"boy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6CG6sFb8B-Y",
        "outputId": "869644ee-249e-41e2-fe61-5c5bc377fca5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('girl', 0.9356188983134577), ('woman', 0.8484545837042662), ('kid', 0.8191819749594064), ('man', 0.8160057192289812)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"university\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQCeUZSN-5dU",
        "outputId": "482ae1e4-79c3-4d4c-f54d-58d0dd0a337c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('harvard', 0.8996833680801852), ('cambridge', 0.8479653746935998), ('mit', 0.8474664193791818), ('stanford', 0.8471945455119274)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"water\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEKgEar1-9gr",
        "outputId": "13bca922-78be-4aa4-ecf4-b55f68e8f10c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('air', 0.8403620992805466), ('clean', 0.8365725718884546), ('fresh', 0.8341815547578887), ('food', 0.8128734435111281)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"physics\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zWeUnXm-_kU",
        "outputId": "c6d1c616-13b7-41b5-f1e3-9febd9d5ca3d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('chemistry', 0.88505321795099), ('economics', 0.8740865968926251), ('beauty', 0.8643784093635186), ('mathematics', 0.8585187948793694)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"muscle\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N40Cpph_CRs",
        "outputId": "a3b3a65b-5f5d-495a-9ee1-9c4998506351"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tissue', 0.8297660188805107), ('nerve', 0.8147653595943043), ('channel', 0.7860179607228286), ('stem', 0.7653359979828239)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"clean\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5LD5O22_Igq",
        "outputId": "7eaf714f-da7e-4751-809d-84e3fa03f562"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fresh', 0.8393722527260793), ('water', 0.8365725718884547), ('wind', 0.8111498493005345), ('heat', 0.8011436024811395)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ADfVM9lO9NE"
      },
      "source": [
        "üîπ **1-(2)** pre-trained glove \n",
        "\n",
        "* **ÏÇ¨Ï†ÑÌïôÏäµÎ™®Îç∏** : ÏûÑÏùòÏùò Í∞íÏúºÎ°ú Ï¥àÍ∏∞ÌôîÌïòÎçò Î™®Îç∏Ïùò Í∞ÄÏ§ëÏπòÎì§ÏùÑ Îã§Î•∏ Î¨∏Ï†úÏóê ÌïôÏäµÏãúÌÇ® Í∞ÄÏ§ëÏπòÎì§Î°ú Ï¥àÍ∏∞ÌôîÌïòÎäî Î∞©Î≤ïÏù¥Îã§.ÏÇ¨Ï†Ñ ÌïôÏäµÌïú Í∞ÄÏ§ëÏπòÎ•º ÌôúÏö©Ìï¥ ÌïôÏäµÌïòÍ≥†Ïûê ÌïòÎäî Î≥∏Îûò Î¨∏Ï†úÎ•º ÌïòÏúÑÎ¨∏Ï†úÎùºÍ≥† ÌïúÎã§. \n",
        "\n",
        "* [Ïã§Ïäµ : Î¨∏Ïû•Ïùò Í∏çÎ∂ÄÏ†ïÏùÑ ÌåêÎã®ÌïòÎäî Í∞êÏÑ± Î∂ÑÎ•ò Î™®Îç∏ ÎßåÎì§Í∏∞](https://wikidocs.net/33793) üëâ ÌïÑÏàò\n",
        "  * [ÏÑ§Î™ÖÏ∞∏Í≥†](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n",
        "* pre-trained data Î•º Í∞ÄÏ†∏Ïò§ÎäîÎç∞ ÏãúÍ∞ÑÏù¥ Ïò§ÎûòÍ±∏Î¶º\n",
        "* kaggle ÎåÄÌöåÏóêÏÑú Ï£ºÎ°ú Ïù¥ Î∞©ÏãùÏùÑ ÎßéÏù¥ ÏÇ¨Ïö©Ìï®\n",
        "  * [Ï∞∏Í≥†](https://lsjsj92.tistory.com/455)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "id": "6sy91m2jB3TP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZlngY35O53sk"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "output_dim = 128\n",
        "input_length = 500\n",
        "\n",
        "v = Embedding(vocab_size, output_dim, input_length = input_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "N_iP5rM-vZAF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # Ìå®Îî©ÏùÑ Í≥†Î†§ÌïòÏó¨ +1\n",
        "print('Îã®Ïñ¥ ÏßëÌï© :',vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yREDjAgevhg4",
        "outputId": "e48e80e2-7e86-4ef3-dd05-239b1d7473f9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Îã®Ïñ¥ ÏßëÌï© : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print('Ï†ïÏàò Ïù∏ÏΩîÎî© Í≤∞Í≥º :',X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRosktDVvkoq",
        "outputId": "efd3df84-3730-40cc-bb22-b6a79c1b4706"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ï†ïÏàò Ïù∏ÏΩîÎî© Í≤∞Í≥º : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('ÏµúÎåÄ Í∏∏Ïù¥ :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osiWeHVyvoBM",
        "outputId": "d1ff976d-acb1-4842-9a2a-c88e3d4a641e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏµúÎåÄ Í∏∏Ïù¥ : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_train = np.array(y_train)\n",
        "print('Ìå®Îî© Í≤∞Í≥º :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8IyS69UvtcZ",
        "outputId": "ed9fa85f-b479-489a-ffcc-3bcca68cf2a7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ìå®Îî© Í≤∞Í≥º :\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "embedding_dim = 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b90taTBvzSI",
        "outputId": "1e2505f2-d88f-4314-b291-87b0524149cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 7 samples\n",
            "Epoch 1/100\n",
            "7/7 - 0s - loss: 0.6926 - acc: 0.5714 - 139ms/epoch - 20ms/sample\n",
            "Epoch 2/100\n",
            "7/7 - 0s - loss: 0.6915 - acc: 0.7143 - 6ms/epoch - 925us/sample\n",
            "Epoch 3/100\n",
            "7/7 - 0s - loss: 0.6905 - acc: 0.7143 - 5ms/epoch - 754us/sample\n",
            "Epoch 4/100\n",
            "7/7 - 0s - loss: 0.6894 - acc: 0.7143 - 6ms/epoch - 885us/sample\n",
            "Epoch 5/100\n",
            "7/7 - 0s - loss: 0.6884 - acc: 0.7143 - 9ms/epoch - 1ms/sample\n",
            "Epoch 6/100\n",
            "7/7 - 0s - loss: 0.6873 - acc: 0.7143 - 5ms/epoch - 648us/sample\n",
            "Epoch 7/100\n",
            "7/7 - 0s - loss: 0.6862 - acc: 0.8571 - 3ms/epoch - 485us/sample\n",
            "Epoch 8/100\n",
            "7/7 - 0s - loss: 0.6852 - acc: 0.8571 - 4ms/epoch - 616us/sample\n",
            "Epoch 9/100\n",
            "7/7 - 0s - loss: 0.6841 - acc: 0.8571 - 4ms/epoch - 562us/sample\n",
            "Epoch 10/100\n",
            "7/7 - 0s - loss: 0.6830 - acc: 0.8571 - 3ms/epoch - 484us/sample\n",
            "Epoch 11/100\n",
            "7/7 - 0s - loss: 0.6820 - acc: 0.8571 - 6ms/epoch - 841us/sample\n",
            "Epoch 12/100\n",
            "7/7 - 0s - loss: 0.6809 - acc: 0.8571 - 3ms/epoch - 359us/sample\n",
            "Epoch 13/100\n",
            "7/7 - 0s - loss: 0.6798 - acc: 0.8571 - 4ms/epoch - 578us/sample\n",
            "Epoch 14/100\n",
            "7/7 - 0s - loss: 0.6787 - acc: 0.8571 - 4ms/epoch - 620us/sample\n",
            "Epoch 15/100\n",
            "7/7 - 0s - loss: 0.6776 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 16/100\n",
            "7/7 - 0s - loss: 0.6765 - acc: 1.0000 - 4ms/epoch - 507us/sample\n",
            "Epoch 17/100\n",
            "7/7 - 0s - loss: 0.6755 - acc: 1.0000 - 5ms/epoch - 761us/sample\n",
            "Epoch 18/100\n",
            "7/7 - 0s - loss: 0.6743 - acc: 1.0000 - 5ms/epoch - 646us/sample\n",
            "Epoch 19/100\n",
            "7/7 - 0s - loss: 0.6732 - acc: 1.0000 - 3ms/epoch - 491us/sample\n",
            "Epoch 20/100\n",
            "7/7 - 0s - loss: 0.6721 - acc: 1.0000 - 6ms/epoch - 848us/sample\n",
            "Epoch 21/100\n",
            "7/7 - 0s - loss: 0.6710 - acc: 1.0000 - 3ms/epoch - 415us/sample\n",
            "Epoch 22/100\n",
            "7/7 - 0s - loss: 0.6699 - acc: 1.0000 - 4ms/epoch - 552us/sample\n",
            "Epoch 23/100\n",
            "7/7 - 0s - loss: 0.6687 - acc: 1.0000 - 3ms/epoch - 450us/sample\n",
            "Epoch 24/100\n",
            "7/7 - 0s - loss: 0.6676 - acc: 1.0000 - 4ms/epoch - 520us/sample\n",
            "Epoch 25/100\n",
            "7/7 - 0s - loss: 0.6664 - acc: 1.0000 - 4ms/epoch - 553us/sample\n",
            "Epoch 26/100\n",
            "7/7 - 0s - loss: 0.6653 - acc: 1.0000 - 4ms/epoch - 507us/sample\n",
            "Epoch 27/100\n",
            "7/7 - 0s - loss: 0.6641 - acc: 1.0000 - 4ms/epoch - 522us/sample\n",
            "Epoch 28/100\n",
            "7/7 - 0s - loss: 0.6629 - acc: 1.0000 - 4ms/epoch - 582us/sample\n",
            "Epoch 29/100\n",
            "7/7 - 0s - loss: 0.6617 - acc: 1.0000 - 4ms/epoch - 604us/sample\n",
            "Epoch 30/100\n",
            "7/7 - 0s - loss: 0.6605 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 31/100\n",
            "7/7 - 0s - loss: 0.6593 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 32/100\n",
            "7/7 - 0s - loss: 0.6581 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 33/100\n",
            "7/7 - 0s - loss: 0.6569 - acc: 1.0000 - 11ms/epoch - 2ms/sample\n",
            "Epoch 34/100\n",
            "7/7 - 0s - loss: 0.6556 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 35/100\n",
            "7/7 - 0s - loss: 0.6544 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 36/100\n",
            "7/7 - 0s - loss: 0.6531 - acc: 1.0000 - 5ms/epoch - 771us/sample\n",
            "Epoch 37/100\n",
            "7/7 - 0s - loss: 0.6518 - acc: 1.0000 - 4ms/epoch - 510us/sample\n",
            "Epoch 38/100\n",
            "7/7 - 0s - loss: 0.6505 - acc: 1.0000 - 4ms/epoch - 605us/sample\n",
            "Epoch 39/100\n",
            "7/7 - 0s - loss: 0.6492 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 40/100\n",
            "7/7 - 0s - loss: 0.6479 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 41/100\n",
            "7/7 - 0s - loss: 0.6466 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 42/100\n",
            "7/7 - 0s - loss: 0.6453 - acc: 1.0000 - 3ms/epoch - 480us/sample\n",
            "Epoch 43/100\n",
            "7/7 - 0s - loss: 0.6439 - acc: 1.0000 - 3ms/epoch - 469us/sample\n",
            "Epoch 44/100\n",
            "7/7 - 0s - loss: 0.6425 - acc: 1.0000 - 3ms/epoch - 482us/sample\n",
            "Epoch 45/100\n",
            "7/7 - 0s - loss: 0.6412 - acc: 1.0000 - 4ms/epoch - 587us/sample\n",
            "Epoch 46/100\n",
            "7/7 - 0s - loss: 0.6398 - acc: 1.0000 - 6ms/epoch - 823us/sample\n",
            "Epoch 47/100\n",
            "7/7 - 0s - loss: 0.6384 - acc: 1.0000 - 5ms/epoch - 660us/sample\n",
            "Epoch 48/100\n",
            "7/7 - 0s - loss: 0.6370 - acc: 1.0000 - 5ms/epoch - 652us/sample\n",
            "Epoch 49/100\n",
            "7/7 - 0s - loss: 0.6355 - acc: 1.0000 - 4ms/epoch - 522us/sample\n",
            "Epoch 50/100\n",
            "7/7 - 0s - loss: 0.6341 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 51/100\n",
            "7/7 - 0s - loss: 0.6326 - acc: 1.0000 - 5ms/epoch - 707us/sample\n",
            "Epoch 52/100\n",
            "7/7 - 0s - loss: 0.6312 - acc: 1.0000 - 6ms/epoch - 839us/sample\n",
            "Epoch 53/100\n",
            "7/7 - 0s - loss: 0.6297 - acc: 1.0000 - 5ms/epoch - 675us/sample\n",
            "Epoch 54/100\n",
            "7/7 - 0s - loss: 0.6282 - acc: 1.0000 - 5ms/epoch - 717us/sample\n",
            "Epoch 55/100\n",
            "7/7 - 0s - loss: 0.6267 - acc: 1.0000 - 5ms/epoch - 708us/sample\n",
            "Epoch 56/100\n",
            "7/7 - 0s - loss: 0.6252 - acc: 1.0000 - 4ms/epoch - 501us/sample\n",
            "Epoch 57/100\n",
            "7/7 - 0s - loss: 0.6236 - acc: 1.0000 - 3ms/epoch - 435us/sample\n",
            "Epoch 58/100\n",
            "7/7 - 0s - loss: 0.6221 - acc: 1.0000 - 6ms/epoch - 927us/sample\n",
            "Epoch 59/100\n",
            "7/7 - 0s - loss: 0.6205 - acc: 1.0000 - 5ms/epoch - 722us/sample\n",
            "Epoch 60/100\n",
            "7/7 - 0s - loss: 0.6189 - acc: 1.0000 - 4ms/epoch - 642us/sample\n",
            "Epoch 61/100\n",
            "7/7 - 0s - loss: 0.6174 - acc: 1.0000 - 6ms/epoch - 838us/sample\n",
            "Epoch 62/100\n",
            "7/7 - 0s - loss: 0.6158 - acc: 1.0000 - 5ms/epoch - 666us/sample\n",
            "Epoch 63/100\n",
            "7/7 - 0s - loss: 0.6142 - acc: 1.0000 - 4ms/epoch - 573us/sample\n",
            "Epoch 64/100\n",
            "7/7 - 0s - loss: 0.6125 - acc: 1.0000 - 5ms/epoch - 730us/sample\n",
            "Epoch 65/100\n",
            "7/7 - 0s - loss: 0.6109 - acc: 1.0000 - 4ms/epoch - 612us/sample\n",
            "Epoch 66/100\n",
            "7/7 - 0s - loss: 0.6093 - acc: 1.0000 - 4ms/epoch - 565us/sample\n",
            "Epoch 67/100\n",
            "7/7 - 0s - loss: 0.6076 - acc: 1.0000 - 5ms/epoch - 713us/sample\n",
            "Epoch 68/100\n",
            "7/7 - 0s - loss: 0.6059 - acc: 1.0000 - 6ms/epoch - 842us/sample\n",
            "Epoch 69/100\n",
            "7/7 - 0s - loss: 0.6042 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 70/100\n",
            "7/7 - 0s - loss: 0.6025 - acc: 1.0000 - 5ms/epoch - 711us/sample\n",
            "Epoch 71/100\n",
            "7/7 - 0s - loss: 0.6008 - acc: 1.0000 - 5ms/epoch - 656us/sample\n",
            "Epoch 72/100\n",
            "7/7 - 0s - loss: 0.5991 - acc: 1.0000 - 4ms/epoch - 506us/sample\n",
            "Epoch 73/100\n",
            "7/7 - 0s - loss: 0.5974 - acc: 1.0000 - 4ms/epoch - 631us/sample\n",
            "Epoch 74/100\n",
            "7/7 - 0s - loss: 0.5956 - acc: 1.0000 - 4ms/epoch - 597us/sample\n",
            "Epoch 75/100\n",
            "7/7 - 0s - loss: 0.5939 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 76/100\n",
            "7/7 - 0s - loss: 0.5921 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 77/100\n",
            "7/7 - 0s - loss: 0.5903 - acc: 1.0000 - 5ms/epoch - 645us/sample\n",
            "Epoch 78/100\n",
            "7/7 - 0s - loss: 0.5885 - acc: 1.0000 - 5ms/epoch - 660us/sample\n",
            "Epoch 79/100\n",
            "7/7 - 0s - loss: 0.5867 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 80/100\n",
            "7/7 - 0s - loss: 0.5849 - acc: 1.0000 - 6ms/epoch - 892us/sample\n",
            "Epoch 81/100\n",
            "7/7 - 0s - loss: 0.5831 - acc: 1.0000 - 4ms/epoch - 615us/sample\n",
            "Epoch 82/100\n",
            "7/7 - 0s - loss: 0.5813 - acc: 1.0000 - 4ms/epoch - 643us/sample\n",
            "Epoch 83/100\n",
            "7/7 - 0s - loss: 0.5794 - acc: 1.0000 - 6ms/epoch - 908us/sample\n",
            "Epoch 84/100\n",
            "7/7 - 0s - loss: 0.5776 - acc: 1.0000 - 7ms/epoch - 941us/sample\n",
            "Epoch 85/100\n",
            "7/7 - 0s - loss: 0.5757 - acc: 1.0000 - 4ms/epoch - 616us/sample\n",
            "Epoch 86/100\n",
            "7/7 - 0s - loss: 0.5738 - acc: 1.0000 - 4ms/epoch - 561us/sample\n",
            "Epoch 87/100\n",
            "7/7 - 0s - loss: 0.5719 - acc: 1.0000 - 4ms/epoch - 641us/sample\n",
            "Epoch 88/100\n",
            "7/7 - 0s - loss: 0.5700 - acc: 1.0000 - 4ms/epoch - 541us/sample\n",
            "Epoch 89/100\n",
            "7/7 - 0s - loss: 0.5681 - acc: 1.0000 - 3ms/epoch - 432us/sample\n",
            "Epoch 90/100\n",
            "7/7 - 0s - loss: 0.5662 - acc: 1.0000 - 6ms/epoch - 836us/sample\n",
            "Epoch 91/100\n",
            "7/7 - 0s - loss: 0.5643 - acc: 1.0000 - 6ms/epoch - 801us/sample\n",
            "Epoch 92/100\n",
            "7/7 - 0s - loss: 0.5623 - acc: 1.0000 - 5ms/epoch - 685us/sample\n",
            "Epoch 93/100\n",
            "7/7 - 0s - loss: 0.5604 - acc: 1.0000 - 4ms/epoch - 631us/sample\n",
            "Epoch 94/100\n",
            "7/7 - 0s - loss: 0.5584 - acc: 1.0000 - 3ms/epoch - 480us/sample\n",
            "Epoch 95/100\n",
            "7/7 - 0s - loss: 0.5565 - acc: 1.0000 - 4ms/epoch - 605us/sample\n",
            "Epoch 96/100\n",
            "7/7 - 0s - loss: 0.5545 - acc: 1.0000 - 7ms/epoch - 959us/sample\n",
            "Epoch 97/100\n",
            "7/7 - 0s - loss: 0.5525 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 98/100\n",
            "7/7 - 0s - loss: 0.5505 - acc: 1.0000 - 5ms/epoch - 699us/sample\n",
            "Epoch 99/100\n",
            "7/7 - 0s - loss: 0.5486 - acc: 1.0000 - 6ms/epoch - 795us/sample\n",
            "Epoch 100/100\n",
            "7/7 - 0s - loss: 0.5465 - acc: 1.0000 - 4ms/epoch - 533us/sample\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7339a21ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUAnYybOwLIA",
        "outputId": "c72bd10c-56a8-4ff0-cd0c-f46995967944"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3PfPdt7wOa1",
        "outputId": "21fd6511-c0fb-4b3d-9c23-e1c8ea8683f6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve, urlopen\n",
        "import gzip\n",
        "import zipfile\n",
        "\n",
        "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
        "zf = zipfile.ZipFile('glove.6B.zip')\n",
        "zf.extractall() \n",
        "zf.close()"
      ],
      "metadata": {
        "id": "TxugoFoJwcA9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dict = dict()\n",
        "\n",
        "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "\n",
        "    # 100Í∞úÏùò Í∞íÏùÑ Í∞ÄÏßÄÎäî arrayÎ°ú Î≥ÄÌôò\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%sÍ∞úÏùò Embedding vectorÍ∞Ä ÏûàÏäµÎãàÎã§.' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSSZl698x_mA",
        "outputId": "0647bd0f-90d8-4805-f623-7bbe9cb03f4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000Í∞úÏùò Embedding vectorÍ∞Ä ÏûàÏäµÎãàÎã§.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print('Î≤°ÌÑ∞Ïùò Ï∞®Ïõê Ïàò :',len(embedding_dict['respectable']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5Vj5TZ3YzK",
        "outputId": "caec383f-07e7-4735-dbe0-7ad7aff39311"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "Î≤°ÌÑ∞Ïùò Ï∞®Ïõê Ïàò : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('ÏûÑÎ≤†Îî© ÌñâÎ†¨Ïùò ÌÅ¨Í∏∞(shape) :',np.shape(embedding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kIG_aWe3ftL",
        "outputId": "34959db8-1260-498b-86da-bd6026761ba4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏûÑÎ≤†Îî© ÌñâÎ†¨Ïùò ÌÅ¨Í∏∞(shape) : (16, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIrJYizu3pO8",
        "outputId": "4496f420-1d5b-4a6c-b185-0dd16e712eff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Îã®Ïñ¥ greatÏùò ÎßµÌïëÎêú Ï†ïÏàò :',tokenizer.word_index['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rKyie3P3rzp",
        "outputId": "a287e050-d2bf-4f79-ad7a-0e7f4f7f6dcf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Îã®Ïñ¥ greatÏùò ÎßµÌïëÎêú Ï†ïÏàò : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXXjK-gr3wHV",
        "outputId": "fc24ce21-3331-4553-c810-1be4b0f5c11a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.013786   0.38216    0.53236    0.15261   -0.29694   -0.20558\n",
            " -0.41846   -0.58437   -0.77355   -0.87866   -0.37858   -0.18516\n",
            " -0.128     -0.20584   -0.22925   -0.42599    0.3725     0.26077\n",
            " -1.0702     0.62916   -0.091469   0.70348   -0.4973    -0.77691\n",
            "  0.66045    0.09465   -0.44893    0.018917   0.33146   -0.35022\n",
            " -0.35789    0.030313   0.22253   -0.23236   -0.19719   -0.0053125\n",
            " -0.25848    0.58081   -0.10705   -0.17845   -0.16206    0.087086\n",
            "  0.63029   -0.76649    0.51619    0.14073    1.019     -0.43136\n",
            "  0.46138   -0.43585   -0.47568    0.19226    0.36065    0.78987\n",
            "  0.088945  -2.7814    -0.15366    0.01015    1.1798     0.15168\n",
            " -0.050112   1.2626    -0.77527    0.36031    0.95761   -0.11385\n",
            "  0.28035   -0.02591    0.31246   -0.15424    0.3778    -0.13599\n",
            "  0.2946    -0.31579    0.42943    0.086969   0.019169  -0.27242\n",
            " -0.31696    0.37327    0.61997    0.13889    0.17188    0.30363\n",
            " -1.2776     0.044423  -0.52736   -0.88536   -0.19428   -0.61947\n",
            " -0.10146   -0.26301   -0.061707   0.36627   -0.95223   -0.39346\n",
            " -0.69183   -1.0426     0.28855    0.63056  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # Îã®Ïñ¥ÏôÄ ÎßµÌïëÎêòÎäî ÏÇ¨Ï†Ñ ÌõàÎ†®Îêú ÏûÑÎ≤†Îî© Î≤°ÌÑ∞Í∞í\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ],
      "metadata": {
        "id": "dT6aweRr3zQq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_3kaMRy33an",
        "outputId": "ce7dc708-cb25-4c71-b342-1b046a4ca94c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.013786  ,  0.38216001,  0.53236002,  0.15261   , -0.29694   ,\n",
              "       -0.20558   , -0.41846001, -0.58437002, -0.77354997, -0.87866002,\n",
              "       -0.37858   , -0.18516   , -0.12800001, -0.20584001, -0.22925   ,\n",
              "       -0.42598999,  0.3725    ,  0.26076999, -1.07019997,  0.62915999,\n",
              "       -0.091469  ,  0.70348001, -0.4973    , -0.77691001,  0.66044998,\n",
              "        0.09465   , -0.44893   ,  0.018917  ,  0.33146   , -0.35021999,\n",
              "       -0.35789001,  0.030313  ,  0.22253001, -0.23236001, -0.19719   ,\n",
              "       -0.0053125 , -0.25848001,  0.58081001, -0.10705   , -0.17845   ,\n",
              "       -0.16205999,  0.087086  ,  0.63028997, -0.76648998,  0.51618999,\n",
              "        0.14072999,  1.01900005, -0.43136001,  0.46138   , -0.43584999,\n",
              "       -0.47567999,  0.19226   ,  0.36065   ,  0.78987002,  0.088945  ,\n",
              "       -2.78139997, -0.15366   ,  0.01015   ,  1.17980003,  0.15167999,\n",
              "       -0.050112  ,  1.26259995, -0.77526999,  0.36030999,  0.95761001,\n",
              "       -0.11385   ,  0.28035   , -0.02591   ,  0.31246001, -0.15424   ,\n",
              "        0.37779999, -0.13598999,  0.29460001, -0.31579   ,  0.42943001,\n",
              "        0.086969  ,  0.019169  , -0.27241999, -0.31696001,  0.37327   ,\n",
              "        0.61997002,  0.13889   ,  0.17188001,  0.30362999, -1.27760005,\n",
              "        0.044423  , -0.52736002, -0.88536   , -0.19428   , -0.61947   ,\n",
              "       -0.10146   , -0.26301   , -0.061707  ,  0.36627001, -0.95222998,\n",
              "       -0.39346001, -0.69182998, -1.04260004,  0.28854999,  0.63055998])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "output_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFl0SXN1352C",
        "outputId": "79d60beb-3d22-4c3d-c572-21a8cf37a9a4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 7 samples\n",
            "Epoch 1/100\n",
            "7/7 - 0s - loss: 0.5499 - acc: 0.7143 - 31ms/epoch - 4ms/sample\n",
            "Epoch 2/100\n",
            "7/7 - 0s - loss: 0.5317 - acc: 0.7143 - 6ms/epoch - 828us/sample\n",
            "Epoch 3/100\n",
            "7/7 - 0s - loss: 0.5144 - acc: 0.8571 - 4ms/epoch - 627us/sample\n",
            "Epoch 4/100\n",
            "7/7 - 0s - loss: 0.4979 - acc: 0.8571 - 4ms/epoch - 617us/sample\n",
            "Epoch 5/100\n",
            "7/7 - 0s - loss: 0.4821 - acc: 1.0000 - 4ms/epoch - 584us/sample\n",
            "Epoch 6/100\n",
            "7/7 - 0s - loss: 0.4672 - acc: 1.0000 - 4ms/epoch - 613us/sample\n",
            "Epoch 7/100\n",
            "7/7 - 0s - loss: 0.4529 - acc: 1.0000 - 5ms/epoch - 653us/sample\n",
            "Epoch 8/100\n",
            "7/7 - 0s - loss: 0.4394 - acc: 1.0000 - 5ms/epoch - 668us/sample\n",
            "Epoch 9/100\n",
            "7/7 - 0s - loss: 0.4265 - acc: 1.0000 - 4ms/epoch - 639us/sample\n",
            "Epoch 10/100\n",
            "7/7 - 0s - loss: 0.4142 - acc: 1.0000 - 5ms/epoch - 679us/sample\n",
            "Epoch 11/100\n",
            "7/7 - 0s - loss: 0.4025 - acc: 1.0000 - 5ms/epoch - 647us/sample\n",
            "Epoch 12/100\n",
            "7/7 - 0s - loss: 0.3913 - acc: 1.0000 - 4ms/epoch - 586us/sample\n",
            "Epoch 13/100\n",
            "7/7 - 0s - loss: 0.3807 - acc: 1.0000 - 4ms/epoch - 600us/sample\n",
            "Epoch 14/100\n",
            "7/7 - 0s - loss: 0.3705 - acc: 1.0000 - 5ms/epoch - 651us/sample\n",
            "Epoch 15/100\n",
            "7/7 - 0s - loss: 0.3607 - acc: 1.0000 - 4ms/epoch - 615us/sample\n",
            "Epoch 16/100\n",
            "7/7 - 0s - loss: 0.3514 - acc: 1.0000 - 4ms/epoch - 585us/sample\n",
            "Epoch 17/100\n",
            "7/7 - 0s - loss: 0.3424 - acc: 1.0000 - 4ms/epoch - 582us/sample\n",
            "Epoch 18/100\n",
            "7/7 - 0s - loss: 0.3338 - acc: 1.0000 - 10ms/epoch - 1ms/sample\n",
            "Epoch 19/100\n",
            "7/7 - 0s - loss: 0.3255 - acc: 1.0000 - 4ms/epoch - 616us/sample\n",
            "Epoch 20/100\n",
            "7/7 - 0s - loss: 0.3175 - acc: 1.0000 - 4ms/epoch - 573us/sample\n",
            "Epoch 21/100\n",
            "7/7 - 0s - loss: 0.3098 - acc: 1.0000 - 4ms/epoch - 558us/sample\n",
            "Epoch 22/100\n",
            "7/7 - 0s - loss: 0.3023 - acc: 1.0000 - 6ms/epoch - 914us/sample\n",
            "Epoch 23/100\n",
            "7/7 - 0s - loss: 0.2951 - acc: 1.0000 - 5ms/epoch - 660us/sample\n",
            "Epoch 24/100\n",
            "7/7 - 0s - loss: 0.2882 - acc: 1.0000 - 5ms/epoch - 651us/sample\n",
            "Epoch 25/100\n",
            "7/7 - 0s - loss: 0.2814 - acc: 1.0000 - 5ms/epoch - 705us/sample\n",
            "Epoch 26/100\n",
            "7/7 - 0s - loss: 0.2749 - acc: 1.0000 - 6ms/epoch - 801us/sample\n",
            "Epoch 27/100\n",
            "7/7 - 0s - loss: 0.2686 - acc: 1.0000 - 5ms/epoch - 693us/sample\n",
            "Epoch 28/100\n",
            "7/7 - 0s - loss: 0.2624 - acc: 1.0000 - 5ms/epoch - 742us/sample\n",
            "Epoch 29/100\n",
            "7/7 - 0s - loss: 0.2565 - acc: 1.0000 - 5ms/epoch - 769us/sample\n",
            "Epoch 30/100\n",
            "7/7 - 0s - loss: 0.2507 - acc: 1.0000 - 4ms/epoch - 568us/sample\n",
            "Epoch 31/100\n",
            "7/7 - 0s - loss: 0.2451 - acc: 1.0000 - 4ms/epoch - 571us/sample\n",
            "Epoch 32/100\n",
            "7/7 - 0s - loss: 0.2396 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 33/100\n",
            "7/7 - 0s - loss: 0.2344 - acc: 1.0000 - 4ms/epoch - 555us/sample\n",
            "Epoch 34/100\n",
            "7/7 - 0s - loss: 0.2292 - acc: 1.0000 - 4ms/epoch - 510us/sample\n",
            "Epoch 35/100\n",
            "7/7 - 0s - loss: 0.2243 - acc: 1.0000 - 4ms/epoch - 558us/sample\n",
            "Epoch 36/100\n",
            "7/7 - 0s - loss: 0.2194 - acc: 1.0000 - 3ms/epoch - 486us/sample\n",
            "Epoch 37/100\n",
            "7/7 - 0s - loss: 0.2147 - acc: 1.0000 - 4ms/epoch - 588us/sample\n",
            "Epoch 38/100\n",
            "7/7 - 0s - loss: 0.2102 - acc: 1.0000 - 4ms/epoch - 513us/sample\n",
            "Epoch 39/100\n",
            "7/7 - 0s - loss: 0.2058 - acc: 1.0000 - 4ms/epoch - 527us/sample\n",
            "Epoch 40/100\n",
            "7/7 - 0s - loss: 0.2015 - acc: 1.0000 - 4ms/epoch - 614us/sample\n",
            "Epoch 41/100\n",
            "7/7 - 0s - loss: 0.1973 - acc: 1.0000 - 4ms/epoch - 562us/sample\n",
            "Epoch 42/100\n",
            "7/7 - 0s - loss: 0.1933 - acc: 1.0000 - 3ms/epoch - 491us/sample\n",
            "Epoch 43/100\n",
            "7/7 - 0s - loss: 0.1893 - acc: 1.0000 - 3ms/epoch - 481us/sample\n",
            "Epoch 44/100\n",
            "7/7 - 0s - loss: 0.1855 - acc: 1.0000 - 5ms/epoch - 655us/sample\n",
            "Epoch 45/100\n",
            "7/7 - 0s - loss: 0.1818 - acc: 1.0000 - 4ms/epoch - 607us/sample\n",
            "Epoch 46/100\n",
            "7/7 - 0s - loss: 0.1782 - acc: 1.0000 - 4ms/epoch - 597us/sample\n",
            "Epoch 47/100\n",
            "7/7 - 0s - loss: 0.1747 - acc: 1.0000 - 4ms/epoch - 605us/sample\n",
            "Epoch 48/100\n",
            "7/7 - 0s - loss: 0.1714 - acc: 1.0000 - 5ms/epoch - 658us/sample\n",
            "Epoch 49/100\n",
            "7/7 - 0s - loss: 0.1681 - acc: 1.0000 - 4ms/epoch - 598us/sample\n",
            "Epoch 50/100\n",
            "7/7 - 0s - loss: 0.1649 - acc: 1.0000 - 4ms/epoch - 597us/sample\n",
            "Epoch 51/100\n",
            "7/7 - 0s - loss: 0.1618 - acc: 1.0000 - 5ms/epoch - 710us/sample\n",
            "Epoch 52/100\n",
            "7/7 - 0s - loss: 0.1587 - acc: 1.0000 - 6ms/epoch - 841us/sample\n",
            "Epoch 53/100\n",
            "7/7 - 0s - loss: 0.1558 - acc: 1.0000 - 6ms/epoch - 888us/sample\n",
            "Epoch 54/100\n",
            "7/7 - 0s - loss: 0.1530 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 55/100\n",
            "7/7 - 0s - loss: 0.1502 - acc: 1.0000 - 8ms/epoch - 1ms/sample\n",
            "Epoch 56/100\n",
            "7/7 - 0s - loss: 0.1475 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 57/100\n",
            "7/7 - 0s - loss: 0.1449 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 58/100\n",
            "7/7 - 0s - loss: 0.1423 - acc: 1.0000 - 9ms/epoch - 1ms/sample\n",
            "Epoch 59/100\n",
            "7/7 - 0s - loss: 0.1398 - acc: 1.0000 - 13ms/epoch - 2ms/sample\n",
            "Epoch 60/100\n",
            "7/7 - 0s - loss: 0.1374 - acc: 1.0000 - 5ms/epoch - 699us/sample\n",
            "Epoch 61/100\n",
            "7/7 - 0s - loss: 0.1351 - acc: 1.0000 - 5ms/epoch - 658us/sample\n",
            "Epoch 62/100\n",
            "7/7 - 0s - loss: 0.1328 - acc: 1.0000 - 4ms/epoch - 505us/sample\n",
            "Epoch 63/100\n",
            "7/7 - 0s - loss: 0.1306 - acc: 1.0000 - 7ms/epoch - 971us/sample\n",
            "Epoch 64/100\n",
            "7/7 - 0s - loss: 0.1284 - acc: 1.0000 - 10ms/epoch - 1ms/sample\n",
            "Epoch 65/100\n",
            "7/7 - 0s - loss: 0.1263 - acc: 1.0000 - 4ms/epoch - 514us/sample\n",
            "Epoch 66/100\n",
            "7/7 - 0s - loss: 0.1242 - acc: 1.0000 - 4ms/epoch - 625us/sample\n",
            "Epoch 67/100\n",
            "7/7 - 0s - loss: 0.1222 - acc: 1.0000 - 4ms/epoch - 569us/sample\n",
            "Epoch 68/100\n",
            "7/7 - 0s - loss: 0.1202 - acc: 1.0000 - 4ms/epoch - 565us/sample\n",
            "Epoch 69/100\n",
            "7/7 - 0s - loss: 0.1183 - acc: 1.0000 - 4ms/epoch - 599us/sample\n",
            "Epoch 70/100\n",
            "7/7 - 0s - loss: 0.1165 - acc: 1.0000 - 4ms/epoch - 547us/sample\n",
            "Epoch 71/100\n",
            "7/7 - 0s - loss: 0.1147 - acc: 1.0000 - 4ms/epoch - 579us/sample\n",
            "Epoch 72/100\n",
            "7/7 - 0s - loss: 0.1129 - acc: 1.0000 - 5ms/epoch - 690us/sample\n",
            "Epoch 73/100\n",
            "7/7 - 0s - loss: 0.1112 - acc: 1.0000 - 5ms/epoch - 671us/sample\n",
            "Epoch 74/100\n",
            "7/7 - 0s - loss: 0.1095 - acc: 1.0000 - 5ms/epoch - 721us/sample\n",
            "Epoch 75/100\n",
            "7/7 - 0s - loss: 0.1078 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 76/100\n",
            "7/7 - 0s - loss: 0.1062 - acc: 1.0000 - 7ms/epoch - 1ms/sample\n",
            "Epoch 77/100\n",
            "7/7 - 0s - loss: 0.1047 - acc: 1.0000 - 11ms/epoch - 2ms/sample\n",
            "Epoch 78/100\n",
            "7/7 - 0s - loss: 0.1031 - acc: 1.0000 - 5ms/epoch - 683us/sample\n",
            "Epoch 79/100\n",
            "7/7 - 0s - loss: 0.1016 - acc: 1.0000 - 4ms/epoch - 533us/sample\n",
            "Epoch 80/100\n",
            "7/7 - 0s - loss: 0.1002 - acc: 1.0000 - 4ms/epoch - 642us/sample\n",
            "Epoch 81/100\n",
            "7/7 - 0s - loss: 0.0988 - acc: 1.0000 - 4ms/epoch - 613us/sample\n",
            "Epoch 82/100\n",
            "7/7 - 0s - loss: 0.0974 - acc: 1.0000 - 5ms/epoch - 673us/sample\n",
            "Epoch 83/100\n",
            "7/7 - 0s - loss: 0.0960 - acc: 1.0000 - 5ms/epoch - 666us/sample\n",
            "Epoch 84/100\n",
            "7/7 - 0s - loss: 0.0947 - acc: 1.0000 - 5ms/epoch - 679us/sample\n",
            "Epoch 85/100\n",
            "7/7 - 0s - loss: 0.0934 - acc: 1.0000 - 3ms/epoch - 499us/sample\n",
            "Epoch 86/100\n",
            "7/7 - 0s - loss: 0.0921 - acc: 1.0000 - 5ms/epoch - 675us/sample\n",
            "Epoch 87/100\n",
            "7/7 - 0s - loss: 0.0908 - acc: 1.0000 - 4ms/epoch - 613us/sample\n",
            "Epoch 88/100\n",
            "7/7 - 0s - loss: 0.0896 - acc: 1.0000 - 4ms/epoch - 563us/sample\n",
            "Epoch 89/100\n",
            "7/7 - 0s - loss: 0.0884 - acc: 1.0000 - 4ms/epoch - 526us/sample\n",
            "Epoch 90/100\n",
            "7/7 - 0s - loss: 0.0873 - acc: 1.0000 - 4ms/epoch - 549us/sample\n",
            "Epoch 91/100\n",
            "7/7 - 0s - loss: 0.0861 - acc: 1.0000 - 4ms/epoch - 594us/sample\n",
            "Epoch 92/100\n",
            "7/7 - 0s - loss: 0.0850 - acc: 1.0000 - 4ms/epoch - 574us/sample\n",
            "Epoch 93/100\n",
            "7/7 - 0s - loss: 0.0839 - acc: 1.0000 - 5ms/epoch - 645us/sample\n",
            "Epoch 94/100\n",
            "7/7 - 0s - loss: 0.0828 - acc: 1.0000 - 4ms/epoch - 536us/sample\n",
            "Epoch 95/100\n",
            "7/7 - 0s - loss: 0.0818 - acc: 1.0000 - 4ms/epoch - 576us/sample\n",
            "Epoch 96/100\n",
            "7/7 - 0s - loss: 0.0808 - acc: 1.0000 - 4ms/epoch - 593us/sample\n",
            "Epoch 97/100\n",
            "7/7 - 0s - loss: 0.0797 - acc: 1.0000 - 4ms/epoch - 582us/sample\n",
            "Epoch 98/100\n",
            "7/7 - 0s - loss: 0.0788 - acc: 1.0000 - 4ms/epoch - 559us/sample\n",
            "Epoch 99/100\n",
            "7/7 - 0s - loss: 0.0778 - acc: 1.0000 - 4ms/epoch - 546us/sample\n",
            "Epoch 100/100\n",
            "7/7 - 0s - loss: 0.0768 - acc: 1.0000 - 4ms/epoch - 607us/sample\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7338905150>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_wcrE5PtLMI"
      },
      "source": [
        "üîπ **1-(3)** fine tuning glove\n",
        "* ÎØ∏ÏÑ∏Ï°∞Ï†ï : ÏÇ¨Ï†Ñ ÌïôÏäµÌïú Î™®Îì† Í∞ÄÏ§ëÏπòÏôÄ ÎçîÎ∂àÏñ¥ ÌïòÏúÑ Î¨∏Ï†úÎ•º ÏúÑÌïú ÏµúÏÜåÌïúÏùò Í∞ÄÏ§ëÏπòÎ•º Ï∂îÍ∞ÄÌï¥ Î™®Îç∏ÏùÑ Ï∂îÍ∞ÄÎ°ú ÌïôÏäµÌïòÎäî Î∞©Î≤ïÏù¥Îã§. \n",
        "\n",
        "* fine tuning Ïù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞ \n",
        "  * pretrained model Ïóê Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÏûàÎäî Îã®Ïñ¥Í∞Ä Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ \n",
        "  * Îç∞Ïù¥ÌÑ∞ ÏßëÌï©Ïù¥ ÎÑàÎ¨¥ ÏûëÏïÑÏÑú Ï†ÑÏ≤¥ Î™®Îç∏ÏùÑ ÌõàÎ†®ÏãúÌÇ§Í∏∞ Ïñ¥Î†§Ïö¥ Í≤ΩÏö∞ \n",
        "\n",
        "* [Mittens ÎùºÏù¥Î∏åÎü¨Î¶¨Î°ú fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) üëâ ÌïÑÏàò\n",
        "  *  GloVe ÏûÑÎ≤†Îî©ÏùÑ fine-tuning ÌïòÍ∏∞ ÏúÑÌïú ÌååÏù¥Ïç¨ ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
        "  * [github](https://github.com/roamanalytics/mittens)\n",
        "\n",
        "* [ÌïúÍµ≠Ïñ¥ ÏÜåÏÑ§ ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÎØ∏ÏÑ∏Ï°∞Ï†ï Î™®Îç∏ ÌïôÏäµ - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) üëâ ÏÑ†ÌÉù (glove Î™®Îç∏ ÏòàÏ†úÎäî ÏïÑÎãôÎãàÎã§. fine-tuning Ïóê Ï¥àÏ†êÏùÑ ÎëêÏñ¥ÏÑú Ï∞∏Í≥†Ìï¥Ï£ºÏãúÎ©¥ Ï¢ãÏùÑ Í≤É Í∞ôÏäµÎãàÎã§.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U mittens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQy8h1PpAbUN",
        "outputId": "b1b211ad-e0b6-4ccc-f387-20ea28e302cb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mittens in /usr/local/lib/python3.7/dist-packages (0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mittens) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "from mittens import GloVe, Mittens\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pickle\n",
        "\n",
        "\n",
        "def glove2dict(glove_filename):\n",
        "    with open(glove_filename, encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
        "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
        "                for line in reader}\n",
        "    return embed\n",
        "\n",
        "glove_path = \"glove.6B.50d.txt\" # get it from https://nlp.stanford.edu/projects/glove\n",
        "pre_glove = glove2dict(glove_path)\n",
        "\n",
        "sw = list(_stop_words.ENGLISH_STOP_WORDS)\n",
        "brown_data = brown.words()[:200000]\n",
        "brown_nonstop = [token.lower() for token in brown_data if (token.lower() not in sw)]\n",
        "oov = [token for token in brown_nonstop if token not in pre_glove.keys()]\n",
        "\n",
        "def get_rareoov(xdict, val):\n",
        "    return [k for (k,v) in Counter(xdict).items() if v<=val]\n",
        "\n",
        "#oov_rare = get_rareoov(oov, 1)\n",
        "#corp_vocab = list(set(oov) - set(oov_rare))\n",
        "#brown_tokens = [token for token in brown_nonstop if token not in oov_rare]\n",
        "#brown_doc = [' '.join(brown_tokens)]\n",
        "\n",
        "corp_vocab = list(set(oov))\n",
        "brown_doc = [' '.join(brown_nonstop)]\n",
        "\n",
        "cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n",
        "X = cv.fit_transform(brown_doc)\n",
        "Xc = (X.T * X)\n",
        "Xc.setdiag(0)\n",
        "coocc_ar = Xc.toarray()\n",
        "\n",
        "mittens_model = Mittens(n=50, max_iter=1000)\n",
        "\n",
        "new_embeddings = mittens_model.fit(\n",
        "    coocc_ar,\n",
        "    vocab=corp_vocab,\n",
        "    initial_embedding_dict= pre_glove)\n",
        "\n",
        "newglove = dict(zip(corp_vocab, new_embeddings))\n",
        "f = open(\"repo_glove.pkl\",\"wb\")\n",
        "pickle.dump(newglove, f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "d0NLK-aXAVXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zz90bW_-MmIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-OB9Siga3G"
      },
      "source": [
        "* (Ï∞∏Í≥†) word2vec pretrained example\n",
        "\n",
        "‚ûï [word2vec ÏÇ¨Ï†ÑÌïôÏäµ Î™®Îç∏ -ÌïúÍµ≠Ïñ¥1](http://doc.mindscale.kr/km/unstructured/11.html)\n",
        "\n",
        "‚ûï [word2vec ÏÇ¨Ï†ÑÌïôÏäµ - ÌïúÍµ≠Ïñ¥2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUWWDwdiPLS9"
      },
      "source": [
        "### **2Ô∏è‚É£ NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N0B4VknPkTk"
      },
      "source": [
        "üëÄ **ÎÇ¥Ïö© Î≥µÏäµ** \n",
        "* Í∞úÏ≤¥Î™Ö Ïù∏ÏãùÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ ÏΩîÌçºÏä§Î°úÎ∂ÄÌÑ∞ Ïñ¥Îñ§ Îã®Ïñ¥Í∞Ä ÏÇ¨Îûå, Ïû•ÏÜå, Ï°∞ÏßÅ Îì±ÏùÑ ÏùòÎØ∏ÌïòÎäî Îã®Ïñ¥Ïù∏ÏßÄÎ•º Ï∞æÏùÑ Ïàò ÏûàÎã§. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgla1BuPRqJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "üîπ **2-(1)** NER task by nltk library\n",
        "\n",
        "\n",
        "* nltk ÏóêÏÑúÎäî Í∞úÏ≤¥Î™Ö Ïù∏ÏãùÍ∏∞ (NER chunker) Î•º ÏßÄÏõêÌïòÍ≥† ÏûàÎã§. \n",
        "* ne_chunk Îäî Í∞úÏ≤¥Î™ÖÏùÑ ÌÉúÍπÖÌïòÍ∏∞ ÏúÑÌï¥ÏÑú ÏïûÏÑú ÌíàÏÇ¨ ÌÉúÍπÖ pos_tag Í∞Ä ÏàòÌñâÎêòÏñ¥Ïïº ÌïúÎã§. \n",
        "\n",
        "\n",
        "üìå [basic code](https://wikidocs.net/30682) üëâ ÌïÑÏàò \n",
        "\n",
        "üìå [BIO ÌëúÌòÑ, LSTMÏùÑ ÌôúÏö©Ìïú NER Ïã§Ïäµ](https://wikidocs.net/24682) üëâ ÏÑ†ÌÉù\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "diaZweMyAxJz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k09tKha3Lgi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX-WtSvPmm6"
      },
      "source": [
        "üîπ **2-(2)** NER task by spacy library\n",
        "\n",
        "\n",
        "* spaCy Îäî ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨Î•º ÏúÑÌïú ÌååÏù¥Ïç¨ Í∏∞Î∞òÏùò Ïò§Ìîà ÏÜåÏä§ ÎùºÏù¥Î∏åÎü¨Î¶¨Î°ú Îã§ÏùåÍ≥º Í∞ôÏùÄ Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌïúÎã§. \n",
        "  * Tokenization \n",
        "  * POS tagging \n",
        "  * Lemmatization \n",
        "  * Sentence Boundary Detection (SBD)\n",
        "  * Named Entity Recognition (NER)\n",
        "  * Similarity\n",
        "  * Text Classification\n",
        "  * Rule-based Matching\n",
        "  * Training\n",
        "  * Serialization\n",
        "\n",
        "* spaCy ÏôÄ NER\n",
        "  * .ents ‚Üí .label_\n",
        "\n",
        "\n",
        "üìå [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) üëâ ÌïÑÏàò (NER Î∂ÄÎ∂ÑÎßå)\n",
        "\n",
        "üìå [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) üëâ ÏÑ†ÌÉù\n",
        "\n",
        "  * ÌõàÎ†®ÎêòÏßÄ ÏïäÏùÄ Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏Ïóê Î™ÖÎ™ÖÎêú ÏóîÌã∞Ìã∞Î•º ÌïôÏäµÌïòÎäî Î∞©Î≤ï : Ïù¥Î†•ÏÑú pdf Îç∞Ïù¥ÌÑ∞ ÌôúÏö© \n",
        "  * manually labelled \n",
        "\n",
        "üìå [ÌïúÍµ≠Ïñ¥ NER](https://github.com/monologg/KoBERT-NER) üëâ Ï∞∏Í≥†ÌïòÎ©¥ Ï¢ãÏùÑ ÏûêÎ£å\n",
        "\n",
        "‚ûï [Ï∞∏Í≥†](http://aispiration.com/nlp2/nlp-ner-python.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXjRfz-qP0Xx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008-V5QsQG25"
      },
      "source": [
        "###**3Ô∏è‚É£ Dependency Parsing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfcodHQQPlt"
      },
      "source": [
        "üëÄ **ÎÇ¥Ïö© Î≥µÏäµ** \n",
        "* Î¨∏Ïû•Ïùò Ï†ÑÏ≤¥Ï†ÅÏù∏ Íµ¨ÏÑ±/Íµ¨Ï°∞ Î≥¥Îã§Îäî Í∞Å Í∞úÎ≥ÑÎã®Ïñ¥ Í∞ÑÏùò 'ÏùòÏ°¥Í¥ÄÍ≥Ñ' ÎòêÎäî 'ÏàòÏãùÍ¥ÄÍ≥Ñ' ÏôÄ Í∞ôÏùÄ Îã®Ïñ¥Í∞Ñ Í¥ÄÍ≥ÑÎ•º ÌååÏïÖÌïòÎäî Í≤ÉÏù¥ Î™©Ï†ÅÏù∏ NLP Task\n",
        "* Î¨∏Ïû• Ìï¥ÏÑùÏùò Î™®Ìò∏ÏÑ±ÏùÑ ÏóÜÏï†Í∏∞ ÏúÑÌï¥ Parsing ÏùÑ ÌïúÎã§."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJLAzZnbRNlL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "üîπ **3-(1)** Dependency Parsing by spacy library\n",
        "\n",
        "\n",
        "* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) üëâ dependecy parsing Î∂ÄÎ∂ÑÎßå ÌïÑÏàò\n",
        "* .dep_ Î©îÏÑúÎìú\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbQEYt76bJXz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9QAEsrLAxHP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQD5oiGgRfHe"
      },
      "source": [
        "üîπ **3-(2)** Spacy (kaggle) \n",
        "\n",
        "* Ï∫êÍ∏Ä ÎÖ∏Ìä∏Î∂Å ÌôòÍ≤ΩÏóêÏÑú Ïã§ÏäµÌï¥Î≥¥Îäî Í≤ÉÏùÑ Í∂åÏû•ÎìúÎ¶ΩÎãàÎã§!\n",
        "\n",
        "* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) üëâ ÌïÑÏàò\n",
        "  * ÎèÑÎÇ†Îìú Ìä∏ÎüºÌîÑ Ìä∏ÏúÑÌÑ∞ Ìä∏Ïúó ÎÇ¥Ïö© Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù\n",
        "\n",
        "\n",
        "üëÄ **ÎÖ∏Ìä∏Î∂Å ÌÇ§Ìè¨Ïù∏Ìä∏** \n",
        "  1. spacy.display Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©Ìïú NER ÏãúÍ∞ÅÌôî \n",
        "  2. Tagging ÏùÑ ÌÜµÌïú Ìä∏ÎüºÌîÑ Ìä∏Ïúó Î∂ÑÏÑù : noun_chunks Îäî dependency graphÎ•º Í≥†Î†§ÌïòÏó¨, noun phraseÎ•º ÎΩëÏïÑÏ§ÄÎã§. \n",
        "  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : ÏßÅÏ†ë Î¨∏Ïû•/Îã®Ïñ¥ Ìå®ÌÑ¥ÏùÑ Îì±Î°ùÌïòÏó¨ parsing\n",
        "  4. Question and answering task using Dependency Parsing\n",
        "    * spacy display :  ``style = 'dep'``\n",
        "    * .dep_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuHGKITRbKYq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uMArOUrxAJ8K"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xUWWDwdiPLS9",
        "008-V5QsQG25"
      ],
      "name": "week5_nlp_hw.ipynbÏùò ÏÇ¨Î≥∏",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}