{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "금융문자 분석 Baseline code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_3vKIQmVmW3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # 데이터 전처리\n",
        "import numpy as np # 데이터 전처리\n",
        "import random #데이터 전처리\n",
        "from pandas import DataFrame #데이터 전처리\n",
        "from collections import Counter #데이터 전처리\n",
        "\n",
        "from tqdm import tqdm #시간 측정용\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer # model setting\n",
        "from sklearn.model_selection import train_test_split  # model setting\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB  # model 관련\n",
        "from sklearn.metrics import roc_auc_score  # model 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\") #해당 14th data의 csv 파일 중 train.csv 불러오기\n",
        "\n",
        "train.head(2)"
      ],
      "metadata": {
        "id": "rysStGcxaAOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"public_test.csv\")\n",
        "\n",
        "test.head(2)"
      ],
      "metadata": {
        "id": "fKoUO-iXaAMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission=pd.read_csv(\"submission_제출양식.csv\")\n",
        "\n",
        "submission.head(2)"
      ],
      "metadata": {
        "id": "DvFcikMgaAJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape, submission.shape"
      ],
      "metadata": {
        "id": "M_YABKgEaAHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(train['smishing'])"
      ],
      "metadata": {
        "id": "_yBX2dO0aAEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "19646/train.shape[0]"
      ],
      "metadata": {
        "id": "gRwBPgcLaAB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "850/12600"
      ],
      "metadata": {
        "id": "V_CSzf0yZ__e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(2019) #반복 수행시에도 동일한 결과 나올 수 있도록 시드 번호 지정\n",
        "train_nsm_list=list(train[train['smishing']!=1].index)\n",
        "train_nsmishing=random.sample(train_nsm_list, 11750 )\n",
        "\n",
        "random.seed(2019)\n",
        "train_sm_list=list(train[train['smishing']==1].index)\n",
        "train_smishing=random.sample(train_sm_list, 850 ) #0.066과 제일 비슷하게 나올 수 있도록  train data under sampling"
      ],
      "metadata": {
        "id": "OF8kXqkaZ_9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_xx=train.iloc[train_smishing+train_nsmishing,:].reset_index(drop=True) #under sampling으로 나온 index들로 train data 선별\n",
        "\n",
        "train_yy=DataFrame(train['smishing'],columns=['smishing']) \n",
        "train_yyy=train_yy.iloc[train_smishing+train_nsmishing,:].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bEyYbNuqZ_6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['smishing']=2 #train data와 동일한 형태 생성을 위해 임의의 숫자를 추가 #이후 스미싱 여부 확률 값으로 덮어 씌워짐\n",
        "test_xx=DataFrame(test['text'])\n",
        "test_yyy=DataFrame(test['smishing'])"
      ],
      "metadata": {
        "id": "xXPlERTfZ_4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_xx.shape,train_yyy.shape,test_xx.shape,test_yyy.shape"
      ],
      "metadata": {
        "id": "BzftrSvhZ_1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "tokenizer = Mecab() # setting tokenizer using Mecab()"
      ],
      "metadata": {
        "id": "ATu2aYn_Z_yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = [ ( tokenizer.pos(x), y ) for x, y in tqdm( zip( train_xx['text'], train_yyy['smishing'] ) )  ] # Mecab를 활용하여 text를 토큰화 시킴\n",
        "test_doc = [ ( tokenizer.pos(x), y ) for x, y in tqdm( zip( test_xx['text'], test_yyy['smishing'] ) )  ]"
      ],
      "metadata": {
        "id": "kA9AGWWJZ_vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['XXX', '.', '을', '를', '이', '가', '-', '(', ')', ':', '!', '?', ')-', '.-', 'ㅡ', 'XXXXXX', '..', '.(', '은', '는'] #필요없는 단어 리스트\n",
        "\n",
        "def get_couple(_words): #필요없는 단어들 없애는 함수\n",
        "    global stopwords\n",
        "    _words = [x for x in _words if x[0] not in stopwords]\n",
        "    l = len(_words)\n",
        "    for i in range(l-1):\n",
        "        yield _words[i][0], _words[i+1][0]"
      ],
      "metadata": {
        "id": "1b6TFvZuZ_oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = [], []\n",
        "for lwords in train_doc:\n",
        "    Y_train.append(lwords[1])\n",
        "    \n",
        "    temp = []\n",
        "    for x, y in get_couple(lwords[0]):\n",
        "        temp.append(\"{}.{}\".format(x, y))\n",
        "    \n",
        "    X_train.append(\" \".join(temp))"
      ],
      "metadata": {
        "id": "2ekQxhZtaR2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "for lwords in test_doc:\n",
        "    \n",
        "    temp = []\n",
        "    for x, y in get_couple(lwords[0]):\n",
        "        temp.append(\"{}.{}\".format(x, y))\n",
        "    \n",
        "    X_test.append(\" \".join(temp))"
      ],
      "metadata": {
        "id": "ie5wjhnAaR0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v=CountVectorizer()\n",
        "\n",
        "v.fit(X_train)\n",
        "\n",
        "vec_x_train= v.transform(X_train).toarray()\n",
        "vec_x_test= v.transform(X_test).toarray()"
      ],
      "metadata": {
        "id": "H2UUAYihaRxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1= MultinomialNB()\n",
        "m1.fit(vec_x_train,Y_train)\n",
        "\n",
        "y_train_pred1=m1.predict_proba(vec_x_train)\n",
        "y_train_pred1_one= [ i[1]  for i in y_train_pred1]\n",
        "\n",
        "y_test_pred1=m1.predict_proba(vec_x_test)\n",
        "y_test_pred1_one= [ i[1]  for i in y_test_pred1]"
      ],
      "metadata": {
        "id": "McwE9URgaRvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['smishing'] = y_test_pred1_one\n",
        "\n",
        "submission.to_csv(\"14th_baseline_multi.csv\",index=False) "
      ],
      "metadata": {
        "id": "YHBtU7zOaRqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L8aJ70tpaRnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GwG-5CWuaRlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jS2hishNaRia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XVy_emyWaRfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}