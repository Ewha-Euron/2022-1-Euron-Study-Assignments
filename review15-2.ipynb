{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b3bc2c",
   "metadata": {},
   "source": [
    "### covid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27bee0",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/maksimeren/covid-19-literature-clustering/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...용량 부족으로 data다운 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b68ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d444558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pby02\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (1,5,13,14,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>d1aafb70c066a2068b02786f8929fd9c900897fb</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>PMC35282</td>\n",
       "      <td>11472636</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "      <td>document_parses/pmc_json/PMC35282.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>6b0567729c2143a66d737eb0a2f63f2dce2e5a7d</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>PMC59543</td>\n",
       "      <td>11667967</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/6b0567729c2143a66d737...</td>\n",
       "      <td>document_parses/pmc_json/PMC59543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>06ced00a5fc04215949aa72528f2eeaae1d58927</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>10.1186/rr19</td>\n",
       "      <td>PMC59549</td>\n",
       "      <td>11667972</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>Crouch, Erika C</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/06ced00a5fc04215949aa...</td>\n",
       "      <td>document_parses/pmc_json/PMC59549.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b73a28n</td>\n",
       "      <td>348055649b6b8cf2b9a376498df9bf41f7123605</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>10.1186/rr44</td>\n",
       "      <td>PMC59574</td>\n",
       "      <td>11686871</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
       "      <td>2001-02-22</td>\n",
       "      <td>Fagan, Karen A; McMurtry, Ivan F; Rodman, David M</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/348055649b6b8cf2b9a37...</td>\n",
       "      <td>document_parses/pmc_json/PMC59574.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785vg6d</td>\n",
       "      <td>5f48792a5fa08bed9f56016f4981ae2ca6031b32</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>10.1186/rr61</td>\n",
       "      <td>PMC59580</td>\n",
       "      <td>11686888</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>Domachowske, Joseph B; Bonville, Cynthia A; Ro...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/5f48792a5fa08bed9f560...</td>\n",
       "      <td>document_parses/pmc_json/PMC59580.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
       "1  02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
       "2  ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
       "3  2b73a28n  348055649b6b8cf2b9a376498df9bf41f7123605      PMC   \n",
       "4  9785vg6d  5f48792a5fa08bed9f56016f4981ae2ca6031b32      PMC   \n",
       "\n",
       "                                               title                    doi  \\\n",
       "0  Clinical features of culture-proven Mycoplasma...  10.1186/1471-2334-1-6   \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...           10.1186/rr14   \n",
       "2    Surfactant protein-D and pulmonary host defense           10.1186/rr19   \n",
       "3               Role of endothelin-1 in lung disease           10.1186/rr44   \n",
       "4  Gene expression in epithelial cells in respons...           10.1186/rr61   \n",
       "\n",
       "      pmcid pubmed_id license  \\\n",
       "0  PMC35282  11472636   no-cc   \n",
       "1  PMC59543  11667967   no-cc   \n",
       "2  PMC59549  11667972   no-cc   \n",
       "3  PMC59574  11686871   no-cc   \n",
       "4  PMC59580  11686888   no-cc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   2001-07-04   \n",
       "1  Inflammatory diseases of the respiratory tract...   2000-08-15   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   2000-08-25   \n",
       "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   2001-02-22   \n",
       "4  Respiratory syncytial virus (RSV) and pneumoni...   2001-05-11   \n",
       "\n",
       "                                             authors         journal  mag_id  \\\n",
       "0                Madani, Tariq A; Al-Ghamdi, Aisha A  BMC Infect Dis     NaN   \n",
       "1  Vliet, Albert van der; Eiserich, Jason P; Cros...      Respir Res     NaN   \n",
       "2                                    Crouch, Erika C      Respir Res     NaN   \n",
       "3  Fagan, Karen A; McMurtry, Ivan F; Rodman, David M      Respir Res     NaN   \n",
       "4  Domachowske, Joseph B; Bonville, Cynthia A; Ro...      Respir Res     NaN   \n",
       "\n",
       "  who_covidence_id arxiv_id  \\\n",
       "0              NaN      NaN   \n",
       "1              NaN      NaN   \n",
       "2              NaN      NaN   \n",
       "3              NaN      NaN   \n",
       "4              NaN      NaN   \n",
       "\n",
       "                                      pdf_json_files  \\\n",
       "0  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
       "1  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
       "2  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
       "3  document_parses/pdf_json/348055649b6b8cf2b9a37...   \n",
       "4  document_parses/pdf_json/5f48792a5fa08bed9f560...   \n",
       "\n",
       "                               pmc_json_files  \\\n",
       "0  document_parses/pmc_json/PMC35282.xml.json   \n",
       "1  document_parses/pmc_json/PMC59543.xml.json   \n",
       "2  document_parses/pmc_json/PMC59549.xml.json   \n",
       "3  document_parses/pmc_json/PMC59574.xml.json   \n",
       "4  document_parses/pmc_json/PMC59580.xml.json   \n",
       "\n",
       "                                                 url  s2_id  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...    NaN  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#root_path = '/kaggle/input/CORD-19-research-challenge/'\n",
    "#metadata_path = f'{root_path}/metadata.csv'\n",
    "meta_df = pd.read_csv('metadata.csv', dtype={\n",
    "    'pubmed_id': str,\n",
    "    'Microsoft Academic Paper ID': str, \n",
    "    'doi': str\n",
    "})\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c886683",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c20f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json = ! ls $root_path/document_parses/pdf_json\n",
    "len(all_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38540b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ee507",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json = [root_path + \"document_parses/pdf_json/\" + s for s in all_json]\n",
    "all_json[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileReader:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path) as file:\n",
    "            content = json.load(file)\n",
    "            self.paper_id = content['paper_id']\n",
    "            self.abstract = []\n",
    "            self.body_text = []\n",
    "            # Abstract\n",
    "            for entry in content['abstract']:\n",
    "                self.abstract.append(entry['text'])\n",
    "            # Body text\n",
    "            for entry in content['body_text']:\n",
    "                self.body_text.append(entry['text'])\n",
    "            self.abstract = '\\n'.join(self.abstract)\n",
    "            self.body_text = '\\n'.join(self.body_text)\n",
    "    def __repr__(self):\n",
    "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\n",
    "first_row = FileReader(all_json[0])\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "all_json_clean = list()\n",
    "for idx, entry in tqdm(enumerate(all_json), total=len(all_json)):\n",
    "    \n",
    "    try:\n",
    "        content = FileReader(entry)\n",
    "    except Exception as e:\n",
    "        continue  # invalid paper format, skip\n",
    "    \n",
    "    if len(content.body_text) == 0:\n",
    "        continue\n",
    "    \n",
    "    all_json_clean.append(all_json[idx])\n",
    "    \n",
    "all_json = all_json_clean\n",
    "len(all_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebecd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "all_json = random.sample(all_json, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155886a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breaks(content, length):\n",
    "    data = \"\"\n",
    "    words = content.split(' ')\n",
    "    total_chars = 0\n",
    "​\n",
    "    # add break every length characters\n",
    "    for i in range(len(words)):\n",
    "        total_chars += len(words[i])\n",
    "        if total_chars > length:\n",
    "            data = data + \"<br>\" + words[i]\n",
    "            total_chars = 0\n",
    "        else:\n",
    "            data = data + \" \" + words[i]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cceb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "dict_ = {'paper_id': [], 'doi':[], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\n",
    "for idx, entry in tqdm(enumerate(all_json), total = len(all_json)):\n",
    "    \n",
    "    try:\n",
    "        content = FileReader(entry)\n",
    "    except Exception as e:\n",
    "        continue  # invalid paper format, skip\n",
    "    \n",
    "    # get metadata information\n",
    "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
    "    # no metadata, skip this paper\n",
    "    if len(meta_data) == 0:\n",
    "        continue\n",
    "    if len(content.body_text) == 0:\n",
    "        continue\n",
    "    dict_['abstract'].append(content.abstract)\n",
    "    dict_['paper_id'].append(content.paper_id)\n",
    "    dict_['body_text'].append(content.body_text)\n",
    "    \n",
    "    # also create a column for the summary of abstract to be used in a plot\n",
    "    if len(content.abstract) == 0: \n",
    "        # no abstract provided\n",
    "        dict_['abstract_summary'].append(\"Not provided.\")\n",
    "    elif len(content.abstract.split(' ')) > 100:\n",
    "        # abstract provided is too long for plot, take first 300 words append with ...\n",
    "        info = content.abstract.split(' ')[:100]\n",
    "        summary = get_breaks(' '.join(info), 40)\n",
    "        dict_['abstract_summary'].append(summary + \"...\")\n",
    "    else:\n",
    "        # abstract is short enough\n",
    "        summary = get_breaks(content.abstract, 40)\n",
    "        dict_['abstract_summary'].append(summary)\n",
    "        \n",
    "    # get metadata information\n",
    "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
    "    \n",
    "    try:\n",
    "        # if more than one author\n",
    "        authors = meta_data['authors'].values[0].split(';')\n",
    "        if len(authors) > 2:\n",
    "            # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n",
    "            dict_['authors'].append(get_breaks('. '.join(authors), 40))\n",
    "        else:\n",
    "            # authors will fit in plot\n",
    "            dict_['authors'].append(\". \".join(authors))\n",
    "    except Exception as e:\n",
    "        # if only one author - or Null valie\n",
    "        dict_['authors'].append(meta_data['authors'].values[0])\n",
    "    \n",
    "    # add the title information, add breaks when needed\n",
    "    try:\n",
    "        title = get_breaks(meta_data['title'].values[0], 40)\n",
    "        dict_['title'].append(title)\n",
    "    # if title was not provided\n",
    "    except Exception as e:\n",
    "        dict_['title'].append(meta_data['title'].values[0])\n",
    "    \n",
    "    # add the journal information\n",
    "    dict_['journal'].append(meta_data['journal'].values[0])\n",
    "    \n",
    "    # add doi\n",
    "    dict_['doi'].append(meta_data['doi'].values[0])\n",
    "    \n",
    "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'doi', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065fd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7034c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c72dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_covid.sample(10000, random_state=42)\n",
    "del df_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df70332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5606be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "\n",
    "# set seed\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# hold label - language\n",
    "languages = []\n",
    "\n",
    "# go through each text\n",
    "for ii in tqdm(range(0,len(df))):\n",
    "    # split by space into list, take the first x intex, join with space\n",
    "    text = df.iloc[ii]['body_text'].split(\" \")\n",
    "    \n",
    "    lang = \"en\"\n",
    "    try:\n",
    "        if len(text) > 50:\n",
    "            lang = detect(\" \".join(text[:50]))\n",
    "        elif len(text) > 0:\n",
    "            lang = detect(\" \".join(text[:len(text)]))\n",
    "    # ught... beginning of the document was not in a good format\n",
    "    except Exception as e:\n",
    "        all_words = set(text)\n",
    "        try:\n",
    "            lang = detect(\" \".join(all_words))\n",
    "        # what!! :( let's see if we can find any text in abstract...\n",
    "        except Exception as e:\n",
    "            \n",
    "            try:\n",
    "                # let's try to label it through the abstract then\n",
    "                lang = detect(df.iloc[ii]['abstract_summary'])\n",
    "            except Exception as e:\n",
    "                lang = \"unknown\"\n",
    "                pass\n",
    "    \n",
    "    # get the language    \n",
    "    languages.append(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "languages_dict = {}\n",
    "for lang in set(languages):\n",
    "    languages_dict[lang] = languages.count(lang)\n",
    "    \n",
    "print(\"Total: {}\\n\".format(len(languages)))\n",
    "pprint(languages_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90550ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = languages\n",
    "plt.bar(range(len(languages_dict)), list(languages_dict.values()), align='center')\n",
    "plt.xticks(range(len(languages_dict)), list(languages_dict.keys()))\n",
    "plt.title(\"Distribution of Languages in Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language'] == 'en'] \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851452f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP \n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punctuations = string.punctuation\n",
    "stopwords = list(STOP_WORDS)\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\n",
    "    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n",
    "    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', \n",
    "    'al.', 'Elsevier', 'PMC', 'CZI'\n",
    "]\n",
    "\n",
    "for w in custom_stop_words:\n",
    "    if w not in stopwords:\n",
    "        stopwords.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66647604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser\n",
    "parser = en_core_sci_lg.load(disable=[\"tagger\", \"ner\"])\n",
    "parser.max_length = 7000000\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    mytokens = \" \".join([i for i in mytokens])\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d737a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df[\"processed_text\"] = df[\"body_text\"].progress_apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa02668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29724ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def vectorize(text, maxx_features):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=maxx_features)\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ccc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['processed_text'].values\n",
    "max_features = 2**12\n",
    "\n",
    "X = vectorize(text, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca&clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_reduced= pca.fit_transform(X.toarray())\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# run kmeans with many different k\n",
    "distortions = []\n",
    "K = range(2, 30)\n",
    "for k in K:\n",
    "    k_means = KMeans(n_clusters=k, random_state=42).fit(X_reduced)\n",
    "    k_means.fit(X_reduced)\n",
    "    distortions.append(sum(np.min(cdist(X_reduced, k_means.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "    #print('Found distortion for {} clusters'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_line = [K[0], K[-1]]\n",
    "Y_line = [distortions[0], distortions[-1]]\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'b-')\n",
    "plt.plot(X_line, Y_line, 'r')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans\n",
    "k = 20\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X_reduced)\n",
    "df['y'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ea7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(verbose=1, perplexity=50)  # Changed perplexity from 100 to 50 per FAQ\n",
    "X_embedded = tsne.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b03e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", 1)\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], palette=palette)\n",
    "plt.title('t-SNE with no Labels')\n",
    "plt.savefig(\"t-sne_covid19.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(13,9)})\n",
    "\n",
    "# colors\n",
    "palette = sns.hls_palette(20, l=.4, s=.9)\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\n",
    "plt.title('t-SNE with Kmeans Labels')\n",
    "plt.savefig(\"improved_cluster_tsne.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ff67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bceb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dabc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='https://miro.medium.com/max/1276/0*Sj65xR38wDwuxhtr.jpg', width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = []\n",
    "    \n",
    "for ii in range(0, 20):\n",
    "    # Creating a vectorizer\n",
    "    vectorizers.append(CountVectorizer(min_df=5, max_df=0.9, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = []\n",
    "\n",
    "for current_cluster, cvec in enumerate(vectorizers):\n",
    "    try:\n",
    "        vectorized_data.append(cvec.fit_transform(df.loc[df['y'] == current_cluster, 'processed_text']))\n",
    "    except Exception as e:\n",
    "        print(\"Not enough instances in cluster: \" + str(current_cluster))\n",
    "        vectorized_data.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e59bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of topics per cluster\n",
    "NUM_TOPICS_PER_CLUSTER = 20\n",
    "\n",
    "\n",
    "lda_models = []\n",
    "\n",
    "for ii in range(0, 20):\n",
    "    # Latent Dirichlet Allocation Model\n",
    "    lda = LatentDirichletAllocation(n_components=NUM_TOPICS_PER_CLUSTER, max_iter=10, learning_method='online',verbose=False, random_state=42)\n",
    "    lda_models.append(lda)\n",
    "    \n",
    "lda_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_lda_data = []\n",
    "\n",
    "for current_cluster, lda in enumerate(lda_models):\n",
    "    print(\"Current Cluster: \" + str(current_cluster))\n",
    "    \n",
    "    if vectorized_data[current_cluster] != None:\n",
    "        clusters_lda_data.append((lda.fit_transform(vectorized_data[current_cluster])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fba2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for printing keywords for each topic\n",
    "def selected_topics(model, vectorizer, top_n=3):\n",
    "    current_words = []\n",
    "    keywords = []\n",
    "    \n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        words = [(vectorizer.get_feature_names()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]]\n",
    "        for word in words:\n",
    "            if word[0] not in current_words:\n",
    "                keywords.append(word)\n",
    "                current_words.append(word[0])\n",
    "                \n",
    "    keywords.sort(key = lambda x: x[1])  \n",
    "    keywords.reverse()\n",
    "    return_values = []\n",
    "    for ii in keywords:\n",
    "        return_values.append(ii[0])\n",
    "    return return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = []\n",
    "for current_vectorizer, lda in enumerate(lda_models):\n",
    "    print(\"Current Cluster: \" + str(current_vectorizer))\n",
    "\n",
    "    if vectorized_data[current_vectorizer] != None:\n",
    "        all_keywords.append(selected_topics(lda, vectorizers[current_vectorizer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab328d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "f=open('topics.txt','w')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for ii in all_keywords:\n",
    "\n",
    "    if vectorized_data[count] != None:\n",
    "        f.write(', '.join(ii) + \"\\n\")\n",
    "    else:\n",
    "        f.write(\"Not enough instances to be determined. \\n\")\n",
    "        f.write(', '.join(ii) + \"\\n\")\n",
    "    count += 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f242d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the COVID-19 DataFrame\n",
    "pickle.dump(df, open(\"df_covid.p\", \"wb\" ))\n",
    "\n",
    "# save the final t-SNE\n",
    "pickle.dump(X_embedded, open(\"X_embedded.p\", \"wb\" ))\n",
    "\n",
    "# save the labels generate with k-means(20)\n",
    "pickle.dump(y_pred, open(\"y_pred.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf90542",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir lib\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c215257",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/MaksimEkin/COVID19-Literature-Clustering/master/lib/plot_text.py\n",
    "! wget https://raw.githubusercontent.com/MaksimEkin/COVID19-Literature-Clustering/master/lib/call_backs.py\n",
    "! mv plot_text.py lib/.\n",
    "! mv call_backs.py lib/.\n",
    "! ls lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c04dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries for plot\n",
    "from lib.plot_text import header, description, description2, cite, description_search, description_slider, notes, dataset_description, toolbox_header \n",
    "from lib.call_backs import input_callback, selected_code\n",
    "import bokeh\n",
    "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, CustomJS, Slider, TapTool, TextInput\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.transform import linear_cmap, transform\n",
    "from bokeh.io import output_file, show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import RadioButtonGroup, TextInput, Div, Paragraph\n",
    "from bokeh.layouts import column, widgetbox, row, layout\n",
    "from bokeh.layouts import column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83542ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "topic_path = os.path.join(os.getcwd(), 'topics.txt')\n",
    "with open(topic_path) as f:\n",
    "    topics = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adaa473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show on notebook\n",
    "output_notebook()\n",
    "# target labels\n",
    "y_labels = y_pred\n",
    "\n",
    "# data sources\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x= X_embedded[:,0], \n",
    "    y= X_embedded[:,1],\n",
    "    x_backup = X_embedded[:,0],\n",
    "    y_backup = X_embedded[:,1],\n",
    "    desc= y_labels, \n",
    "    titles= df['title'],\n",
    "    authors = df['authors'],\n",
    "    journal = df['journal'],\n",
    "    abstract = df['abstract_summary'],\n",
    "    labels = [\"C-\" + str(x) for x in y_labels],\n",
    "    links = df['doi']\n",
    "    ))\n",
    "\n",
    "# hover over information\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Title\", \"@titles{safe}\"),\n",
    "    (\"Author(s)\", \"@authors{safe}\"),\n",
    "    (\"Journal\", \"@journal\"),\n",
    "    (\"Abstract\", \"@abstract{safe}\"),\n",
    "    (\"Link\", \"@links\")\n",
    "],\n",
    "point_policy=\"follow_mouse\")\n",
    "\n",
    "# map colors\n",
    "mapper = linear_cmap(field_name='desc', \n",
    "                     palette=Category20[20],\n",
    "                     low=min(y_labels) ,high=max(y_labels))\n",
    "\n",
    "# prepare the figure\n",
    "plot = figure(plot_width=1200, plot_height=850, \n",
    "           tools=[hover, 'pan', 'wheel_zoom', 'box_zoom', 'reset', 'save', 'tap'], \n",
    "           title=\"Clustering of the COVID-19 Literature with t-SNE and K-Means\", \n",
    "           toolbar_location=\"above\")\n",
    "\n",
    "# plot settings\n",
    "plot.scatter('x', 'y', size=5, \n",
    "          source=source,\n",
    "          fill_color=mapper,\n",
    "          line_alpha=0.3,\n",
    "          line_color=\"black\",\n",
    "          legend = 'labels')\n",
    "plot.legend.background_fill_alpha = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords\n",
    "text_banner = Paragraph(text= 'Keywords: Slide to specific cluster to see the keywords.', height=25)\n",
    "input_callback_1 = input_callback(plot, source, text_banner, topics)\n",
    "\n",
    "# currently selected article\n",
    "div_curr = Div(text=\"\"\"Click on a plot to see the link to the article.\"\"\",height=150)\n",
    "callback_selected = CustomJS(args=dict(source=source, current_selection=div_curr), code=selected_code())\n",
    "taptool = plot.select(type=TapTool)\n",
    "taptool.callback = callback_selected\n",
    "\n",
    "# WIDGETS\n",
    "slider = Slider(start=0, end=20, value=20, step=1, title=\"Cluster #\", callback=input_callback_1)\n",
    "keyword = TextInput(title=\"Search:\", callback=input_callback_1)\n",
    "\n",
    "# pass call back arguments\n",
    "input_callback_1.args[\"text\"] = keyword\n",
    "input_callback_1.args[\"slider\"] = slider\n",
    "# column(,,widgetbox(keyword),,widgetbox(slider),, notes, cite, cite2, cite3), plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STYLE\n",
    "header.sizing_mode = \"stretch_width\"\n",
    "header.style={'color': '#2e484c', 'font-family': 'Julius Sans One, sans-serif;'}\n",
    "header.margin=5\n",
    "\n",
    "description.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "description.sizing_mode = \"stretch_width\"\n",
    "description.margin = 5\n",
    "\n",
    "description2.sizing_mode = \"stretch_width\"\n",
    "description2.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "description2.margin=10\n",
    "\n",
    "description_slider.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "description_slider.sizing_mode = \"stretch_width\"\n",
    "\n",
    "description_search.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "description_search.sizing_mode = \"stretch_width\"\n",
    "description_search.margin = 5\n",
    "\n",
    "slider.sizing_mode = \"stretch_width\"\n",
    "slider.margin=15\n",
    "\n",
    "keyword.sizing_mode = \"scale_both\"\n",
    "keyword.margin=15\n",
    "\n",
    "div_curr.style={'color': '#BF0A30', 'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "div_curr.sizing_mode = \"scale_both\"\n",
    "div_curr.margin = 20\n",
    "\n",
    "text_banner.style={'color': '#0269A4', 'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "text_banner.sizing_mode = \"stretch_width\"\n",
    "text_banner.margin = 20\n",
    "\n",
    "plot.sizing_mode = \"scale_both\"\n",
    "plot.margin = 5\n",
    "\n",
    "dataset_description.sizing_mode = \"stretch_width\"\n",
    "dataset_description.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "dataset_description.margin=10\n",
    "\n",
    "notes.sizing_mode = \"stretch_width\"\n",
    "notes.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "notes.margin=10\n",
    "\n",
    "cite.sizing_mode = \"stretch_width\"\n",
    "cite.style ={'font-family': 'Helvetica Neue, Helvetica, Arial, sans-serif;', 'font-size': '1.1em'}\n",
    "cite.margin=10\n",
    "\n",
    "r = row(div_curr,text_banner)\n",
    "r.sizing_mode = \"stretch_width\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fb37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show\n",
    "# LAYOUT OF THE PAGE\n",
    "l = layout([\n",
    "    [header],\n",
    "    [description],\n",
    "    [description_slider, description_search],\n",
    "    [slider, keyword],\n",
    "    [text_banner],\n",
    "    [div_curr],\n",
    "    [plot],\n",
    "    [description2, dataset_description, notes, cite],\n",
    "])\n",
    "l.sizing_mode = \"scale_both\"\n",
    "\n",
    "\n",
    "# show\n",
    "output_file('t-sne_covid-19_interactive.html')\n",
    "show(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
