{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week10_nlp_hw.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-vPZn15zBHIv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowionlyseedaylight/2022-1-Euron-Study-Assignments/blob/Week_11/week10_nlp_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ week10 ê³¼ì œëŠ” **9ì£¼ì°¨ì˜ Machine Translation, Seq2Seq and Attention**ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Œ ìœ„í‚¤ë…ìŠ¤ì˜ ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ êµì¬ ì‹¤ìŠµ, \bí…ì„œí”Œë¡œìš° ë° ì¼€ë¼ìŠ¤ ë“±ì˜ ê³µì‹ ë¬¸ì„œ ìë£Œë¡œ êµ¬ì„±ë˜ì–´ìˆëŠ” ê³¼ì œì…ë‹ˆë‹¤. \n",
        "\n",
        "ğŸ“Œ ì•ˆë‚´ëœ ë§í¬ì— ë§ì¶”ì–´ **ì§ì ‘ ì½”ë“œë¥¼ ë”°ë¼ ì¹˜ë©´ì„œ (í•„ì‚¬)** í•´ë‹¹ nlp task ì˜ ê¸°ë³¸ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë©”ì„œë“œë¥¼ ìˆ™ì§€í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ğŸ˜Š í•„ìˆ˜ë¼ê³  ì²´í¬í•œ ë¶€ë¶„ì€ ê³¼ì œì— ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì£¼ì‹œê³ , ì„ íƒìœ¼ë¡œ ì²´í¬í•œ ë¶€ë¶„ì€ ììœ¨ì ìœ¼ë¡œ ìŠ¤í„°ë”” í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Œ ê¶ê¸ˆí•œ ì‚¬í•­ì€ ê¹ƒí—ˆë¸Œ ì´ìŠˆë‚˜, ì¹´í†¡ë°©, ì„¸ì…˜ ë°œí‘œ ì‹œì‘ ì´ì „ ì‹œê°„ ë“±ì„ í™œìš©í•˜ì—¬ ììœ ë¡­ê²Œ ê³µìœ í•´ì£¼ì„¸ìš”!"
      ],
      "metadata": {
        "id": "QhUHfXkPAORh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk colab í™˜ê²½ì—ì„œ ì‹¤í–‰ì‹œ í•„ìš”í•œ ì½”ë“œì…ë‹ˆë‹¤. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "3XjTSbcxBB6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633735f7-ab23-4fcd-d8e6-d9625b1f4e98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1ï¸âƒ£ **Seq2Seq**\n",
        "\n"
      ],
      "metadata": {
        "id": "-vPZn15zBHIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ Seq2Seq** \n",
        "\n",
        "* ì…ë ¥ëœ ì‹œí€€ìŠ¤ë¡œë¶€í„° ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•˜ëŠ” ë¶„ì•¼ \n",
        "  * ì±—ë´‡ : (ì§ˆë¬¸) - (ëŒ€ë‹µ) \n",
        "  * ê¸°ê³„ë²ˆì—­ : (ì…ë ¥ë¬¸ì¥) - (ë²ˆì—­ë¬¸ì¥) \n",
        "* ì´ ì™¸ì—ë„ Text summarization, Speech to Text ë“±ì— ì“°ì´ëŠ” ëª¨ë¸ "
      ],
      "metadata": {
        "id": "cfTJoGzkEBlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "ğŸ”¹ **seq2seq**\n",
        "\n",
        "* [ê°œë…ë³µìŠµ](https://wikidocs.net/24996) \n",
        "\n",
        "ğŸ“Œ [word-Level NMT](https://wikidocs.net/86900) ğŸ‘‰ í•„ìˆ˜ \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ğŸ“Œ [BLEU](https://wikidocs.net/31695) ğŸ‘‰ ì„ íƒ(ê¶Œì¥) \n",
        "  * def function ìœ¼ë¡œ êµ¬í˜„ í•˜ëŠ” ë°©ë²•, nltk íŒ¨í‚¤ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ë°©ë²• \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQLViVEQmKvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "G40TKGnRFs0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Vg32oNQhmOpm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "http = urllib3.PoolManager()\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "metadata": {
        "id": "mhh8iEyk9SGX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000"
      ],
      "metadata": {
        "id": "FGxBTM7aXHSb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "êµ¬ë‘ì  ë“±ì„ ì œê±°í•˜ê±°ë‚˜ ë‹¨ì–´ì™€ êµ¬ë¶„í•´ì£¼ê¸° ìœ„í•œ ì „ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "DbuxZE3y9qI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_ascii(s):\n",
        "  # í”„ë‘ìŠ¤ì–´ ì•…ì„¼íŠ¸(accent) ì‚­ì œ\n",
        "  # ì˜ˆì‹œ : 'dÃ©jÃ  dinÃ©' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  # ì•…ì„¼íŠ¸ ì œê±° í•¨ìˆ˜ í˜¸ì¶œ\n",
        "  sent = to_ascii(sent.lower())\n",
        "\n",
        "  # ë‹¨ì–´ì™€ êµ¬ë‘ì  ì‚¬ì´ì— ê³µë°± ì¶”ê°€.\n",
        "  # ex) \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,Â¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") ì´ë“¤ì„ ì œì™¸í•˜ê³ ëŠ” ì „ë¶€ ê³µë°±ìœ¼ë¡œ ë³€í™˜.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # ë‹¤ìˆ˜ ê°œì˜ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "iJksiYc-Y6zS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "êµ¬í˜„í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì„ì˜ì˜ ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë´…ì‹œë‹¤."
      ],
      "metadata": {
        "id": "jUHCFy2O9rF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous dÃ©jÃ  dinÃ©?\"\n",
        "\n",
        "print('ì „ì²˜ë¦¬ ì „ ì˜ì–´ ë¬¸ì¥ :', en_sent)\n",
        "print('ì „ì²˜ë¦¬ í›„ ì˜ì–´ ë¬¸ì¥ :',preprocess_sentence(en_sent))\n",
        "print('ì „ì²˜ë¦¬ ì „ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ :', fr_sent)\n",
        "print('ì „ì²˜ë¦¬ í›„ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvSK5JZk9mZR",
        "outputId": "c3c95df0-fcab-41e4-ea06-7834c5c4628e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì „ì²˜ë¦¬ ì „ ì˜ì–´ ë¬¸ì¥ : Have you had dinner?\n",
            "ì „ì²˜ë¦¬ í›„ ì˜ì–´ ë¬¸ì¥ : have you had dinner ?\n",
            "ì „ì²˜ë¦¬ ì „ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ : Avez-vous dÃ©jÃ  dinÃ©?\n",
            "ì „ì²˜ë¦¬ í›„ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì „ì²´ ë°ì´í„°ì—ì„œ 33,000ê°œì˜ ìƒ˜í”Œì— ëŒ€í•œ ì „ì²˜ë¦¬\n",
        "- Teacher Forcing ì‚¬ìš©\n",
        "- ì…ë ¥ ì‹œí€€ìŠ¤ì—ëŠ” ì‹œì‘ì„ ì˜ë¯¸í•˜ëŠ” í† í°ì¸ sosë¥¼ ì¶”ê°€í•˜ê³ , ì¶œë ¥ ì‹œí€€ìŠ¤ì—ëŠ” ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” í† í°ì¸ eosë¥¼ ì¶”ê°€\n"
      ],
      "metadata": {
        "id": "T6KV8pEMDyGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # source ë°ì´í„°ì™€ target ë°ì´í„° ë¶„ë¦¬\n",
        "      src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      # source ë°ì´í„° ì „ì²˜ë¦¬\n",
        "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # target ë°ì´í„° ì „ì²˜ë¦¬\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "SHj-Z0oo9tUk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìƒìœ„ 5ê°œ ìƒ˜í”Œë§Œ ì¶œë ¥í•´ë³´ì."
      ],
      "metadata": {
        "id": "DNECAQFPEFRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
        "print('ì¸ì½”ë”ì˜ ì…ë ¥ :',sents_en_in[:5])\n",
        "print('ë””ì½”ë”ì˜ ì…ë ¥ :',sents_fra_in[:5])\n",
        "print('ë””ì½”ë”ì˜ ë ˆì´ë¸” :',sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2jNkc8yEB4U",
        "outputId": "cb2eea77-fe29-42ac-947b-bdbb78ee4ff6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¸ì½”ë”ì˜ ì…ë ¥ : [['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n",
            "ë””ì½”ë”ì˜ ì…ë ¥ : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n",
            "ë””ì½”ë”ì˜ ë ˆì´ë¸” : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì´ì „ ì‹œì ì˜ ë””ì½”ë” ì…€ì˜ ì˜ˆì¸¡ê°’ ëŒ€ì‹  ì‹¤ì œê°’ì„ í˜„ì¬ ì‹œì ì˜ ë””ì½”ë” ì…€ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©\n",
        "\n",
        "- Teacher Forcing: RNNì˜ ëª¨ë“  ì‹œì ì— ëŒ€í•´ì„œ ì´ì „ ì‹œì ì˜ ì˜ˆì¸¡ê°’ ëŒ€ì‹  ì‹¤ì œê°’ì„ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ë²•\n",
        "\n"
      ],
      "metadata": {
        "id": "t3ELDUwvEUc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì¼€ë¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ í†µí•´ ë‹¨ì–´ ì§‘í•©ì„ ìƒì„±, ì •ìˆ˜ ì¸ì½”ë”©"
      ],
      "metadata": {
        "id": "YlVEZPuoEpqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "metadata": {
        "id": "UpZBi74CEI2H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë°ì´í„°ì˜ í¬ê¸°(shape)ë¥¼ í™•ì¸"
      ],
      "metadata": {
        "id": "pd8hsOCzEqqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('ì¸ì½”ë”ì˜ ì…ë ¥ì˜ í¬ê¸°(shape) :',encoder_input.shape)\n",
        "print('ë””ì½”ë”ì˜ ì…ë ¥ì˜ í¬ê¸°(shape) :',decoder_input.shape)\n",
        "print('ë””ì½”ë”ì˜ ë ˆì´ë¸”ì˜ í¬ê¸°(shape) :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyStov8lEqVC",
        "outputId": "e7e13837-b484-4742-b946-afefb53d0d6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¸ì½”ë”ì˜ ì…ë ¥ì˜ í¬ê¸°(shape) : (33000, 8)\n",
            "ë””ì½”ë”ì˜ ì…ë ¥ì˜ í¬ê¸°(shape) : (33000, 16)\n",
            "ë””ì½”ë”ì˜ ë ˆì´ë¸”ì˜ í¬ê¸°(shape) : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"ì˜ì–´ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° : {:d}, í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlxAhqWhEuWd",
        "outputId": "670bcf48-788a-415e-d4c0-e652275a0e2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì˜ì–´ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° : 4672, í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° : 8153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ëŠ” ê°ê° 4,647ê°œì™€ 8,022ê°œì…ë‹ˆë‹¤. ë‹¨ì–´ë¡œë¶€í„° ì •ìˆ˜ë¥¼ ì–»ëŠ” ë”•ì…”ë„ˆë¦¬ì™€ ì •ìˆ˜ë¡œë¶€í„° ë‹¨ì–´ë¥¼ ì–»ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ê°ê° ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. ì´ë“¤ì€ í›ˆë ¨ì„ ë§ˆì¹˜ê³  ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•˜ëŠ” ë‹¨ê³„ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "TfnRn2WtE5QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "ahG1ykLHE22q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìˆœì„œê°€ ì„ì¸ ì •ìˆ˜ sequence ë¦¬ìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "sOGyTgVlE8ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('ëœë¤ ì‹œí€€ìŠ¤ :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm1p5HI-E6BM",
        "outputId": "b642c5f0-6694-4413-e01a-8808e07a8631"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëœë¤ ì‹œí€€ìŠ¤ : [ 7121 20552  5710 ... 11540 28511 24259]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "5n6QDNeiFFdU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMn8oQSkFHgk",
        "outputId": "253693c0-7ae3-4896-f92f-dbb63ee1b8dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  28, 106, 188,   1,   0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNCQTX9jFOCF",
        "outputId": "39ea7ac0-6c3a-4819-a405-9754d6495413"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  11,  15,  30, 185,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-68_eYKFPo9",
        "outputId": "106952c7-886b-4675-ab4a-f04f7a1f95dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 11,  15,  30, 185,   1,   3,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> 18, 5, 16, 173, 1ì´ë¼ëŠ” ë™ì¼ ì‹œí€€ìŠ¤ë¥¼ í™•ì¸í•¨."
      ],
      "metadata": {
        "id": "qV9JkLkDFUs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print('ê²€ì¦ ë°ì´í„°ì˜ ê°œìˆ˜ :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRsAGY6bFT5x",
        "outputId": "a78289ee-5fa1-4fae-d294-d6606f24639f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ê²€ì¦ ë°ì´í„°ì˜ ê°œìˆ˜ : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3300ê°œë¥¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©"
      ],
      "metadata": {
        "id": "NS4HGbI-Fbee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "7a8uOcRxFYqt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í¬ê¸°(shape)ë¥¼ ì¶œë ¥"
      ],
      "metadata": {
        "id": "hC_97NHQFfUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('í›ˆë ¨ source ë°ì´í„°ì˜ í¬ê¸° :',encoder_input_train.shape)\n",
        "print('í›ˆë ¨ target ë°ì´í„°ì˜ í¬ê¸° :',decoder_input_train.shape)\n",
        "print('í›ˆë ¨ target ë ˆì´ë¸”ì˜ í¬ê¸° :',decoder_target_train.shape)\n",
        "print('í…ŒìŠ¤íŠ¸ source ë°ì´í„°ì˜ í¬ê¸° :',encoder_input_test.shape)\n",
        "print('í…ŒìŠ¤íŠ¸ target ë°ì´í„°ì˜ í¬ê¸° :',decoder_input_test.shape)\n",
        "print('í…ŒìŠ¤íŠ¸ target ë ˆì´ë¸”ì˜ í¬ê¸° :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CABS82hQFhmS",
        "outputId": "38738874-7390-42ce-c965-0bd01f5aa9df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í›ˆë ¨ source ë°ì´í„°ì˜ í¬ê¸° : (29700, 8)\n",
            "í›ˆë ¨ target ë°ì´í„°ì˜ í¬ê¸° : (29700, 16)\n",
            "í›ˆë ¨ target ë ˆì´ë¸”ì˜ í¬ê¸° : (29700, 16)\n",
            "í…ŒìŠ¤íŠ¸ source ë°ì´í„°ì˜ í¬ê¸° : (3300, 8)\n",
            "í…ŒìŠ¤íŠ¸ target ë°ì´í„°ì˜ í¬ê¸° : (3300, 16)\n",
            "í…ŒìŠ¤íŠ¸ target ë ˆì´ë¸”ì˜ í¬ê¸° : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ê¸°ê³„ ë²ˆì—­ê¸° ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "-UReJHjqF0sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "3IB9fOedF6oq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ê³¼ LSTMì˜ ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°ë¥¼ 64ë¡œ ì‚¬ìš©"
      ],
      "metadata": {
        "id": "M_U4l4VfF9OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64"
      ],
      "metadata": {
        "id": "4XpkErx4F8eO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¸ì½”ë”\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # ì„ë² ë”© ì¸µ\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # íŒ¨ë”© 0ì€ ì—°ì‚°ì—ì„œ ì œì™¸\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True) # ìƒíƒœê°’ ë¦¬í„´ì„ ìœ„í•´ return_stateëŠ” True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # ì€ë‹‰ ìƒíƒœì™€ ì…€ ìƒíƒœë¥¼ ë¦¬í„´\n",
        "encoder_states = [state_h, state_c] # ì¸ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœì™€ ì…€ ìƒíƒœë¥¼ ì €ì¥"
      ],
      "metadata": {
        "id": "4IgnshjYF_sU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë””ì½”ë”\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # ì„ë² ë”© ì¸µ\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # íŒ¨ë”© 0ì€ ì—°ì‚°ì—ì„œ ì œì™¸\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# ìƒíƒœê°’ ë¦¬í„´ì„ ìœ„í•´ return_stateëŠ” True, ëª¨ë“  ì‹œì ì— ëŒ€í•´ì„œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ return_sequencesëŠ” True\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
        "\n",
        "# ì¸ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœë¥¼ ì´ˆê¸° ì€ë‹‰ ìƒíƒœ(initial_state)ë¡œ ì‚¬ìš©\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# ëª¨ë“  ì‹œì ì˜ ê²°ê³¼ì— ëŒ€í•´ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ ì¶œë ¥ì¸µì„ í†µí•´ ë‹¨ì–´ ì˜ˆì¸¡\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ì •ì˜.\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "hfPTfAa1GPSu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyA-GBv6GRuG",
        "outputId": "0e61000f-86ae-48c3-8d94-a62d492992f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 124s 494ms/step - loss: 3.4783 - acc: 0.6116 - val_loss: 2.1083 - val_acc: 0.6186\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 107s 460ms/step - loss: 1.9278 - acc: 0.6447 - val_loss: 1.7935 - val_acc: 0.7078\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 107s 459ms/step - loss: 1.7064 - acc: 0.7336 - val_loss: 1.6277 - val_acc: 0.7503\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 107s 460ms/step - loss: 1.5608 - acc: 0.7540 - val_loss: 1.5020 - val_acc: 0.7640\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 108s 462ms/step - loss: 1.4435 - acc: 0.7667 - val_loss: 1.4134 - val_acc: 0.7745\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 107s 459ms/step - loss: 1.3565 - acc: 0.7788 - val_loss: 1.3437 - val_acc: 0.7834\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 107s 458ms/step - loss: 1.2773 - acc: 0.7931 - val_loss: 1.2721 - val_acc: 0.7989\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 106s 457ms/step - loss: 1.2045 - acc: 0.8056 - val_loss: 1.2184 - val_acc: 0.8085\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 107s 457ms/step - loss: 1.1428 - acc: 0.8133 - val_loss: 1.1698 - val_acc: 0.8136\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 106s 456ms/step - loss: 1.0877 - acc: 0.8213 - val_loss: 1.1263 - val_acc: 0.8207\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 107s 457ms/step - loss: 1.0371 - acc: 0.8279 - val_loss: 1.0886 - val_acc: 0.8253\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 107s 459ms/step - loss: 0.9916 - acc: 0.8327 - val_loss: 1.0554 - val_acc: 0.8280\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 107s 457ms/step - loss: 0.9504 - acc: 0.8371 - val_loss: 1.0301 - val_acc: 0.8309\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 110s 472ms/step - loss: 0.9139 - acc: 0.8408 - val_loss: 1.0005 - val_acc: 0.8345\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 137s 587ms/step - loss: 0.8783 - acc: 0.8444 - val_loss: 0.9803 - val_acc: 0.8365\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 126s 542ms/step - loss: 0.8465 - acc: 0.8476 - val_loss: 0.9570 - val_acc: 0.8395\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 143s 615ms/step - loss: 0.8152 - acc: 0.8508 - val_loss: 0.9406 - val_acc: 0.8413\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 147s 633ms/step - loss: 0.7869 - acc: 0.8537 - val_loss: 0.9256 - val_acc: 0.8427\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 149s 642ms/step - loss: 0.7600 - acc: 0.8564 - val_loss: 0.9088 - val_acc: 0.8438\n",
            "Epoch 20/50\n",
            "196/233 [========================>.....] - ETA: 21s - loss: 0.7346 - acc: 0.8590"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. seq2seq ê¸°ê³„ ë²ˆì—­ê¸° ë™ì‘ì‹œí‚¤ê¸°"
      ],
      "metadata": {
        "id": "Y4IzNfdoGU3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¸ì½”ë”\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# ë””ì½”ë” ì„¤ê³„ ì‹œì‘\n",
        "# ì´ì „ ì‹œì ì˜ ìƒíƒœë¥¼ ë³´ê´€í•  í…ì„œ\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# í›ˆë ¨ ë•Œ ì‚¬ìš©í–ˆë˜ ì„ë² ë”© ì¸µì„ ì¬ì‚¬ìš©\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì„ ìœ„í•´ ì´ì „ ì‹œì ì˜ ìƒíƒœë¥¼ í˜„ ì‹œì ì˜ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# ëª¨ë“  ì‹œì ì— ëŒ€í•´ì„œ ë‹¨ì–´ ì˜ˆì¸¡\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# ìˆ˜ì •ëœ ë””ì½”ë”\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "bS-D8ZrDGWdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # ì…ë ¥ìœ¼ë¡œë¶€í„° ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ì‹œì ì˜ ìƒíƒœ(ì€ë‹‰ ìƒíƒœ, ì…€ ìƒíƒœ)ë¥¼ ì–»ìŒ\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>ì— í•´ë‹¹í•˜ëŠ” ì •ìˆ˜ ìƒì„±\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_conditionì´ Trueê°€ ë  ë•Œê¹Œì§€ ë£¨í”„ ë°˜ë³µ\n",
        "  # êµ¬í˜„ì˜ ê°„ì†Œí™”ë¥¼ ìœ„í•´ì„œ ì´ í•¨ìˆ˜ëŠ” ë°°ì¹˜ í¬ê¸°ë¥¼ 1ë¡œ ê°€ì •í•©ë‹ˆë‹¤.\n",
        "  while not stop_condition:\n",
        "    # ì´ì  ì‹œì ì˜ ìƒíƒœ states_valueë¥¼ í˜„ ì‹œì ì˜ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¨ì–´ë¡œ ë³€í™˜\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # í˜„ì¬ ì‹œì ì˜ ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ ë¬¸ì¥ì— ì¶”ê°€\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    # <eos>ì— ë„ë‹¬í•˜ê±°ë‚˜ ì •í•´ì§„ ê¸¸ì´ë¥¼ ë„˜ìœ¼ë©´ ì¤‘ë‹¨.\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    # í˜„ì¬ ì‹œì ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì‹œì ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì €ì¥\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # í˜„ì¬ ì‹œì ì˜ ìƒíƒœë¥¼ ë‹¤ìŒ ì‹œì ì˜ ìƒíƒœë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì €ì¥\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "VnRjXIMkGeqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì›ë¬¸ì˜ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "# ë²ˆì—­ë¬¸ì˜ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "TGrkNxjOGg6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"ì…ë ¥ë¬¸ì¥ :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"ì •ë‹µë¬¸ì¥ :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"ë²ˆì—­ë¬¸ì¥ :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "id": "ifEoLnARIRK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"ì…ë ¥ë¬¸ì¥ :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"ì •ë‹µë¬¸ì¥ :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"ë²ˆì—­ë¬¸ì¥ :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "id": "Cwv95YO3IVr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pJIWoJooXIj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2ï¸âƒ£ Attention**"
      ],
      "metadata": {
        "id": "xUWWDwdiPLS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ‘€ **ë‚´ìš©ë³µìŠµ attention** \n",
        "* RNNì— ê¸°ë°˜í•œ seq2seq ëª¨ë¸ì˜ ë‹¨ì ì„ ë³´ì™„í•œ ëª¨ë¸ \n",
        "  * ì •ë³´ì†ì‹¤, ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ í•´ê²° \n",
        "  * ì…ë ¥ë¬¸ì¥ì´ ê¸¸ë©´ ë²ˆì—­ í’ˆì§ˆì´ ë–¨ì–´ì§€ëŠ” í˜„ìƒ ë°©ì§€ \n",
        "\n",
        "*  ë””ì½”ë”ì—ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë§¤ ì‹œì (time step)ë§ˆë‹¤, ì¸ì½”ë”ì—ì„œì˜ ì „ì²´ ì…ë ¥ ë¬¸ì¥ ì¤‘, í•´ë‹¹ ì‹œì ì—ì„œ ì˜ˆì¸¡í•´ì•¼í•  ë‹¨ì–´ì™€ ì—°ê´€ì´ ìˆëŠ” ì…ë ¥ ë‹¨ì–´ ë¶€ë¶„ì„ ì¢€ ë” ì§‘ì¤‘(attention)í•´ì„œ ë³´ëŠ” ì›ë¦¬"
      ],
      "metadata": {
        "id": "9N0B4VknPkTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "ğŸ”¹ **2-(1)** ê¸°ë³¸\n",
        "\n",
        "* [ê°œë…ë³µìŠµ](https://wikidocs.net/22893) \n",
        "\n",
        "ğŸ“Œ [IMDB ë¦¬ë·° ê°ì„±ë¶„ë¥˜](https://wikidocs.net/48920) ğŸ‘‰ í•„ìˆ˜ \n",
        "\n",
        "\n",
        "\n",
        "ğŸ“Œ [TensorFlow ê³µì‹ë¬¸ì„œ - í…ìŠ¤íŠ¸ ë²ˆì—­](\n",
        "https://www.tensorflow.org/text/tutorials/nmt_with_attention) ğŸ‘‰ ì„ íƒ\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QWgla1BuPRqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IMDB ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬í•˜ê¸°"
      ],
      "metadata": {
        "id": "O7g4boENL40X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "diaZweMyAxJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "metadata": {
        "id": "WUSjV6NpL7eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ë¦¬ë·°ì˜ ìµœëŒ€ ê¸¸ì´ : {}'.format(max(len(l) for l in X_train)))\n",
        "print('ë¦¬ë·°ì˜ í‰ê·  ê¸¸ì´ : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ],
      "metadata": {
        "id": "HnQz7G7aL84o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "0QDhqGjdL-Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ë°”ë‹¤ë‚˜ìš° ì–´í…ì…˜(Bahdanau Attention)"
      ],
      "metadata": {
        "id": "NtyTcO5CMABI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "6JcJVWkPMCcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # ë‹¨, keyì™€ valueëŠ” ê°™ìŒ\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score ê³„ì‚°ì„ ìœ„í•´ ë’¤ì—ì„œ í•  ë§ì…ˆì„ ìœ„í•´ì„œ ì°¨ì›ì„ ë³€ê²½í•´ì¤ë‹ˆë‹¤.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "9V9n8dcrMEE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ì–‘ë°©í–¥ LSTM + ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜(BiLSTM with Attention Mechanism)"
      ],
      "metadata": {
        "id": "EaW1iVGUMHJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "metadata": {
        "id": "t3fNo9zZMFzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"
      ],
      "metadata": {
        "id": "lO-DsnbNMKHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
      ],
      "metadata": {
        "id": "UG04Mk96MMpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
      ],
      "metadata": {
        "id": "z3rwHykFMM7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "metadata": {
        "id": "WogWdTHtMPOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_h = Concatenate()([forward_h, backward_h]) # ì€ë‹‰ ìƒíƒœ\n",
        "state_c = Concatenate()([forward_c, backward_c]) # ì…€ ìƒíƒœ"
      ],
      "metadata": {
        "id": "wBS55eV0MQq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = BahdanauAttention(64) # ê°€ì¤‘ì¹˜ í¬ê¸° ì •ì˜\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "metadata": {
        "id": "Id5Sb27SMSFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "metadata": {
        "id": "7RxrngATMTrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1rXc_I4VMVAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
      ],
      "metadata": {
        "id": "aynG0fU2MWV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n í…ŒìŠ¤íŠ¸ ì •í™•ë„: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "LKguTnpKMYj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ **2-(2)** Another task\n",
        "\n",
        "**ì•„ë˜ 3ê°€ì§€ ì˜ˆì œ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ í•„ì‚¬í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤**\n",
        "\n",
        "ğŸ’¨ Text summarization\n",
        "\n",
        "ğŸ“Œ [ì•„ë§ˆì¡´ ë¦¬ë·° ë°ì´í„°ë¡œ í…ìŠ¤íŠ¸ ìš”ì•½ êµ¬í˜„í•˜ê¸°](https://wikidocs.net/72820) \n",
        "\n",
        "ğŸ“Œ [ë‰´ìŠ¤ ê¸°ì‚¬ í…ìŠ¤íŠ¸ ìš”ì•½](https://www.kaggle.com/code/sandeepbhogaraju/text-summarization-with-seq2seq-model/notebook)\n",
        "\n",
        "\n",
        "â•[KaKao Pororo](https://kakaobrain.github.io/pororo/index.html) ğŸ‘‰ ë°©í•™ í”„ë¡œì íŠ¸ ë•Œ í™œìš©í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ :)\n",
        "  * Seq2Seq ì— í•´ë‹¹í•˜ëŠ” example ì°¸ê³ \n",
        "\n",
        "---\n",
        "\n",
        "ğŸ’¨ Chatbot\n",
        "\n",
        "\n",
        "ğŸ“Œ [í•œêµ­ì–´ ì±—ë´‡ êµ¬í˜„í•˜ê¸°](https://teddylee777.github.io/tensorflow/seq2seq-with-attention) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TPX-WtSvPmm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í•œêµ­ì–´ ì±—ë´‡ êµ¬í˜„í•˜ê¸°**"
      ],
      "metadata": {
        "id": "6vtgvi_mMuZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "my3CWhEtXEj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Korpora"
      ],
      "metadata": {
        "id": "ivXXwDKSMx6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import KoreanChatbotKorpus\n",
        "corpus = KoreanChatbotKorpus()"
      ],
      "metadata": {
        "id": "OaIdWR9ZM3tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_all_texts()[:10]"
      ],
      "metadata": {
        "id": "zJzoJYH8M4G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_all_pairs()[0].text"
      ],
      "metadata": {
        "id": "ScNr5JObM-O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_all_pairs()[0].pair"
      ],
      "metadata": {
        "id": "PAuEwph0M-4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë°ì´í„° ì „ì²˜ë¦¬**"
      ],
      "metadata": {
        "id": "2AtsZpfhNFBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "pairs = []\n",
        "\n",
        "for sentence in corpus.get_all_pairs():\n",
        "    texts.append(sentence.text)\n",
        "    pairs.append(sentence.pair)"
      ],
      "metadata": {
        "id": "C6yIFiOnNHIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(texts, pairs))[:5]"
      ],
      "metadata": {
        "id": "cygtg0VFNJ1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re ëª¨ë“ˆì€ regex expressionì„ ì ìš©í•˜ê¸° ìœ„í•˜ì—¬ í™œìš©í•©ë‹ˆë‹¤.\n",
        "import re"
      ],
      "metadata": {
        "id": "1UsjQZogNLkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(sentence):\n",
        "    # í•œê¸€, ìˆ«ìë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ìëŠ” ì œê±°í•©ë‹ˆë‹¤.\n",
        "    sentence = re.sub(r'[^0-9ã„±-ã…ã…-ã…£ê°€-í£ ]',r'', sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "Ds-VTJmpNNvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_sentence('12ì‹œ ë•¡^^!??')\n",
        "clean_sentence('abcefê°€ë‚˜ë‹¤^^$%@12ì‹œ ë•¡^^!??')"
      ],
      "metadata": {
        "id": "PJHNmXh6NQ2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸° (Konlpy)**"
      ],
      "metadata": {
        "id": "PpvXpHwKNUZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "ak3crwwUNSyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "VQGpWTaQNYpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "5FkBsRx2NbXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í˜•íƒœì†Œ ë³€í™˜ì— í™œìš©í•˜ëŠ” í•¨ìˆ˜\n",
        "# morphs í•¨ìˆ˜ ì•ˆì— ë³€í™˜í•œ í•œê¸€ ë¬¸ì¥ì„ ì…ë ¥ í•©ë‹ˆë‹¤.\n",
        "def process_morph(sentence):\n",
        "    return ' '.join(okt.morphs(sentence))"
      ],
      "metadata": {
        "id": "kx0mK7UUNco3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_morph(sentence, is_question=True):\n",
        "    # í•œê¸€ ë¬¸ì¥ ì „ì²˜ë¦¬\n",
        "    sentence = clean_sentence(sentence)\n",
        "    # í˜•íƒœì†Œ ë³€í™˜\n",
        "    sentence = process_morph(sentence)\n",
        "    # Question ì¸ ê²½ìš°, Answerì¸ ê²½ìš°ë¥¼ ë¶„ê¸°í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        # START í† í°ì€ decoder inputì— END í† í°ì€ decoder outputì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "        return ('<START> ' + sentence, sentence + ' <END>')"
      ],
      "metadata": {
        "id": "95puCGq2NgMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts, pairs):\n",
        "    questions = []\n",
        "    answer_in = []\n",
        "    answer_out = []\n",
        "\n",
        "    # ì§ˆì˜ì— ëŒ€í•œ ì „ì²˜ë¦¬\n",
        "    for text in texts:\n",
        "        # ì „ì²˜ë¦¬ì™€ morph ìˆ˜í–‰\n",
        "        question = clean_and_morph(text, is_question=True)\n",
        "        questions.append(question)\n",
        "\n",
        "    # ë‹µë³€ì— ëŒ€í•œ ì „ì²˜ë¦¬\n",
        "    for pair in pairs:\n",
        "        # ì „ì²˜ë¦¬ì™€ morph ìˆ˜í–‰\n",
        "        in_, out_ = clean_and_morph(pair, is_question=False)\n",
        "        answer_in.append(in_)\n",
        "        answer_out.append(out_)\n",
        "    \n",
        "    return questions, answer_in, answer_out"
      ],
      "metadata": {
        "id": "7-gkJLBNNgya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answer_in, answer_out = preprocess(texts, pairs)"
      ],
      "metadata": {
        "id": "JWiNBPELNjnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions[:5]"
      ],
      "metadata": {
        "id": "Ai_QWe43Nj8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in[:5]"
      ],
      "metadata": {
        "id": "3RN0SqOjNlsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_out[:5]"
      ],
      "metadata": {
        "id": "Dy7l4u9LNnFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences = questions + answer_in + answer_out"
      ],
      "metadata": {
        "id": "OD0MCspwNooR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = (' '.join(questions) + ' '.join(answer_in) + ' '.join(answer_out)).split()\n",
        "len(set(a))"
      ],
      "metadata": {
        "id": "funp9_dvNqDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í† í°í™”**"
      ],
      "metadata": {
        "id": "yuNXPzSaNtvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# WARNING ë¬´ì‹œ\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "7pTPlZEWNrol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')"
      ],
      "metadata": {
        "id": "HjI8_XYkNyIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(all_sentences)"
      ],
      "metadata": {
        "id": "p2Ub3NAJNyfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, idx in tokenizer.word_index.items():\n",
        "    print(f'{word}\\t\\t => \\t{idx}')\n",
        "    if idx > 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "zUDR16m6Nz1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "87CqoZtUN1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ì¹˜í™˜: í…ìŠ¤íŠ¸ë¥¼ ì‹œí€€ìŠ¤ë¡œ ì¸ì½”ë”©**"
      ],
      "metadata": {
        "id": "gVrz8s3kN3GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_sequence = tokenizer.texts_to_sequences(questions)\n",
        "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
        "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)"
      ],
      "metadata": {
        "id": "5e8GxNU7N23X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë¬¸ì¥ì˜ ê¸¸ì´ ë§ì¶”ê¸°**"
      ],
      "metadata": {
        "id": "-wjddRemN8YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 30"
      ],
      "metadata": {
        "id": "FY6mbcenN67p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "answer_in_padded = pad_sequences(answer_in_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "answer_out_padded = pad_sequences(answer_out_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')"
      ],
      "metadata": {
        "id": "FkHBQRpdN-xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_padded.shape"
      ],
      "metadata": {
        "id": "L2XgEjM8OAHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in_padded.shape, answer_out_padded.shape"
      ],
      "metadata": {
        "id": "B7ezW8xSOBVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ëª¨ë¸**"
      ],
      "metadata": {
        "id": "z2V7CalIOEVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "41AB194jOCrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•™ìŠµìš© ì¸ì½”ë”(Encoder)"
      ],
      "metadata": {
        "id": "CUw00NetOHvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
        "        self.dropout = Dropout(0.2, name='Dropout')\n",
        "        # (attention) return_sequences=True ì¶”ê°€\n",
        "        self.lstm = LSTM(units, return_state=True, return_sequences=True, name='LSTM')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x)\n",
        "        # (attention) x return ì¶”ê°€\n",
        "        return x, [hidden_state, cell_state]"
      ],
      "metadata": {
        "id": "2QouEdxXOGAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•™ìŠµìš© ë””ì½”ë” (Decoder)"
      ],
      "metadata": {
        "id": "-EsJyAbxOQk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
        "        self.dropout = Dropout(0.2, name='Dropout')\n",
        "        self.lstm = LSTM(units, \n",
        "                         return_state=True, \n",
        "                         return_sequences=True, \n",
        "                         name='LSTM'\n",
        "                        )\n",
        "        self.attention = Attention(name='Attention')\n",
        "        self.dense = Dense(VOCAB_SIZE, activation='softmax', name='Dense')\n",
        "    \n",
        "    def call(self, inputs, initial_state):\n",
        "        # (attention) encoder_inputs ì¶”ê°€\n",
        "        encoder_inputs, decoder_inputs = inputs\n",
        "        x = self.embedding(decoder_inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
        "        \n",
        "        # (attention) key_value, attention_matrix ì¶”ê°€\n",
        "        # ì´ì „ hidden_stateì˜ ê°’ì„ concatìœ¼ë¡œ ë§Œë“¤ì–´ vectorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.        \n",
        "        key_value = tf.concat([initial_state[0][:, tf.newaxis, :], x[:, :-1, :]], axis=1)        \n",
        "        # ì´ì „ hidden_stateì˜ ê°’ì„ concatìœ¼ë¡œ ë§Œë“  vectorì™€ encoderì—ì„œ ë‚˜ì˜¨ ì¶œë ¥ ê°’ë“¤ë¡œ attentionì„ êµ¬í•©ë‹ˆë‹¤.\n",
        "        attention_matrix = self.attention([key_value, encoder_inputs])\n",
        "        # ìœ„ì—ì„œ êµ¬í•œ attention_matrixì™€ decoderì˜ ì¶œë ¥ ê°’ì„ concat í•©ë‹ˆë‹¤.\n",
        "        x = tf.concat([x, attention_matrix], axis=-1)\n",
        "        \n",
        "        x = self.dense(x)\n",
        "        return x, hidden_state, cell_state"
      ],
      "metadata": {
        "id": "qvIK2yDrON6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ëª¨ë¸ ê²°í•©**"
      ],
      "metadata": {
        "id": "Yjp_bKqqOVtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.time_steps = time_steps\n",
        "        \n",
        "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        \n",
        "        \n",
        "    def call(self, inputs, training=True):\n",
        "        if training:\n",
        "            encoder_inputs, decoder_inputs = inputs\n",
        "            # (attention) encoder ì¶œë ¥ ê°’ ìˆ˜ì •\n",
        "            encoder_outputs, context_vector = self.encoder(encoder_inputs)\n",
        "            # (attention) decoder ì…ë ¥ ê°’ ìˆ˜ì •\n",
        "            decoder_outputs, _, _ = self.decoder((encoder_outputs, decoder_inputs), initial_state=context_vector)\n",
        "            return decoder_outputs\n",
        "        else:\n",
        "            x = inputs\n",
        "            # (attention) encoder ì¶œë ¥ ê°’ ìˆ˜ì •\n",
        "            encoder_outputs, context_vector = self.encoder(x)\n",
        "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
        "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
        "            \n",
        "            for i in tf.range(self.time_steps):\n",
        "                decoder_output, decoder_hidden, decoder_cell = self.decoder((encoder_outputs, target_seq), initial_state=context_vector)\n",
        "                decoder_output = tf.cast(tf.argmax(decoder_output, axis=-1), dtype=tf.int32)\n",
        "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
        "                results = results.write(i, decoder_output)\n",
        "                \n",
        "                if decoder_output == self.end_token:\n",
        "                    break\n",
        "                    \n",
        "                target_seq = decoder_output\n",
        "                context_vector = [decoder_hidden, decoder_cell]\n",
        "                \n",
        "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
      ],
      "metadata": {
        "id": "2Bm8MASUOWu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë‹¨ì–´ë³„ ì›í•«ì¸ì½”ë”© ì ìš©**"
      ],
      "metadata": {
        "id": "5fo51iXDOaAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "aJxv3HxzOYxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(padded):\n",
        "    # ì›í•«ì¸ì½”ë”© ì´ˆê¸°í™”\n",
        "    one_hot_vector = np.zeros((len(answer_out_padded), MAX_LENGTH, VOCAB_SIZE))\n",
        "\n",
        "    # ë””ì½”ë” ëª©í‘œë¥¼ ì›í•«ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜\n",
        "    # í•™ìŠµì‹œ ì…ë ¥ì€ ì¸ë±ìŠ¤ì´ì§€ë§Œ, ì¶œë ¥ì€ ì›í•«ì¸ì½”ë”© í˜•ì‹ì„\n",
        "    for i, sequence in enumerate(answer_out_padded):\n",
        "        for j, index in enumerate(sequence):\n",
        "            one_hot_vector[i, j, index] = 1\n",
        "\n",
        "    return one_hot_vector"
      ],
      "metadata": {
        "id": "n2zT1bkeOcD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in_one_hot = convert_to_one_hot(answer_in_padded)\n",
        "answer_out_one_hot = convert_to_one_hot(answer_out_padded)"
      ],
      "metadata": {
        "id": "PUMzCKjWOdhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in_one_hot[0].shape, answer_in_one_hot[0].shape"
      ],
      "metadata": {
        "id": "9VJKJqbJOe62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë³€í™˜ëœ indexë¥¼ ë‹¤ì‹œ ë‹¨ì–´ë¡œ ë³€í™˜**"
      ],
      "metadata": {
        "id": "qzDzPDzWOhaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_index_to_text(indexs, end_token): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # ëª¨ë“  ë¬¸ì¥ì— ëŒ€í•´ì„œ ë°˜ë³µ\n",
        "    for index in indexs:\n",
        "        if index == end_token:\n",
        "            # ë ë‹¨ì–´ì´ë¯€ë¡œ ì˜ˆì¸¡ ì¤‘ë¹„\n",
        "            break;\n",
        "        # ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ì˜ ê²½ìš° ë‹¨ì–´ ì¶”ê°€\n",
        "        if index > 0 and tokenizer.index_word[index] is not None:\n",
        "            sentence += tokenizer.index_word[index]\n",
        "        else:\n",
        "        # ì‚¬ì „ì— ì—†ëŠ” ì¸ë±ìŠ¤ë©´ ë¹ˆ ë¬¸ìì—´ ì¶”ê°€\n",
        "            sentence += ''\n",
        "            \n",
        "        # ë¹ˆì¹¸ ì¶”ê°€\n",
        "        sentence += ' '\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "IIYoNWG4OjQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í•™ìŠµ(Training)**"
      ],
      "metadata": {
        "id": "5MJOfIEQOlkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 100\n",
        "TIME_STEPS = MAX_LENGTH\n",
        "START_TOKEN = tokenizer.word_index['<START>']\n",
        "END_TOKEN = tokenizer.word_index['<END>']\n",
        "\n",
        "UNITS = 128\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
        "DATA_LENGTH = len(questions)\n",
        "SAMPLE_SIZE = 3"
      ],
      "metadata": {
        "id": "Sqsxj8mmOkvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'model/training_checkpoint-6.ckpt'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True,\n",
        "                             save_best_only=True, \n",
        "                             monitor='loss', \n",
        "                             verbose=1\n",
        "                            )"
      ],
      "metadata": {
        "id": "Sc9x8EOHOqGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "8VpNkyGROryV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "9lXSht76OtNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ëª¨ë¸ ìƒì„± & compile"
      ],
      "metadata": {
        "id": "EMAjFbo-Ovpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¶„ì‚° í™˜ê²½ ì ìš©ì‹œ\n",
        "with strategy.scope():\n",
        "    seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "    seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "j33gshjwOudu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "gEw6o1twOxha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—°ì†í•˜ì—¬ í•™ìŠµì‹œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•˜ì—¬ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "seq2seq.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "pJielt9IOyr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model, question_inputs):\n",
        "    results = model(inputs=question_inputs, training=False)\n",
        "    # ë³€í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜\n",
        "    results = np.asarray(results).reshape(-1)\n",
        "    return results"
      ],
      "metadata": {
        "id": "y0GNKT-WOz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(35):\n",
        "    seq2seq.fit([question_padded, answer_in_padded],\n",
        "                answer_out_one_hot,\n",
        "                epochs=10,\n",
        "                batch_size=16, \n",
        "                callbacks=[checkpoint]\n",
        "               )\n",
        "    # ëœë¤í•œ ìƒ˜í”Œ ë²ˆí˜¸ ì¶”ì¶œ\n",
        "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
        "\n",
        "    # ì˜ˆì¸¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
        "    for idx in samples:\n",
        "        question_inputs = question_padded[idx]\n",
        "        # ë¬¸ì¥ ì˜ˆì¸¡\n",
        "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
        "        \n",
        "        # ë³€í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜\n",
        "        results = convert_index_to_text(results, END_TOKEN)\n",
        "        \n",
        "        print(f'Q: {questions[idx]}')\n",
        "        print(f'A: {results}\\n')\n",
        "        print()"
      ],
      "metadata": {
        "id": "JhorPTZhO1Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ì˜ˆì¸¡**"
      ],
      "metadata": {
        "id": "c9ahVgnTO4A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ìì—°ì–´ (ì§ˆë¬¸ ì…ë ¥) ëŒ€í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def make_question(sentence):\n",
        "    sentence = clean_and_morph(sentence)\n",
        "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "    return question_padded"
      ],
      "metadata": {
        "id": "MGMDldydO20y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_question('ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ í™”ì°½í•©ë‹ˆë‹¤')"
      ],
      "metadata": {
        "id": "9m_MECJ6O6DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_question('ì°ì°ì°ì°ì°ì´ì•¼~ ì™„ì „ ì°ì´ì•¼~')"
      ],
      "metadata": {
        "id": "baBkWKYaO7hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chatbot(question):\n",
        "    question_inputs = make_question(question)\n",
        "    results = make_prediction(seq2seq, question_inputs)\n",
        "    results = convert_index_to_text(results, END_TOKEN)\n",
        "    return results"
      ],
      "metadata": {
        "id": "k0LPNu3pO82K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ìœ ì €ë¡œë¶€í„° Text ì…ë ¥ ê°’ì„ ë°›ì•„ ë‹µë³€ ì¶œë ¥**"
      ],
      "metadata": {
        "id": "fY8FE1CtO_81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input('<< ë§ì„ ê±¸ì–´ ë³´ì„¸ìš”!\\n')\n",
        "    if user_input == 'q':\n",
        "        break\n",
        "    print('>> ì±—ë´‡ ì‘ë‹µ: {}'.format(run_chatbot(user_input)))"
      ],
      "metadata": {
        "id": "R_BlqiNSO-Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pNIGBOkXONXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ **2-(3)** ë…¼ë¬¸ì½ê¸° - cs224n 10ê°• ë§›ë³´ê¸° ğŸ‘‰ ì„ íƒ\n",
        "\n",
        "\n",
        "ğŸ“Œ [Bidirectional Attention Flow for Machine Comprehension](https://arxiv.org/abs/1611.01603v6)\n",
        "  * [ì •ë¦¬ ë¸”ë¡œê·¸](https://www.quantumdl.com/entry/10%EC%A3%BC%EC%B0%A82-Bidirectional-Attention-Flow-for-Machine-Comprehension-BiDAF)"
      ],
      "metadata": {
        "id": "bWqZjYiqPpyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UCFj71k-P_Jm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}