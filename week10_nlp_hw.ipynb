{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week10_nlp_hw.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-vPZn15zBHIv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowionlyseedaylight/2022-1-Euron-Study-Assignments/blob/Week_11/week10_nlp_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 week10 과제는 **9주차의 Machine Translation, Seq2Seq and Attention**으로 구성되어 있습니다.\n",
        "\n",
        "📌 위키독스의 딥러닝을 이용한 자연어 처리 입문 교재 실습, \b텐서플로우 및 케라스 등의 공식 문서 자료로 구성되어있는 과제입니다. \n",
        "\n",
        "📌 안내된 링크에 맞추어 **직접 코드를 따라 치면서 (필사)** 해당 nlp task 의 기본적인 라이브러리와 메서드를 숙지해보시면 좋을 것 같습니다😊 필수라고 체크한 부분은 과제에 반드시 포함시켜주시고, 선택으로 체크한 부분은 자율적으로 스터디 하시면 됩니다.\n",
        "\n",
        "📌 궁금한 사항은 깃허브 이슈나, 카톡방, 세션 발표 시작 이전 시간 등을 활용하여 자유롭게 공유해주세요!"
      ],
      "metadata": {
        "id": "QhUHfXkPAORh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk colab 환경에서 실행시 필요한 코드입니다. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "3XjTSbcxBB6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633735f7-ab23-4fcd-d8e6-d9625b1f4e98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ **Seq2Seq**\n",
        "\n"
      ],
      "metadata": {
        "id": "-vPZn15zBHIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👀 **내용 복습 Seq2Seq** \n",
        "\n",
        "* 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 분야 \n",
        "  * 챗봇 : (질문) - (대답) \n",
        "  * 기계번역 : (입력문장) - (번역문장) \n",
        "* 이 외에도 Text summarization, Speech to Text 등에 쓰이는 모델 "
      ],
      "metadata": {
        "id": "cfTJoGzkEBlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "🔹 **seq2seq**\n",
        "\n",
        "* [개념복습](https://wikidocs.net/24996) \n",
        "\n",
        "📌 [word-Level NMT](https://wikidocs.net/86900) 👉 필수 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "📌 [BLEU](https://wikidocs.net/31695) 👉 선택(권장) \n",
        "  * def function 으로 구현 하는 방법, nltk 패키지 라이브러리 사용 방법 \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQLViVEQmKvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 로드 및 전처리"
      ],
      "metadata": {
        "id": "G40TKGnRFs0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Vg32oNQhmOpm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "http = urllib3.PoolManager()\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "metadata": {
        "id": "mhh8iEyk9SGX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000"
      ],
      "metadata": {
        "id": "FGxBTM7aXHSb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "구두점 등을 제거하거나 단어와 구분해주기 위한 전처리"
      ],
      "metadata": {
        "id": "DbuxZE3y9qI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_ascii(s):\n",
        "  # 프랑스어 악센트(accent) 삭제\n",
        "  # 예시 : 'déjà diné' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  # 악센트 제거 함수 호출\n",
        "  sent = to_ascii(sent.lower())\n",
        "\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # 다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "iJksiYc-Y6zS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "구현한 전처리 함수들을 임의의 문장을 입력으로 테스트해봅시다."
      ],
      "metadata": {
        "id": "jUHCFy2O9rF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('전처리 전 영어 문장 :', en_sent)\n",
        "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
        "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
        "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvSK5JZk9mZR",
        "outputId": "c3c95df0-fcab-41e4-ea06-7834c5c4628e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장 : Have you had dinner?\n",
            "전처리 후 영어 문장 : have you had dinner ?\n",
            "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전체 데이터에서 33,000개의 샘플에 대한 전처리\n",
        "- Teacher Forcing 사용\n",
        "- 입력 시퀀스에는 시작을 의미하는 토큰인 sos를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 eos를 추가\n"
      ],
      "metadata": {
        "id": "T6KV8pEMDyGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # source 데이터와 target 데이터 분리\n",
        "      src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      # source 데이터 전처리\n",
        "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # target 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "SHj-Z0oo9tUk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "상위 5개 샘플만 출력해보자."
      ],
      "metadata": {
        "id": "DNECAQFPEFRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
        "print('인코더의 입력 :',sents_en_in[:5])\n",
        "print('디코더의 입력 :',sents_fra_in[:5])\n",
        "print('디코더의 레이블 :',sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2jNkc8yEB4U",
        "outputId": "cb2eea77-fe29-42ac-947b-bdbb78ee4ff6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n",
            "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n",
            "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이전 시점의 디코더 셀의 예측값 대신 실제값을 현재 시점의 디코더 셀의 입력으로 사용하는 방법을 사용\n",
        "\n",
        "- Teacher Forcing: RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법\n",
        "\n"
      ],
      "metadata": {
        "id": "t3ELDUwvEUc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스 토크나이저를 통해 단어 집합을 생성, 정수 인코딩"
      ],
      "metadata": {
        "id": "YlVEZPuoEpqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "metadata": {
        "id": "UpZBi74CEI2H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 크기(shape)를 확인"
      ],
      "metadata": {
        "id": "pd8hsOCzEqqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
        "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
        "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyStov8lEqVC",
        "outputId": "e7e13837-b484-4742-b946-afefb53d0d6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력의 크기(shape) : (33000, 8)\n",
            "디코더의 입력의 크기(shape) : (33000, 16)\n",
            "디코더의 레이블의 크기(shape) : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlxAhqWhEuWd",
        "outputId": "670bcf48-788a-415e-d4c0-e652275a0e2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기 : 4672, 프랑스어 단어 집합의 크기 : 8153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 집합의 크기는 각각 4,647개와 8,022개입니다. 단어로부터 정수를 얻는 딕셔너리와 정수로부터 단어를 얻는 딕셔너리를 각각 만들어줍니다. 이들은 훈련을 마치고 예측값과 실제값을 비교하는 단계에서 사용됩니다."
      ],
      "metadata": {
        "id": "TfnRn2WtE5QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "ahG1ykLHE22q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "순서가 섞인 정수 sequence 리스트"
      ],
      "metadata": {
        "id": "sOGyTgVlE8ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm1p5HI-E6BM",
        "outputId": "b642c5f0-6694-4413-e01a-8808e07a8631"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 : [ 7121 20552  5710 ... 11540 28511 24259]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "5n6QDNeiFFdU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMn8oQSkFHgk",
        "outputId": "253693c0-7ae3-4896-f92f-dbb63ee1b8dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  28, 106, 188,   1,   0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNCQTX9jFOCF",
        "outputId": "39ea7ac0-6c3a-4819-a405-9754d6495413"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  11,  15,  30, 185,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-68_eYKFPo9",
        "outputId": "106952c7-886b-4675-ab4a-f04f7a1f95dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 11,  15,  30, 185,   1,   3,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> 18, 5, 16, 173, 1이라는 동일 시퀀스를 확인함."
      ],
      "metadata": {
        "id": "qV9JkLkDFUs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print('검증 데이터의 개수 :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRsAGY6bFT5x",
        "outputId": "a78289ee-5fa1-4fae-d294-d6606f24639f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 데이터의 개수 : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3300개를 테스트 데이터로 사용"
      ],
      "metadata": {
        "id": "NS4HGbI-Fbee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "7a8uOcRxFYqt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터와 테스트 데이터의 크기(shape)를 출력"
      ],
      "metadata": {
        "id": "hC_97NHQFfUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CABS82hQFhmS",
        "outputId": "38738874-7390-42ce-c965-0bd01f5aa9df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 8)\n",
            "훈련 target 데이터의 크기 : (29700, 16)\n",
            "훈련 target 레이블의 크기 : (29700, 16)\n",
            "테스트 source 데이터의 크기 : (3300, 8)\n",
            "테스트 target 데이터의 크기 : (3300, 16)\n",
            "테스트 target 레이블의 크기 : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 기계 번역기 만들기"
      ],
      "metadata": {
        "id": "-UReJHjqF0sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "3IB9fOedF6oq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 벡터의 차원과 LSTM의 은닉 상태의 크기를 64로 사용"
      ],
      "metadata": {
        "id": "M_U4l4VfF9OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64"
      ],
      "metadata": {
        "id": "4XpkErx4F8eO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "metadata": {
        "id": "4IgnshjYF_sU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 모델의 입력과 출력을 정의.\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "hfPTfAa1GPSu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyA-GBv6GRuG",
        "outputId": "0e61000f-86ae-48c3-8d94-a62d492992f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 124s 494ms/step - loss: 3.4783 - acc: 0.6116 - val_loss: 2.1083 - val_acc: 0.6186\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 107s 460ms/step - loss: 1.9278 - acc: 0.6447 - val_loss: 1.7935 - val_acc: 0.7078\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 107s 459ms/step - loss: 1.7064 - acc: 0.7336 - val_loss: 1.6277 - val_acc: 0.7503\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 107s 460ms/step - loss: 1.5608 - acc: 0.7540 - val_loss: 1.5020 - val_acc: 0.7640\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 108s 462ms/step - loss: 1.4435 - acc: 0.7667 - val_loss: 1.4134 - val_acc: 0.7745\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 107s 459ms/step - loss: 1.3565 - acc: 0.7788 - val_loss: 1.3437 - val_acc: 0.7834\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 107s 458ms/step - loss: 1.2773 - acc: 0.7931 - val_loss: 1.2721 - val_acc: 0.7989\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 106s 457ms/step - loss: 1.2045 - acc: 0.8056 - val_loss: 1.2184 - val_acc: 0.8085\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 107s 457ms/step - loss: 1.1428 - acc: 0.8133 - val_loss: 1.1698 - val_acc: 0.8136\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 106s 456ms/step - loss: 1.0877 - acc: 0.8213 - val_loss: 1.1263 - val_acc: 0.8207\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 107s 457ms/step - loss: 1.0371 - acc: 0.8279 - val_loss: 1.0886 - val_acc: 0.8253\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 107s 459ms/step - loss: 0.9916 - acc: 0.8327 - val_loss: 1.0554 - val_acc: 0.8280\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 107s 457ms/step - loss: 0.9504 - acc: 0.8371 - val_loss: 1.0301 - val_acc: 0.8309\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 110s 472ms/step - loss: 0.9139 - acc: 0.8408 - val_loss: 1.0005 - val_acc: 0.8345\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 137s 587ms/step - loss: 0.8783 - acc: 0.8444 - val_loss: 0.9803 - val_acc: 0.8365\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 126s 542ms/step - loss: 0.8465 - acc: 0.8476 - val_loss: 0.9570 - val_acc: 0.8395\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 143s 615ms/step - loss: 0.8152 - acc: 0.8508 - val_loss: 0.9406 - val_acc: 0.8413\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 147s 633ms/step - loss: 0.7869 - acc: 0.8537 - val_loss: 0.9256 - val_acc: 0.8427\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 149s 642ms/step - loss: 0.7600 - acc: 0.8564 - val_loss: 0.9088 - val_acc: 0.8438\n",
            "Epoch 20/50\n",
            "196/233 [========================>.....] - ETA: 21s - loss: 0.7346 - acc: 0.8590"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. seq2seq 기계 번역기 동작시키기"
      ],
      "metadata": {
        "id": "Y4IzNfdoGU3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# 디코더 설계 시작\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# 수정된 디코더\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "bS-D8ZrDGWdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 정수 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "VnRjXIMkGeqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "TGrkNxjOGg6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "id": "ifEoLnARIRK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "id": "Cwv95YO3IVr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pJIWoJooXIj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2️⃣ Attention**"
      ],
      "metadata": {
        "id": "xUWWDwdiPLS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👀 **내용복습 attention** \n",
        "* RNN에 기반한 seq2seq 모델의 단점을 보완한 모델 \n",
        "  * 정보손실, 기울기 소실 문제 해결 \n",
        "  * 입력문장이 길면 번역 품질이 떨어지는 현상 방지 \n",
        "\n",
        "*  디코더에서 출력 단어를 예측하는 매 시점(time step)마다, 인코더에서의 전체 입력 문장 중, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보는 원리"
      ],
      "metadata": {
        "id": "9N0B4VknPkTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "🔹 **2-(1)** 기본\n",
        "\n",
        "* [개념복습](https://wikidocs.net/22893) \n",
        "\n",
        "📌 [IMDB 리뷰 감성분류](https://wikidocs.net/48920) 👉 필수 \n",
        "\n",
        "\n",
        "\n",
        "📌 [TensorFlow 공식문서 - 텍스트 번역](\n",
        "https://www.tensorflow.org/text/tutorials/nmt_with_attention) 👉 선택\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QWgla1BuPRqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IMDB 리뷰 데이터 전처리하기"
      ],
      "metadata": {
        "id": "O7g4boENL40X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "diaZweMyAxJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "metadata": {
        "id": "WUSjV6NpL7eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ],
      "metadata": {
        "id": "HnQz7G7aL84o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "0QDhqGjdL-Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 바다나우 어텐션(Bahdanau Attention)"
      ],
      "metadata": {
        "id": "NtyTcO5CMABI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "6JcJVWkPMCcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "9V9n8dcrMEE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
      ],
      "metadata": {
        "id": "EaW1iVGUMHJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "metadata": {
        "id": "t3fNo9zZMFzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"
      ],
      "metadata": {
        "id": "lO-DsnbNMKHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
      ],
      "metadata": {
        "id": "UG04Mk96MMpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
      ],
      "metadata": {
        "id": "z3rwHykFMM7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "metadata": {
        "id": "WogWdTHtMPOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
      ],
      "metadata": {
        "id": "wBS55eV0MQq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "metadata": {
        "id": "Id5Sb27SMSFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "metadata": {
        "id": "7RxrngATMTrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1rXc_I4VMVAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
      ],
      "metadata": {
        "id": "aynG0fU2MWV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "LKguTnpKMYj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 **2-(2)** Another task\n",
        "\n",
        "**아래 3가지 예제 중 하나를 골라 필사해주시면 됩니다**\n",
        "\n",
        "💨 Text summarization\n",
        "\n",
        "📌 [아마존 리뷰 데이터로 텍스트 요약 구현하기](https://wikidocs.net/72820) \n",
        "\n",
        "📌 [뉴스 기사 텍스트 요약](https://www.kaggle.com/code/sandeepbhogaraju/text-summarization-with-seq2seq-model/notebook)\n",
        "\n",
        "\n",
        "➕[KaKao Pororo](https://kakaobrain.github.io/pororo/index.html) 👉 방학 프로젝트 때 활용해보면 좋을 것 같습니다 :)\n",
        "  * Seq2Seq 에 해당하는 example 참고\n",
        "\n",
        "---\n",
        "\n",
        "💨 Chatbot\n",
        "\n",
        "\n",
        "📌 [한국어 챗봇 구현하기](https://teddylee777.github.io/tensorflow/seq2seq-with-attention) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TPX-WtSvPmm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**한국어 챗봇 구현하기**"
      ],
      "metadata": {
        "id": "6vtgvi_mMuZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "my3CWhEtXEj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Korpora"
      ],
      "metadata": {
        "id": "ivXXwDKSMx6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import KoreanChatbotKorpus\n",
        "corpus = KoreanChatbotKorpus()"
      ],
      "metadata": {
        "id": "OaIdWR9ZM3tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_all_texts()[:10]"
      ],
      "metadata": {
        "id": "zJzoJYH8M4G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_all_pairs()[0].text"
      ],
      "metadata": {
        "id": "ScNr5JObM-O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_all_pairs()[0].pair"
      ],
      "metadata": {
        "id": "PAuEwph0M-4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 전처리**"
      ],
      "metadata": {
        "id": "2AtsZpfhNFBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "pairs = []\n",
        "\n",
        "for sentence in corpus.get_all_pairs():\n",
        "    texts.append(sentence.text)\n",
        "    pairs.append(sentence.pair)"
      ],
      "metadata": {
        "id": "C6yIFiOnNHIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(texts, pairs))[:5]"
      ],
      "metadata": {
        "id": "cygtg0VFNJ1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re 모듈은 regex expression을 적용하기 위하여 활용합니다.\n",
        "import re"
      ],
      "metadata": {
        "id": "1UsjQZogNLkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(sentence):\n",
        "    # 한글, 숫자를 제외한 모든 문자는 제거합니다.\n",
        "    sentence = re.sub(r'[^0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "Ds-VTJmpNNvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_sentence('12시 땡^^!??')\n",
        "clean_sentence('abcef가나다^^$%@12시 땡^^!??')"
      ],
      "metadata": {
        "id": "PJHNmXh6NQ2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**한글 형태소 분석기 (Konlpy)**"
      ],
      "metadata": {
        "id": "PpvXpHwKNUZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "ak3crwwUNSyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "VQGpWTaQNYpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "5FkBsRx2NbXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 형태소 변환에 활용하는 함수\n",
        "# morphs 함수 안에 변환한 한글 문장을 입력 합니다.\n",
        "def process_morph(sentence):\n",
        "    return ' '.join(okt.morphs(sentence))"
      ],
      "metadata": {
        "id": "kx0mK7UUNco3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_morph(sentence, is_question=True):\n",
        "    # 한글 문장 전처리\n",
        "    sentence = clean_sentence(sentence)\n",
        "    # 형태소 변환\n",
        "    sentence = process_morph(sentence)\n",
        "    # Question 인 경우, Answer인 경우를 분기하여 처리합니다.\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        # START 토큰은 decoder input에 END 토큰은 decoder output에 추가합니다.\n",
        "        return ('<START> ' + sentence, sentence + ' <END>')"
      ],
      "metadata": {
        "id": "95puCGq2NgMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts, pairs):\n",
        "    questions = []\n",
        "    answer_in = []\n",
        "    answer_out = []\n",
        "\n",
        "    # 질의에 대한 전처리\n",
        "    for text in texts:\n",
        "        # 전처리와 morph 수행\n",
        "        question = clean_and_morph(text, is_question=True)\n",
        "        questions.append(question)\n",
        "\n",
        "    # 답변에 대한 전처리\n",
        "    for pair in pairs:\n",
        "        # 전처리와 morph 수행\n",
        "        in_, out_ = clean_and_morph(pair, is_question=False)\n",
        "        answer_in.append(in_)\n",
        "        answer_out.append(out_)\n",
        "    \n",
        "    return questions, answer_in, answer_out"
      ],
      "metadata": {
        "id": "7-gkJLBNNgya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answer_in, answer_out = preprocess(texts, pairs)"
      ],
      "metadata": {
        "id": "JWiNBPELNjnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions[:5]"
      ],
      "metadata": {
        "id": "Ai_QWe43Nj8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in[:5]"
      ],
      "metadata": {
        "id": "3RN0SqOjNlsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_out[:5]"
      ],
      "metadata": {
        "id": "Dy7l4u9LNnFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences = questions + answer_in + answer_out"
      ],
      "metadata": {
        "id": "OD0MCspwNooR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = (' '.join(questions) + ' '.join(answer_in) + ' '.join(answer_out)).split()\n",
        "len(set(a))"
      ],
      "metadata": {
        "id": "funp9_dvNqDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**토큰화**"
      ],
      "metadata": {
        "id": "yuNXPzSaNtvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# WARNING 무시\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "7pTPlZEWNrol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')"
      ],
      "metadata": {
        "id": "HjI8_XYkNyIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(all_sentences)"
      ],
      "metadata": {
        "id": "p2Ub3NAJNyfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, idx in tokenizer.word_index.items():\n",
        "    print(f'{word}\\t\\t => \\t{idx}')\n",
        "    if idx > 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "zUDR16m6Nz1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "87CqoZtUN1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**치환: 텍스트를 시퀀스로 인코딩**"
      ],
      "metadata": {
        "id": "gVrz8s3kN3GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_sequence = tokenizer.texts_to_sequences(questions)\n",
        "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
        "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)"
      ],
      "metadata": {
        "id": "5e8GxNU7N23X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문장의 길이 맞추기**"
      ],
      "metadata": {
        "id": "-wjddRemN8YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 30"
      ],
      "metadata": {
        "id": "FY6mbcenN67p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "answer_in_padded = pad_sequences(answer_in_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "answer_out_padded = pad_sequences(answer_out_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')"
      ],
      "metadata": {
        "id": "FkHBQRpdN-xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_padded.shape"
      ],
      "metadata": {
        "id": "L2XgEjM8OAHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in_padded.shape, answer_out_padded.shape"
      ],
      "metadata": {
        "id": "B7ezW8xSOBVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델**"
      ],
      "metadata": {
        "id": "z2V7CalIOEVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "41AB194jOCrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습용 인코더(Encoder)"
      ],
      "metadata": {
        "id": "CUw00NetOHvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
        "        self.dropout = Dropout(0.2, name='Dropout')\n",
        "        # (attention) return_sequences=True 추가\n",
        "        self.lstm = LSTM(units, return_state=True, return_sequences=True, name='LSTM')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x)\n",
        "        # (attention) x return 추가\n",
        "        return x, [hidden_state, cell_state]"
      ],
      "metadata": {
        "id": "2QouEdxXOGAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습용 디코더 (Decoder)"
      ],
      "metadata": {
        "id": "-EsJyAbxOQk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
        "        self.dropout = Dropout(0.2, name='Dropout')\n",
        "        self.lstm = LSTM(units, \n",
        "                         return_state=True, \n",
        "                         return_sequences=True, \n",
        "                         name='LSTM'\n",
        "                        )\n",
        "        self.attention = Attention(name='Attention')\n",
        "        self.dense = Dense(VOCAB_SIZE, activation='softmax', name='Dense')\n",
        "    \n",
        "    def call(self, inputs, initial_state):\n",
        "        # (attention) encoder_inputs 추가\n",
        "        encoder_inputs, decoder_inputs = inputs\n",
        "        x = self.embedding(decoder_inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
        "        \n",
        "        # (attention) key_value, attention_matrix 추가\n",
        "        # 이전 hidden_state의 값을 concat으로 만들어 vector를 생성합니다.        \n",
        "        key_value = tf.concat([initial_state[0][:, tf.newaxis, :], x[:, :-1, :]], axis=1)        \n",
        "        # 이전 hidden_state의 값을 concat으로 만든 vector와 encoder에서 나온 출력 값들로 attention을 구합니다.\n",
        "        attention_matrix = self.attention([key_value, encoder_inputs])\n",
        "        # 위에서 구한 attention_matrix와 decoder의 출력 값을 concat 합니다.\n",
        "        x = tf.concat([x, attention_matrix], axis=-1)\n",
        "        \n",
        "        x = self.dense(x)\n",
        "        return x, hidden_state, cell_state"
      ],
      "metadata": {
        "id": "qvIK2yDrON6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 결합**"
      ],
      "metadata": {
        "id": "Yjp_bKqqOVtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.time_steps = time_steps\n",
        "        \n",
        "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        \n",
        "        \n",
        "    def call(self, inputs, training=True):\n",
        "        if training:\n",
        "            encoder_inputs, decoder_inputs = inputs\n",
        "            # (attention) encoder 출력 값 수정\n",
        "            encoder_outputs, context_vector = self.encoder(encoder_inputs)\n",
        "            # (attention) decoder 입력 값 수정\n",
        "            decoder_outputs, _, _ = self.decoder((encoder_outputs, decoder_inputs), initial_state=context_vector)\n",
        "            return decoder_outputs\n",
        "        else:\n",
        "            x = inputs\n",
        "            # (attention) encoder 출력 값 수정\n",
        "            encoder_outputs, context_vector = self.encoder(x)\n",
        "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
        "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
        "            \n",
        "            for i in tf.range(self.time_steps):\n",
        "                decoder_output, decoder_hidden, decoder_cell = self.decoder((encoder_outputs, target_seq), initial_state=context_vector)\n",
        "                decoder_output = tf.cast(tf.argmax(decoder_output, axis=-1), dtype=tf.int32)\n",
        "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
        "                results = results.write(i, decoder_output)\n",
        "                \n",
        "                if decoder_output == self.end_token:\n",
        "                    break\n",
        "                    \n",
        "                target_seq = decoder_output\n",
        "                context_vector = [decoder_hidden, decoder_cell]\n",
        "                \n",
        "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
      ],
      "metadata": {
        "id": "2Bm8MASUOWu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단어별 원핫인코딩 적용**"
      ],
      "metadata": {
        "id": "5fo51iXDOaAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "aJxv3HxzOYxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(padded):\n",
        "    # 원핫인코딩 초기화\n",
        "    one_hot_vector = np.zeros((len(answer_out_padded), MAX_LENGTH, VOCAB_SIZE))\n",
        "\n",
        "    # 디코더 목표를 원핫인코딩으로 변환\n",
        "    # 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
        "    for i, sequence in enumerate(answer_out_padded):\n",
        "        for j, index in enumerate(sequence):\n",
        "            one_hot_vector[i, j, index] = 1\n",
        "\n",
        "    return one_hot_vector"
      ],
      "metadata": {
        "id": "n2zT1bkeOcD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in_one_hot = convert_to_one_hot(answer_in_padded)\n",
        "answer_out_one_hot = convert_to_one_hot(answer_out_padded)"
      ],
      "metadata": {
        "id": "PUMzCKjWOdhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_in_one_hot[0].shape, answer_in_one_hot[0].shape"
      ],
      "metadata": {
        "id": "9VJKJqbJOe62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**변환된 index를 다시 단어로 변환**"
      ],
      "metadata": {
        "id": "qzDzPDzWOhaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_index_to_text(indexs, end_token): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == end_token:\n",
        "            # 끝 단어이므로 예측 중비\n",
        "            break;\n",
        "        # 사전에 존재하는 단어의 경우 단어 추가\n",
        "        if index > 0 and tokenizer.index_word[index] is not None:\n",
        "            sentence += tokenizer.index_word[index]\n",
        "        else:\n",
        "        # 사전에 없는 인덱스면 빈 문자열 추가\n",
        "            sentence += ''\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "IIYoNWG4OjQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습(Training)**"
      ],
      "metadata": {
        "id": "5MJOfIEQOlkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 100\n",
        "TIME_STEPS = MAX_LENGTH\n",
        "START_TOKEN = tokenizer.word_index['<START>']\n",
        "END_TOKEN = tokenizer.word_index['<END>']\n",
        "\n",
        "UNITS = 128\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
        "DATA_LENGTH = len(questions)\n",
        "SAMPLE_SIZE = 3"
      ],
      "metadata": {
        "id": "Sqsxj8mmOkvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'model/training_checkpoint-6.ckpt'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True,\n",
        "                             save_best_only=True, \n",
        "                             monitor='loss', \n",
        "                             verbose=1\n",
        "                            )"
      ],
      "metadata": {
        "id": "Sc9x8EOHOqGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "8VpNkyGROryV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "9lXSht76OtNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성 & compile"
      ],
      "metadata": {
        "id": "EMAjFbo-Ovpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분산 환경 적용시\n",
        "with strategy.scope():\n",
        "    seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "    seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "j33gshjwOudu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "gEw6o1twOxha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연속하여 학습시 체크포인트를 로드하여 이어서 학습합니다.\n",
        "seq2seq.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "pJielt9IOyr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model, question_inputs):\n",
        "    results = model(inputs=question_inputs, training=False)\n",
        "    # 변환된 인덱스를 문장으로 변환\n",
        "    results = np.asarray(results).reshape(-1)\n",
        "    return results"
      ],
      "metadata": {
        "id": "y0GNKT-WOz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(35):\n",
        "    seq2seq.fit([question_padded, answer_in_padded],\n",
        "                answer_out_one_hot,\n",
        "                epochs=10,\n",
        "                batch_size=16, \n",
        "                callbacks=[checkpoint]\n",
        "               )\n",
        "    # 랜덤한 샘플 번호 추출\n",
        "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
        "\n",
        "    # 예측 성능 테스트\n",
        "    for idx in samples:\n",
        "        question_inputs = question_padded[idx]\n",
        "        # 문장 예측\n",
        "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
        "        \n",
        "        # 변환된 인덱스를 문장으로 변환\n",
        "        results = convert_index_to_text(results, END_TOKEN)\n",
        "        \n",
        "        print(f'Q: {questions[idx]}')\n",
        "        print(f'A: {results}\\n')\n",
        "        print()"
      ],
      "metadata": {
        "id": "JhorPTZhO1Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**예측**"
      ],
      "metadata": {
        "id": "c9ahVgnTO4A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 자연어 (질문 입력) 대한 전처리 함수\n",
        "def make_question(sentence):\n",
        "    sentence = clean_and_morph(sentence)\n",
        "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "    return question_padded"
      ],
      "metadata": {
        "id": "MGMDldydO20y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_question('오늘 날씨가 정말 화창합니다')"
      ],
      "metadata": {
        "id": "9m_MECJ6O6DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_question('찐찐찐찐찐이야~ 완전 찐이야~')"
      ],
      "metadata": {
        "id": "baBkWKYaO7hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chatbot(question):\n",
        "    question_inputs = make_question(question)\n",
        "    results = make_prediction(seq2seq, question_inputs)\n",
        "    results = convert_index_to_text(results, END_TOKEN)\n",
        "    return results"
      ],
      "metadata": {
        "id": "k0LPNu3pO82K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**유저로부터 Text 입력 값을 받아 답변 출력**"
      ],
      "metadata": {
        "id": "fY8FE1CtO_81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input('<< 말을 걸어 보세요!\\n')\n",
        "    if user_input == 'q':\n",
        "        break\n",
        "    print('>> 챗봇 응답: {}'.format(run_chatbot(user_input)))"
      ],
      "metadata": {
        "id": "R_BlqiNSO-Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pNIGBOkXONXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 **2-(3)** 논문읽기 - cs224n 10강 맛보기 👉 선택\n",
        "\n",
        "\n",
        "📌 [Bidirectional Attention Flow for Machine Comprehension](https://arxiv.org/abs/1611.01603v6)\n",
        "  * [정리 블로그](https://www.quantumdl.com/entry/10%EC%A3%BC%EC%B0%A82-Bidirectional-Attention-Flow-for-Machine-Comprehension-BiDAF)"
      ],
      "metadata": {
        "id": "bWqZjYiqPpyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UCFj71k-P_Jm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}